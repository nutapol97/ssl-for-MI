{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f5c784b-e99a-40e1-9453-a7d754508a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#comment this if you are not using puffer?\n",
    "os.environ['http_proxy'] = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148b7e57-a8b7-4695-ad8e-775cb0fe0e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in /opt/conda/lib/python3.9/site-packages (1.0.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from mne) (1.7.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from mne) (21.3)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.9/site-packages (from mne) (1.21.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from mne) (3.5.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from mne) (3.0.3)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from mne) (5.1.1)\n",
      "Requirement already satisfied: pooch>=1.5 in /opt/conda/lib/python3.9/site-packages (from mne) (1.6.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from mne) (4.62.3)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.9/site-packages (from pooch>=1.5->mne) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from pooch>=1.5->mne) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->mne) (3.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->mne) (2.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (4.28.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->mne) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a06ff5a-770e-490f-8b8a-2341de2d96f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.9/site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.9/site-packages (from opencv-python) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c352b33-cc7e-47b9-bb02-cc55034373c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: warmup-scheduler in /opt/conda/lib/python3.9/site-packages (0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install warmup-scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3fe08b-8f7c-4439-a50a-06ac2d537926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import os\n",
    "import sys\n",
    "from mne.datasets import eegbci\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from mne.datasets import eegbci\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4a67bea-12f3-413f-a6ba-9c00854fe16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from net import resnet18, resnet34, resnet50, resnet101, resnet152\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import tqdm\n",
    "import mit_utils as utils\n",
    "# import analytics\n",
    "import time\n",
    "import os, shutil\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import random\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24c5c92a-1dfe-458f-84ae-861d039e98c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG:\n",
    "    def __init__(self, path, base_url, subjects, runs):\n",
    "        self.subpath = ''\n",
    "        self.path = path\n",
    "        self.base_url = base_url\n",
    "        self.subjects = subjects\n",
    "        self.runs = runs\n",
    "        \n",
    "        # download data if does not exist in path.\n",
    "        # self.load_data()\n",
    "        self.data_to_raw()\n",
    "    \n",
    "    def load_data(self):\n",
    "        print(f\">>> Start download from: {self.base_url}.\")\n",
    "        print(f\"Downloading files to: {self.path}.\")\n",
    "        for subject in self.subjects:\n",
    "            eegbci.load_data(subject,self.runs,path=self.path,base_url=self.base_url)\n",
    "        print(\"Done.\")\n",
    "    \n",
    "    \n",
    "        \n",
    "        print(\"Done.\")\n",
    "        return self.raw\n",
    "    def filter(self, freq):\n",
    "        raw = self.raw\n",
    "        low, high = freq\n",
    "        print(f\">>> Apply filter.\")\n",
    "        self.raw.filter(low, high, fir_design='firwin', verbose=20)\n",
    "        return  raw\n",
    "    def raw_ica(self):\n",
    "        raw = self.raw\n",
    "        ica = mne.preprocessing.ICA(n_components=64, max_iter=100)\n",
    "        ica.fit(raw)\n",
    "        ica.exclude = [1, 2]  # details on how we picked these are omitted here\n",
    "        ica.plot_properties(raw, picks=ica.exclude)\n",
    "        ica.apply(raw)\n",
    "        print('ICA DONE ????')\n",
    "        return  raw\n",
    "        \n",
    "    def get_events(self):\n",
    "        event_id = dict(T1=0, T2=1) # the events we want to extract\n",
    "        events, event_id = mne.events_from_annotations(self.raw, event_id=event_id)\n",
    "        return events, event_id\n",
    "    \n",
    "    def get_epochs(self, events, event_id):\n",
    "        picks = mne.pick_types(self.raw.info, eeg=True, exclude='bads')\n",
    "        tmin = 0\n",
    "        tmax = 4\n",
    "        epochs = mne.Epochs(self.raw, events, event_id, tmin, tmax, proj=True, \n",
    "                            picks=picks, baseline=None, preload=True)\n",
    "        return epochs\n",
    "    \n",
    "    def create_epochs(self):\n",
    "        print(\">>> Create Epochs.\")\n",
    "        events, event_id = self.get_events()\n",
    "        self.epochs = self.get_epochs(events, event_id)\n",
    "        return events , event_id\n",
    "        \n",
    "        print(\"Done.\")\n",
    "    \n",
    "    def get_X_y(self):\n",
    "        if self.epochs is None:\n",
    "            events , event_id=self.create_epochs()\n",
    "        self.X = self.epochs.get_data()\n",
    "        self.y = self.epochs.events[:, -1]\n",
    "        return self.X, self.y\n",
    "    \n",
    "    \n",
    "    def data_to_raw(self):\n",
    "        fullpath = os.path.join(self.path, *self.subpath.split(sep='/'))\n",
    "        #print(f\">>> Extract all subjects from: {fullpath}.\")\n",
    "        extension = \"edf\"\n",
    "        raws = []\n",
    "        count = 1\n",
    "        for i, subject in enumerate(self.subjects):\n",
    "            sname = f\"S{str(subject).zfill(3)}\".upper()\n",
    "            \n",
    "            for j, run in enumerate(self.runs):\n",
    "                rname = f\"{sname}R{str(run).zfill(2)}\".upper()\n",
    "                path_file = os.path.join(fullpath, sname, f'{rname}.{extension}')\n",
    "                #print(path_file)\n",
    "                #print(f\"Loading file #{count}/{len(self.subjects)*len(self.runs)}: {f'{rname}.{extension}'}\")\n",
    "                raw = mne.io.read_raw_edf( path_file , preload=True, verbose='WARNING' )\n",
    "                raws.append(raw)\n",
    "                count += 1\n",
    "\n",
    "        raw = mne.io.concatenate_raws(raws)\n",
    "        eegbci.standardize(raw)\n",
    "        montage = mne.channels.make_standard_montage('standard_1005')\n",
    "        raw.set_montage(montage)\n",
    "        self.raw = raw\n",
    "        \n",
    "        \n",
    "        \n",
    "def do_plot(train_loss, valid_loss):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(train_loss, label='train_loss')\n",
    "    plt.plot(valid_loss, label='valid_loss')\n",
    "    plt.title('loss {}'.format(iter))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e1694-ae3c-4a9f-9ab9-19fa54692d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba306842-10d9-4f07-ac2f-f2a39c09f12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def save_ckpt(state, is_best, model_save_dir, message='best_w.pth'):\n",
    "    current_w = os.path.join(model_save_dir, 'latest_w.pth')\n",
    "    best_w = os.path.join(model_save_dir, message)\n",
    "    torch.save(state, current_w)\n",
    "    if is_best: shutil.copyfile(current_w, best_w)\n",
    "\n",
    "def transform(x, mode):\n",
    "    x_ = x.cpu().numpy()\n",
    "\n",
    "    Trans = Transform()\n",
    "    if mode == 'time_warp':\n",
    "        pieces = random.randint(5,20)\n",
    "        stretch = random.uniform(1.5,4)\n",
    "        squeeze = random.uniform(0.25,0.67)\n",
    "        x_ = Trans.time_warp(x_, 100, pieces, stretch, squeeze)\n",
    "    elif mode == 'noise':\n",
    "        factor = random.uniform(10,20)\n",
    "        x_ = Trans.add_noise_with_SNR(x_,factor)\n",
    "    elif mode == 'scale':\n",
    "        x_ = Trans.scaled(x_,[0.3,3])\n",
    "    elif mode == 'negate':\n",
    "        x_ = Trans.negate(x_)\n",
    "    elif mode == 'hor_flip':\n",
    "        x_ = Trans.hor_filp(x_)\n",
    "        \n",
    "    elif mode == 'permute':\n",
    "        pieces = random.randint(5,20)\n",
    "        x_ = Trans.permute(x_,pieces)\n",
    "        \n",
    "    elif mode == 'cutout_resize':\n",
    "        pieces = random.randint(5, 20)\n",
    "        x_ = Trans.cutout_resize(x_, pieces)\n",
    "    elif mode == 'cutout_zero':\n",
    "        pieces = random.randint(5, 20)\n",
    "        x_ = Trans.cutout_zero(x_, pieces)\n",
    "    elif mode == 'crop_resize':\n",
    "        size = random.uniform(0.25,0.75)\n",
    "        x_ = Trans.crop_resize(x_, size)\n",
    "    elif mode == 'move_avg':\n",
    "        n = random.randint(3, 10)\n",
    "        x_ = Trans.move_avg(x_,n, mode=\"same\")\n",
    "    #     to test\n",
    "    elif mode == 'lowpass':\n",
    "        order = random.randint(3, 10)\n",
    "        cutoff = random.uniform(5,20)\n",
    "        x_ = Trans.lowpass_filter(x_, order, [cutoff])\n",
    "    elif mode == 'highpass':\n",
    "        order = random.randint(3, 10)\n",
    "        cutoff = random.uniform(5, 10)\n",
    "        x_ = Trans.highpass_filter(x_, order, [cutoff])\n",
    "    elif mode == 'bandpass':\n",
    "        order = random.randint(3, 10)\n",
    "        cutoff_l = random.uniform(1, 5)\n",
    "        cutoff_h = random.uniform(20, 40)\n",
    "        cutoff = [cutoff_l, cutoff_h]\n",
    "        x_ = Trans.bandpass_filter(x_, order, cutoff)\n",
    "\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "\n",
    "    x_ = x_.copy()\n",
    "    x_ = x_[:,None,:]\n",
    "    return x_\n",
    "\n",
    "def comtrast_loss(x, criterion):\n",
    "    LARGE_NUM = 1e9\n",
    "    temperature = 0.1\n",
    "    x = F.normalize(x, dim=-1)\n",
    "\n",
    "    num = int(x.shape[0] / 2)\n",
    "    hidden1, hidden2 = torch.split(x, num)\n",
    "\n",
    "\n",
    "    hidden1_large = hidden1\n",
    "    hidden2_large = hidden2\n",
    "    labels = torch.arange(0,num).to(device)\n",
    "    masks = F.one_hot(torch.arange(0,num), num).to(device)\n",
    "\n",
    "\n",
    "    logits_aa = torch.matmul(hidden1, hidden1_large.T) / temperature\n",
    "    logits_aa = logits_aa - masks * LARGE_NUM\n",
    "    logits_bb = torch.matmul(hidden2, hidden2_large.T) / temperature\n",
    "    logits_bb = logits_bb - masks * LARGE_NUM\n",
    "    logits_ab = torch.matmul(hidden1, hidden2_large.T) / temperature\n",
    "    logits_ba = torch.matmul(hidden2, hidden1_large.T) / temperature\n",
    "    # print(labels)\n",
    "    #\n",
    "    # print(torch.cat([logits_ab, logits_aa], 1).shape)\n",
    "\n",
    "    loss_a = criterion(torch.cat([logits_ab, logits_aa], 1),\n",
    "        labels)\n",
    "    loss_b = criterion(torch.cat([logits_ba, logits_bb], 1),\n",
    "        labels)\n",
    "    loss = torch.mean(loss_a + loss_b)\n",
    "    return loss, labels, logits_ab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e20e1b7-3be3-4c2e-bd06-ae16476baacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed1d.pth',\n",
    "}\n",
    "\n",
    "dp_rate = 0\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv1d(in_planes, out_planes, kernel_size=33, stride=stride,\n",
    "                     padding=16, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn0 = nn.BatchNorm1d(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes*2)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dropout = nn.Dropout(dp_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.bn0(x)\n",
    "        out = self.relu(out)\n",
    "        # out = self.dropout(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "            # residual = torch.cat((residual,residual),1)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.bn0 = nn.BatchNorm1d(inplanes)\n",
    "        self.conv1 = nn.Conv1d(inplanes, planes, kernel_size=33, bias=False, padding=16)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=65, stride=stride,\n",
    "                               padding=32, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.conv3 = nn.Conv1d(planes, planes * 4, kernel_size=1, bias=False, padding=0)\n",
    "        self.bn3 = nn.BatchNorm1d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dropout = nn.Dropout(dp_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.bn0(x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        # out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "            # residual = torch.cat((residual, residual), 1)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, classification, num_classes=2):\n",
    "        self.inplanes = 12\n",
    "        self.classification = classification\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(2, self.inplanes, kernel_size=33, stride=1, padding=16,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv1d(self.inplanes, self.inplanes, kernel_size=33, stride=2, padding=16,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(self.inplanes)\n",
    "        self.downsample = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv1d(self.inplanes, self.inplanes, kernel_size=33, stride=1, padding=16,\n",
    "                               bias=False)\n",
    "        self.dropout = nn.Dropout(dp_rate)\n",
    "        self.layer1 = self._make_layer(block, 12, layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block, 24, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 48, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 96, layers[3], stride=2)\n",
    "        # self.layer5 = self._make_layer(block, self.inplanes, layers[4], stride=2)\n",
    "        self.bn_final = nn.BatchNorm1d(96*2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(2)\n",
    "        self.fc1 = nn.Linear(384,716)  # FIXED 716 t 512\n",
    "        self.bn3 = nn.BatchNorm1d(716)\n",
    "        self.fc2 = nn.Linear(716, 192)\n",
    "        self.bn4 = nn.BatchNorm1d(192)\n",
    "        self.fc3 = nn.Linear(192, 2)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        # x = self.maxpool(x)\n",
    "        out = self.conv2(x)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv3(out)\n",
    "        residual = self.downsample(x)\n",
    "        #print('residual : {}'.format(residual.shape))\n",
    "        #print('out : {}'.format(out.shape))\n",
    "        out += residual\n",
    "        x = self.relu(out)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # x = self.layer5(x)\n",
    "        x = self.bn_final(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(\"x shape : {}\".format(x.shape))\n",
    "        if self.classification:\n",
    "            x = self.fc1(x)\n",
    "            x = self.bn3(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2(x)\n",
    "            x = self.bn4(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc3(x)\n",
    "            # x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [ 2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41a1ed4f-a45c-4f32-ae7d-a7b002901dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy import signal\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "class Transform:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def add_noise(self, signal, noise_amount):\n",
    "        \"\"\"\n",
    "        adding noise\n",
    "        \"\"\"\n",
    "        signal = signal.T\n",
    "        noise = (0.4 ** 0.5) * np.random.normal(1, noise_amount, np.shape(signal)[0])\n",
    "        noise = noise[:,None]\n",
    "        noised_signal = signal + noise\n",
    "        noised_signal = noised_signal.T\n",
    "        # print(noised_signal.shape)\n",
    "        return noised_signal\n",
    "\n",
    "    def add_noise_with_SNR(self,signal, noise_amount):\n",
    "        \"\"\"\n",
    "        adding noise\n",
    "        created using: https://stackoverflow.com/a/53688043/10700812\n",
    "        \"\"\"\n",
    "        signal = signal[0]\n",
    "        target_snr_db = noise_amount  # 20\n",
    "        x_watts = signal ** 2  # Calculate signal power and convert to dB\n",
    "        sig_avg_watts = np.mean(x_watts)\n",
    "        sig_avg_db = 10 * np.log10(sig_avg_watts)  # Calculate noise then convert to watts\n",
    "        noise_avg_db = sig_avg_db - target_snr_db\n",
    "        noise_avg_watts = 10 ** (noise_avg_db / 10)\n",
    "        mean_noise = 0\n",
    "        noise_volts = np.random.normal(mean_noise, np.sqrt(noise_avg_watts),\n",
    "                                       len(x_watts))  # Generate an sample of white noise\n",
    "        noised_signal = signal + noise_volts  # noise added signal\n",
    "        noised_signal = noised_signal[None,:]\n",
    "        # print(noised_signal.shape)\n",
    "\n",
    "        return noised_signal\n",
    "\n",
    "    def scaled(self,signal, factor_list):\n",
    "        \"\"\"\"\n",
    "        scale the signal\n",
    "        \"\"\"\n",
    "        factor = round(np.random.uniform(factor_list[0],factor_list[1]),2)\n",
    "        signal[0] = 1 / (1 + np.exp(-signal[0]))\n",
    "        # print(signal.max())\n",
    "        return signal\n",
    "\n",
    "    def negate(self,signal):\n",
    "        \"\"\"\n",
    "        negate the signal\n",
    "        \"\"\"\n",
    "        signal[0] = signal[0] * (-1)\n",
    "        return signal\n",
    "\n",
    "    def hor_filp(self,signal):\n",
    "        \"\"\"\n",
    "        flipped horizontally\n",
    "        \"\"\"\n",
    "        hor_flipped = np.flip(signal,axis=1)\n",
    "        return hor_flipped\n",
    "\n",
    "\n",
    "\n",
    "    def cutout_resize(self,signal,pieces):\n",
    "        \"\"\"\n",
    "                signal: numpy array (batch x window)\n",
    "                pieces: number of segments along time\n",
    "                cutout 1 piece\n",
    "                \"\"\"\n",
    "        signal = signal.T\n",
    "        pieces = int(np.ceil(np.shape(signal)[0] / (np.shape(signal)[0] // pieces)).tolist())  # 向上取整\n",
    "        piece_length = int(np.shape(signal)[0] // pieces)\n",
    "        import random\n",
    "        sequence = []\n",
    "\n",
    "        cutout = random.randint(0, pieces)\n",
    "        # print(cutout)\n",
    "        # sequence1 = list(range(0, cutout))\n",
    "        # sequence2 = list(range(int(cutout + 1), pieces))\n",
    "        # sequence = np.hstack((sequence1, sequence2))\n",
    "        for i in range(pieces):\n",
    "            if i == cutout:\n",
    "                pass\n",
    "            else:\n",
    "                sequence.append(i)\n",
    "        # print(sequence)\n",
    "\n",
    "        cutout_signal = np.reshape(signal[:(np.shape(signal)[0] // pieces * pieces)],\n",
    "                                     (pieces, piece_length)).tolist()\n",
    "\n",
    "        tail = signal[(np.shape(signal)[0] // pieces * pieces):]\n",
    "\n",
    "        cutout_signal = np.asarray(cutout_signal)[sequence]\n",
    "\n",
    "        cutout_signal = np.hstack(cutout_signal)\n",
    "        cutout_signal = np.concatenate((cutout_signal, tail[:, 0]), axis=0)\n",
    "\n",
    "        cutout_signal = cv2.resize(cutout_signal, (1, 3072), interpolation=cv2.INTER_LINEAR)\n",
    "        cutout_signal = cutout_signal.T\n",
    "\n",
    "\n",
    "        return cutout_signal\n",
    "\n",
    "    def cutout_zero(self,signal,pieces):\n",
    "        \"\"\"\n",
    "                signal: numpy array (batch x window)\n",
    "                pieces: number of segments along time\n",
    "                cutout 1 piece\n",
    "                \"\"\"\n",
    "        signal = signal.T\n",
    "        ones = np.ones((np.shape(signal)[0],np.shape(signal)[1]))\n",
    "        # print(ones.shape)\n",
    "        # assert False\n",
    "        pieces = int(np.ceil(np.shape(signal)[0] / (np.shape(signal)[0] // pieces)).tolist())  # 向上取整\n",
    "        piece_length = int(np.shape(signal)[0] // pieces)\n",
    "\n",
    "\n",
    "        cutout = random.randint(1, pieces)\n",
    "        cutout_signal = np.reshape(signal[:(np.shape(signal)[0] // pieces * pieces)],\n",
    "                                     (pieces, piece_length)).tolist()\n",
    "        ones_pieces = np.reshape(ones[:(np.shape(signal)[0] // pieces * pieces)],\n",
    "                                   (pieces, piece_length)).tolist()\n",
    "        tail = signal[(np.shape(signal)[0] // pieces * pieces):]\n",
    "\n",
    "        cutout_signal = np.asarray(cutout_signal)\n",
    "        ones_pieces = np.asarray(ones_pieces)\n",
    "        for i in range(pieces):\n",
    "            if i == cutout:\n",
    "                ones_pieces[i]*=0\n",
    "\n",
    "        cutout_signal = cutout_signal * ones_pieces\n",
    "        cutout_signal = np.hstack(cutout_signal)\n",
    "        cutout_signal = np.concatenate((cutout_signal, tail[:, 0]), axis=0)\n",
    "        cutout_signal = cutout_signal[:,None]\n",
    "        cutout_signal = cutout_signal.T\n",
    "\n",
    "        return cutout_signal\n",
    "    # mic\n",
    "    \n",
    "\n",
    "    def move_avg(self,a,n, mode=\"same\"):\n",
    "        # a = a.T\n",
    "\n",
    "        result = np.convolve(a[0], np.ones((n,)) / n, mode=mode)\n",
    "        return result[None,:]\n",
    "\n",
    "    def bandpass_filter(self, x, order, cutoff, fs=100):\n",
    "        result = np.zeros((x.shape[0], x.shape[1]))\n",
    "        w1 = 2 * cutoff[0] / int(fs)\n",
    "        w2 = 2 * cutoff[1] / int(fs)\n",
    "        b, a = signal.butter(order, [w1, w2], btype='bandpass')  # 配置滤波器 8 表示滤波器的阶数\n",
    "        result = signal.filtfilt(b, a, x, axis=1)\n",
    "        # print(result.shape)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def lowpass_filter(self, x, order, cutoff, fs=100):\n",
    "        result = np.zeros((x.shape[0], x.shape[1]))\n",
    "        w1 = 2 * cutoff[0] / int(fs)\n",
    "        # w2 = 2 * cutoff[1] / fs\n",
    "        b, a = signal.butter(order, w1, btype='lowpass')  # 配置滤波器 8 表示滤波器的阶数\n",
    "        result = signal.filtfilt(b, a, x, axis=1)\n",
    "        # print(result.shape)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def highpass_filter(self, x, order, cutoff, fs=100):\n",
    "        result = np.zeros((x.shape[0], x.shape[1]))\n",
    "        w1 = 2 * cutoff[0] / int(fs)\n",
    "        # w2 = 2 * cutoff[1] / fs\n",
    "        b, a = signal.butter(order, w1, btype='highpass')  # 配置滤波器 8 表示滤波器的阶数\n",
    "        result = signal.filtfilt(b, a, x, axis=1)\n",
    "        # print(result.shape)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def time_warp(self,signal, sampling_freq, pieces, stretch_factor, squeeze_factor):\n",
    "        \"\"\"\n",
    "        signal: numpy array (batch x window)\n",
    "        sampling freq\n",
    "        pieces: number of segments along time\n",
    "        stretch factor\n",
    "        squeeze factor\n",
    "        \"\"\"\n",
    "        signal = signal.T\n",
    "\n",
    "        total_time = np.shape(signal)[0] // sampling_freq\n",
    "        segment_time = total_time / pieces\n",
    "        sequence = list(range(0, pieces))\n",
    "        stretch = np.random.choice(sequence, math.ceil(len(sequence) / 2), replace=False)\n",
    "        squeeze = list(set(sequence).difference(set(stretch)))\n",
    "        initialize = True\n",
    "        for i in sequence:\n",
    "            orig_signal = signal[int(i * np.floor(segment_time * sampling_freq)):int(\n",
    "                (i + 1) * np.floor(segment_time * sampling_freq))]\n",
    "            orig_signal = orig_signal.reshape(np.shape(orig_signal)[0],64, 1)\n",
    "            if i in stretch:\n",
    "                output_shape = int(np.ceil(np.shape(orig_signal)[0] * stretch_factor))\n",
    "                new_signal = cv2.resize(orig_signal, (1, output_shape), interpolation=cv2.INTER_LINEAR)\n",
    "                if initialize == True:\n",
    "                    time_warped = new_signal\n",
    "                    initialize = False\n",
    "                else:\n",
    "                    time_warped = np.vstack((time_warped, new_signal))\n",
    "            elif i in squeeze:\n",
    "                output_shape = int(np.ceil(np.shape(orig_signal)[0] * squeeze_factor))\n",
    "                new_signal = cv2.resize(orig_signal, (1, output_shape), interpolation=cv2.INTER_LINEAR)\n",
    "                if initialize == True:\n",
    "                    time_warped = new_signal\n",
    "                    initialize = False\n",
    "                else:\n",
    "                    time_warped = np.vstack((time_warped, new_signal))\n",
    "        time_warped = cv2.resize(time_warped, (1,3072), interpolation=cv2.INTER_LINEAR)\n",
    "        time_warped = time_warped.T\n",
    "        return time_warped\n",
    "    \n",
    "    \n",
    "    def crop_resize(self, signal, size):\n",
    "        #print(signal.shape)\n",
    "        \n",
    "        signal = signal.T\n",
    "        size = signal.shape[0] * size\n",
    "        size = int(size)\n",
    "        start = random.randint(0, signal.shape[0]-size)\n",
    "        crop_signal = signal[start:start + size,:]\n",
    "        #print(crop_signal.shape)\n",
    "\n",
    "        crop_signal = cv2.resize(crop_signal, (2, 640), interpolation=cv2.INTER_LINEAR)\n",
    "        # print(crop_signal.shape)\n",
    "        crop_signal = crop_signal.T\n",
    "        #print(\"crop_signal.shape : {}\".format(crop_signal.shape))\n",
    "        return crop_signal\n",
    "    \n",
    "    \n",
    "    def permute(self,signal, pieces):\n",
    "        \"\"\"\n",
    "        signal: numpy array (batch x window)\n",
    "        pieces: number of segments along time\n",
    "        \"\"\"\n",
    "        #print('signal shape ; {}'.format(signal.shape))\n",
    "        signal = signal.T\n",
    "        \n",
    "        pieces = int(np.ceil(np.shape(signal)[0] / (np.shape(signal)[0] // pieces)).tolist()) #向上取整\n",
    "        piece_length = int(np.shape(signal)[0] // pieces)\n",
    "        #print(pieces*piece_length)\n",
    "        cal = pieces*piece_length\n",
    "        while cal != 640:\n",
    "            pieces = random.randint(5,20)\n",
    "            pieces = int(np.ceil(np.shape(signal)[0] / (np.shape(signal)[0] // pieces)).tolist()) #向上取整\n",
    "            piece_length = int(np.shape(signal)[0] // pieces)\n",
    "            #print(pieces*piece_length)\n",
    "            cal = pieces*piece_length\n",
    "            \n",
    "        sequence = list(range(0, pieces))\n",
    "        np.random.shuffle(sequence)\n",
    "        #print(signal[:(np.shape(signal)[0] // pieces * pieces)].shape)\n",
    "        for i in range(signal.shape[1]):\n",
    "            #print(i)\n",
    "            #print('signal shape loop ; {}'.format(signal.shape))\n",
    "            # 2,640\n",
    "            permuted_signal = np.reshape(signal[:(np.shape(signal)[0] // pieces * pieces),i],\n",
    "                                         (pieces, piece_length)).tolist()\n",
    "            #print('permuted_signal : {}'.format(len(permuted_signal)))\n",
    "            tail = signal[i,(np.shape(signal)[0] // pieces * pieces):]\n",
    "            \n",
    "            #print('tail shape  ; {}'.format(tail.shape))\n",
    "            permuted_signal = np.asarray(permuted_signal)[sequence]\n",
    "            permuted_signal = np.concatenate(permuted_signal, axis=0)\n",
    "            #print('permuted_signal shape  ; {}'.format(permuted_signal.shape))\n",
    "            permuted_signal = np.concatenate((permuted_signal,tail), axis=0)\n",
    "            permuted_signal = permuted_signal[:,None]\n",
    "            permuted_signal = permuted_signal.T\n",
    "            if i == 0 :\n",
    "                permuted_signal_re = permuted_signal\n",
    "            else:\n",
    "                permuted_signal_re = np.stack((permuted_signal_re,permuted_signal))\n",
    "            #print(permuted_signal_re.shape)\n",
    "        return permuted_signal_re\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e917af6-f1c7-4361-b4ec-ace0d684544a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Apply filter.\n",
      "Filtering raw data in 474 contiguous segments\n",
      "Setting up band-pass filter from 0.05 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.05\n",
      "- Lower transition bandwidth: 0.05 Hz (-6 dB cutoff frequency: 0.03 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 10561 samples (66.006 sec)\n",
      "\n",
      ">>> Create Epochs.\n",
      "Used Annotations descriptions: ['T1', 'T2']\n",
      "Not setting metadata\n",
      "7110 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 7110 events and 641 original time points ...\n",
      "43 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[    672,       0,       1],\n",
       "        [   2000,       0,       0],\n",
       "        [   3328,       0,       0],\n",
       "        ...,\n",
       "        [9355488,       0,       1],\n",
       "        [9356816,       0,       0],\n",
       "        [9358144,       0,       1]]),\n",
       " {'T1': 0, 'T2': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# home directory + datasets folder\n",
    "#path = '/content/drive/MyDrive/MNE-eegbci-data/files/eegmmidb/'\n",
    "path = '1.0.0'\n",
    "base_url = 'https://physionet.org/files/eegmmidb/'\n",
    "# subjects = [1]\n",
    "runs = [3, 4, 7, 8, 11, 12]\n",
    "subjects = [i for i in range(1, 80)]\n",
    "#subjects = [1]\n",
    "# runs = [6,10,14]\n",
    "\n",
    "eeg = EEG(path, base_url, subjects, runs)\n",
    "raw=eeg.data_to_raw()\n",
    "# apply filter\n",
    "freq = (0.05, 40.)\n",
    "raw=eeg.filter(freq=freq)\n",
    "#raw=eeg.raw_ica()\n",
    "eeg.create_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dcca7d47-2ced-4852-81c9-d4e921b68fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7067, 64, 641) (7067,)\n",
      "(7067, 1, 641)\n",
      "(7067, 1, 641)\n",
      "(7067, 2, 641)\n",
      "(7067, 2, 640)\n"
     ]
    }
   ],
   "source": [
    "X, y = eeg.get_X_y()\n",
    "\n",
    "print(X.shape, y.shape)\n",
    " \n",
    "#X = X[:, np.newaxis,:,:]\n",
    "X.shape\n",
    "\n",
    "X2 = X[:,  7:8, :] \n",
    "print(X2.shape)\n",
    "\n",
    "X3= X[:,  13:14, :]\n",
    "print(X3.shape)\n",
    "X4 = np.concatenate((X2,X3), axis=1)\n",
    "print(X4.shape)\n",
    "X = X4\n",
    "X=X[:,:,:640]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aead17ed-830d-4cdb-86f7-0295d2dfceeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3bdda6f-001a-4baf-8f15-0417d4f44c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = resnet18(classification=False).to(device)\n",
    "#net = nn.DataParallel(net).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "batch_size = 512\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1 * (batch_size / 64), momentum=0.9, weight_decay=0.00001)\n",
    "\n",
    "epochs = 10\n",
    "lr_schduler = CosineAnnealingLR(optimizer, T_max=epochs - 10, eta_min=0.05)#default =0.07\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=10, after_scheduler=lr_schduler)\n",
    "optimizer.zero_grad()\n",
    "optimizer.step()\n",
    "scheduler_warmup.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc60be98-3102-47a7-9f7b-00cfe85d1a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4946, 2, 640) (4946,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "      \n",
    "x_train = torch.tensor(x_train, dtype=torch.float).to(device)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9c0f955-fa2f-44b1-a70e-c406ab100845",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = ['R', 'L']\n",
    "val_acc_list = []\n",
    "n_train_samples = x_train.shape[0]\n",
    "iter_per_epoch = n_train_samples // batch_size + 1\n",
    "best_acc = -1\n",
    "err = []\n",
    "best_err = 1\n",
    "margin = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ed86e63-47b8-407c-85e3-d68729c195f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs\"\n",
    "model_name = 'resnet17'\n",
    "model_save_dir = '%s/%s_%s' % (log_dir, model_name, time.strftime(\"%m%d%H%M\"))\n",
    "\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "log_templete = {\"acc\": None,\n",
    "                    \"cm\": None,\n",
    "                    \"f1\": None,\n",
    "                \"per F1\":None,\n",
    "                \"epoch\":None,\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe07ef3a-e3be-4ee3-9b19-e91a4fcaee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_plot_acc_loss(acc, loss):\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(acc, label='acc')\n",
    "    plt.plot(loss, label='loss')\n",
    "    #plt.title('loss {}'.format(iter))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a0b72b6-6d49-4f07-90b3-3a0fd8e474fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 lr?: 0.8 error: 0.8040841083704003  train_loss = tensor(87.1490, device='cuda:1') Acc = 19.59158916295997\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "acc =[]\n",
    "loss_train = [] \n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    net.train()\n",
    "    loss_sum = 0\n",
    "    evaluation = []\n",
    "    \n",
    "    iter = 0\n",
    "    with tqdm.tqdm(total=iter_per_epoch) as pbar:\n",
    "        error_counter = 0\n",
    "        \n",
    "        for X, y in train_iter:\n",
    "            trans1 = np.zeros(X.shape)\n",
    "            trans2 = np.zeros(X.shape)\n",
    "            #print(\"trans2 : {}\".format(trans2.shape))\n",
    "            #print(\"X shape : {}\".format(X.shape))\n",
    "            #print(\"X shape[3] : {}\".format(X.shape[3]))\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                t1 = transform(X[i], \"crop_resize\")\n",
    "                #print(\"t1 shape : {}\".format(t1.shape))\n",
    "                trans1[i] = t1.reshape(2,X.shape[2])\n",
    "            #print(\"trans1 shape : {}\".format(trans1))   \n",
    "            for i in range(X.shape[0]):\n",
    "                t2 = transform(X[i], 'permute')\n",
    "                \n",
    "                #print(\"t2 shape : {}\".format(t2.shape))\n",
    "                trans2[i] = t2.reshape(2,X.shape[2])\n",
    "                \n",
    "            trans = np.concatenate((trans1,trans2))\n",
    "            \n",
    "            trans = torch.tensor(trans, dtype=torch.float, device=device)\n",
    "            \n",
    "            output = net(trans)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            l, lab_con, log_con = comtrast_loss(output, criterion)\n",
    "            _, log_p = torch.max(log_con.data,1)\n",
    "            evaluation.append((log_p == lab_con).tolist())\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += l\n",
    "            iter += 1\n",
    "            pbar.set_description(\"Epoch %d, loss = %.2f\" % (epoch, l.data))\n",
    "            pbar.update(1)\n",
    "        err = l.data\n",
    "    evaluation = [item for sublist in evaluation for item in sublist]\n",
    "\n",
    "\n",
    "    train_acc = sum(evaluation) / len(evaluation)\n",
    "    error = 1 - train_acc\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    acc.append(train_acc*100)\n",
    "    loss_train.append(loss_sum.data.cpu())\n",
    "    #print(acc)\n",
    "    #print(loss_train)\n",
    "    do_plot_acc_loss(acc, loss_train)\n",
    "    print(\"Epoch:\", epoch,\"lr?:\", current_lr, \"error:\", error, \" train_loss =\", loss_sum.data, \"Acc =\",train_acc*100)\n",
    "    #do_plot(loss_sum.data, error)\n",
    "    scheduler_warmup.step()\n",
    "    state = {\"state_dict\": net.state_dict(), \"epoch\": epoch}\n",
    "    save_ckpt(state, best_err > error, model_save_dir)\n",
    "    best_err = min(best_err, error)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db44b9ce-25ca-4732-8844-613139b303fb",
   "metadata": {},
   "source": [
    "### Train classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "09f07f1a-ff9b-45bc-97af-141d7050216d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss = tensor(3.5852, device='cuda:1') val_acc = 61.338991041961336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_561/4185647189.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mloss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0miter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch %d, loss = %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = resnet18(classification=True).to(device)\n",
    "#net = nn.DataParallel(net)\n",
    "checkpoint = torch.load(os.path.join(model_save_dir,'best_w.pth'))\n",
    "#checkpoint = torch.load(os.path.join(\"logs/resnet17_05170339\",'best_w.pth'))\n",
    "net.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=0.00001)\n",
    "\n",
    "epochs_t = 70\n",
    "lr_schduler = CosineAnnealingLR(optimizer, T_max=epochs_t - 10, eta_min=0.09)#default =0.07\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=10, after_scheduler=lr_schduler)\n",
    "optimizer.zero_grad()\n",
    "optimizer.step()\n",
    "scheduler_warmup.step()\n",
    "\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "val_acc_list = []\n",
    "loss_list = []\n",
    "acc_plot = []\n",
    "n_train_samples = x_train.shape[0]\n",
    "iter_per_epoch = n_train_samples // batch_size + 1\n",
    "best_acc = -1\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs_t):\n",
    "    net.train()\n",
    "    loss_sum = 0\n",
    "    evaluation = []\n",
    "    iter = 0\n",
    "    with tqdm.tqdm(total=iter_per_epoch) as pbar:\n",
    "        for X, y in train_iter:\n",
    "            #print(\"X shape : {}\".format(X.shape))\n",
    "            output = net(X)\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            evaluation.append((predicted == y).tolist())\n",
    "            optimizer.zero_grad()\n",
    "            l = criterion(output, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += l\n",
    "            iter += 1\n",
    "            pbar.set_description(\"Epoch %d, loss = %.2f\" % (epoch, l.data))\n",
    "            pbar.update(1)\n",
    "    evaluation = [item for sublist in evaluation for item in sublist]\n",
    "    train_acc = sum(evaluation) / len(evaluation)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(\"Epoch:\", epoch,\"lr:\", current_lr,\" train_loss =\", loss_sum.data, \" train_acc =\", train_acc)\n",
    "    # scheduler.step()\n",
    "    scheduler_warmup.step()\n",
    "    val_loss = 0\n",
    "    evaluation = []\n",
    "    pred_v = []\n",
    "    true_v = []\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for X, y in test_iter:\n",
    "            output = net(X)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            evaluation.append((predicted == y).tolist())\n",
    "            l = criterion(output, y)\n",
    "            val_loss += l\n",
    "            pred_v.append(predicted.tolist())\n",
    "            true_v.append(y.tolist())\n",
    "    evaluation = [item for sublist in evaluation for item in sublist]\n",
    "    pred_v = [item for sublist in pred_v for item in sublist]\n",
    "    true_v = [item for sublist in true_v for item in sublist]\n",
    "\n",
    "    running_acc = sum(evaluation)*100 / len(evaluation)\n",
    "    val_acc_list.append(running_acc)\n",
    "    loss_list.append(val_loss.cpu())\n",
    "    do_plot_acc_loss(val_acc_list, loss_list)\n",
    "    print(\"val_loss =\", val_loss, \"val_acc =\", running_acc)\n",
    "\n",
    "\n",
    "    state = {\"state_dict\": net.state_dict(), \"epoch\": epoch}\n",
    "    save_ckpt(state, best_acc < running_acc, model_save_dir, 'best_cls.pth')\n",
    "    best_acc = max(best_acc, running_acc)\n",
    "\n",
    "print(\"Highest acc:\", max(val_acc_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3126f035-0257-4933-9893-21eb7550ca1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbe8263-2b0f-473e-b4e1-1c1f57502866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a06601-f3d9-406b-b31e-a3e80f6abaca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
