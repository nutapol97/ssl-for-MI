{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f5c784b-e99a-40e1-9453-a7d754508a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#comment this if you are not using puffer?\n",
    "os.environ['http_proxy'] = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148b7e57-a8b7-4695-ad8e-775cb0fe0e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in /opt/conda/lib/python3.9/site-packages (1.0.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from mne) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.9/site-packages (from mne) (1.21.5)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from mne) (3.5.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from mne) (3.0.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from mne) (1.7.3)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from mne) (5.1.1)\n",
      "Requirement already satisfied: pooch>=1.5 in /opt/conda/lib/python3.9/site-packages (from mne) (1.6.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from mne) (21.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from pooch>=1.5->mne) (2.27.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.9/site-packages (from pooch>=1.5->mne) (1.4.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->mne) (3.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->mne) (2.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (4.28.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->mne) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a06ff5a-770e-490f-8b8a-2341de2d96f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.9/site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.9/site-packages (from opencv-python) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c352b33-cc7e-47b9-bb02-cc55034373c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: warmup-scheduler in /opt/conda/lib/python3.9/site-packages (0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install warmup-scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3fe08b-8f7c-4439-a50a-06ac2d537926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import os\n",
    "import sys\n",
    "from mne.datasets import eegbci\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from mne.datasets import eegbci\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4a67bea-12f3-413f-a6ba-9c00854fe16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from net import resnet18, resnet34, resnet50, resnet101, resnet152\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import tqdm\n",
    "import mit_utils as utils\n",
    "# import analytics\n",
    "import time\n",
    "import os, shutil\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import random\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24c5c92a-1dfe-458f-84ae-861d039e98c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG:\n",
    "    def __init__(self, path, base_url, subjects, runs):\n",
    "        self.subpath = ''\n",
    "        self.path = path\n",
    "        self.base_url = base_url\n",
    "        self.subjects = subjects\n",
    "        self.runs = runs\n",
    "        \n",
    "        # download data if does not exist in path.\n",
    "        # self.load_data()\n",
    "        self.data_to_raw()\n",
    "    \n",
    "    def load_data(self):\n",
    "        print(f\">>> Start download from: {self.base_url}.\")\n",
    "        print(f\"Downloading files to: {self.path}.\")\n",
    "        for subject in self.subjects:\n",
    "            eegbci.load_data(subject,self.runs,path=self.path,base_url=self.base_url)\n",
    "        print(\"Done.\")\n",
    "    \n",
    "    \n",
    "        \n",
    "        print(\"Done.\")\n",
    "        return self.raw\n",
    "    def filter(self, freq):\n",
    "        raw = self.raw\n",
    "        low, high = freq\n",
    "        print(f\">>> Apply filter.\")\n",
    "        self.raw.filter(low, high, fir_design='firwin', verbose=20)\n",
    "        return  raw\n",
    "    def raw_ica(self):\n",
    "        raw = self.raw\n",
    "        ica = mne.preprocessing.ICA(n_components=64, max_iter=100)\n",
    "        ica.fit(raw)\n",
    "        ica.exclude = [1, 2]  # details on how we picked these are omitted here\n",
    "        ica.plot_properties(raw, picks=ica.exclude)\n",
    "        ica.apply(raw)\n",
    "        print('ICA DONE ????')\n",
    "        return  raw\n",
    "        \n",
    "    def get_events(self):\n",
    "        event_id = dict(T1=0, T2=1) # the events we want to extract\n",
    "        events, event_id = mne.events_from_annotations(self.raw, event_id=event_id)\n",
    "        return events, event_id\n",
    "    \n",
    "    def get_epochs(self, events, event_id):\n",
    "        picks = mne.pick_types(self.raw.info, eeg=True, exclude='bads')\n",
    "        tmin = 0\n",
    "        tmax = 4\n",
    "        epochs = mne.Epochs(self.raw, events, event_id, tmin, tmax, proj=True, \n",
    "                            picks=picks, baseline=None, preload=True)\n",
    "        return epochs\n",
    "    \n",
    "    def create_epochs(self):\n",
    "        print(\">>> Create Epochs.\")\n",
    "        events, event_id = self.get_events()\n",
    "        self.epochs = self.get_epochs(events, event_id)\n",
    "        return events , event_id\n",
    "        \n",
    "        print(\"Done.\")\n",
    "    \n",
    "    def get_X_y(self):\n",
    "        if self.epochs is None:\n",
    "            events , event_id=self.create_epochs()\n",
    "        self.X = self.epochs.get_data()\n",
    "        self.y = self.epochs.events[:, -1]\n",
    "        return self.X, self.y\n",
    "    \n",
    "    \n",
    "    def data_to_raw(self):\n",
    "        fullpath = os.path.join(self.path, *self.subpath.split(sep='/'))\n",
    "        #print(f\">>> Extract all subjects from: {fullpath}.\")\n",
    "        extension = \"edf\"\n",
    "        raws = []\n",
    "        count = 1\n",
    "        for i, subject in enumerate(self.subjects):\n",
    "            sname = f\"S{str(subject).zfill(3)}\".upper()\n",
    "            \n",
    "            for j, run in enumerate(self.runs):\n",
    "                rname = f\"{sname}R{str(run).zfill(2)}\".upper()\n",
    "                path_file = os.path.join(fullpath, sname, f'{rname}.{extension}')\n",
    "                #print(path_file)\n",
    "                #print(f\"Loading file #{count}/{len(self.subjects)*len(self.runs)}: {f'{rname}.{extension}'}\")\n",
    "                raw = mne.io.read_raw_edf( path_file , preload=True, verbose='WARNING' )\n",
    "                raws.append(raw)\n",
    "                count += 1\n",
    "\n",
    "        raw = mne.io.concatenate_raws(raws)\n",
    "        eegbci.standardize(raw)\n",
    "        montage = mne.channels.make_standard_montage('standard_1005')\n",
    "        raw.set_montage(montage)\n",
    "        self.raw = raw\n",
    "        \n",
    "        \n",
    "        \n",
    "def do_plot(train_loss, valid_loss):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(train_loss, label='train_loss')\n",
    "    plt.plot(valid_loss, label='valid_loss')\n",
    "    plt.title('loss {}'.format(iter))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba306842-10d9-4f07-ac2f-f2a39c09f12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def save_ckpt(state, is_best, model_save_dir, message='best_w.pth'):\n",
    "    current_w = os.path.join(model_save_dir, 'latest_w.pth')\n",
    "    best_w = os.path.join(model_save_dir, message)\n",
    "    torch.save(state, current_w)\n",
    "    if is_best: shutil.copyfile(current_w, best_w)\n",
    "\n",
    "def transform(x, mode):\n",
    "    x_ = x.cpu().numpy()\n",
    "\n",
    "    Trans = Transform()\n",
    "    if mode == 'time_warp':\n",
    "        pieces = random.randint(5,20)\n",
    "        stretch = random.uniform(1.5,4)\n",
    "        squeeze = random.uniform(0.25,0.67)\n",
    "        x_ = Trans.time_warp(x_, 100, pieces, stretch, squeeze)\n",
    "    elif mode == 'noise':\n",
    "        factor = random.uniform(10,20)\n",
    "        x_ = Trans.add_noise_with_SNR(x_,factor)\n",
    "    elif mode == 'scale':\n",
    "        x_ = Trans.scaled(x_,[0.3,3])\n",
    "    elif mode == 'negate':\n",
    "        x_ = Trans.negate(x_)\n",
    "    elif mode == 'hor_flip':\n",
    "        x_ = Trans.hor_filp(x_)\n",
    "        \n",
    "    elif mode == 'permute':\n",
    "        pieces = random.randint(5,20)\n",
    "        x_ = Trans.permute(x_,pieces)\n",
    "        \n",
    "    elif mode == 'cutout_resize':\n",
    "        pieces = random.randint(5, 20)\n",
    "        x_ = Trans.cutout_resize(x_, pieces)\n",
    "    elif mode == 'cutout_zero':\n",
    "        pieces = random.randint(5, 20)\n",
    "        x_ = Trans.cutout_zero(x_, pieces)\n",
    "    elif mode == 'crop_resize':\n",
    "        size = random.uniform(0.25,0.75)\n",
    "        x_ = Trans.crop_resize(x_, size)\n",
    "    elif mode == 'move_avg':\n",
    "        n = random.randint(3, 10)\n",
    "        x_ = Trans.move_avg(x_,n, mode=\"same\")\n",
    "    #     to test\n",
    "    elif mode == 'lowpass':\n",
    "        order = random.randint(3, 10)\n",
    "        cutoff = random.uniform(5,20)\n",
    "        x_ = Trans.lowpass_filter(x_, order, [cutoff])\n",
    "    elif mode == 'highpass':\n",
    "        order = random.randint(3, 10)\n",
    "        cutoff = random.uniform(5, 10)\n",
    "        x_ = Trans.highpass_filter(x_, order, [cutoff])\n",
    "    elif mode == 'bandpass':\n",
    "        order = random.randint(3, 10)\n",
    "        cutoff_l = random.uniform(1, 5)\n",
    "        cutoff_h = random.uniform(20, 40)\n",
    "        cutoff = [cutoff_l, cutoff_h]\n",
    "        x_ = Trans.bandpass_filter(x_, order, cutoff)\n",
    "\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "\n",
    "    x_ = x_.copy()\n",
    "    x_ = x_[:,None,:]\n",
    "    return x_\n",
    "\n",
    "def comtrast_loss(x, criterion):\n",
    "    LARGE_NUM = 1e9\n",
    "    temperature = 0.1\n",
    "    x = F.normalize(x, dim=-1)\n",
    "\n",
    "    num = int(x.shape[0] / 2)\n",
    "    hidden1, hidden2 = torch.split(x, num)\n",
    "\n",
    "\n",
    "    hidden1_large = hidden1\n",
    "    hidden2_large = hidden2\n",
    "    labels = torch.arange(0,num).to(device)\n",
    "    masks = F.one_hot(torch.arange(0,num), num).to(device)\n",
    "\n",
    "\n",
    "    logits_aa = torch.matmul(hidden1, hidden1_large.T) / temperature\n",
    "    logits_aa = logits_aa - masks * LARGE_NUM\n",
    "    logits_bb = torch.matmul(hidden2, hidden2_large.T) / temperature\n",
    "    logits_bb = logits_bb - masks * LARGE_NUM\n",
    "    logits_ab = torch.matmul(hidden1, hidden2_large.T) / temperature\n",
    "    logits_ba = torch.matmul(hidden2, hidden1_large.T) / temperature\n",
    "    # print(labels)\n",
    "    #\n",
    "    # print(torch.cat([logits_ab, logits_aa], 1).shape)\n",
    "\n",
    "    loss_a = criterion(torch.cat([logits_ab, logits_aa], 1),\n",
    "        labels)\n",
    "    loss_b = criterion(torch.cat([logits_ba, logits_bb], 1),\n",
    "        labels)\n",
    "    loss = torch.mean(loss_a + loss_b)\n",
    "    return loss, labels, logits_ab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e20e1b7-3be3-4c2e-bd06-ae16476baacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed1d.pth',\n",
    "}\n",
    "\n",
    "dp_rate = 0\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv1d(in_planes, out_planes, kernel_size=33, stride=stride,\n",
    "                     padding=16, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn0 = nn.BatchNorm1d(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes*2)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dropout = nn.Dropout(dp_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.bn0(x)\n",
    "        out = self.relu(out)\n",
    "        # out = self.dropout(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "            # residual = torch.cat((residual,residual),1)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.bn0 = nn.BatchNorm1d(inplanes)\n",
    "        self.conv1 = nn.Conv1d(inplanes, planes, kernel_size=33, bias=False, padding=16)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=65, stride=stride,\n",
    "                               padding=32, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.conv3 = nn.Conv1d(planes, planes * 4, kernel_size=1, bias=False, padding=0)\n",
    "        self.bn3 = nn.BatchNorm1d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dropout = nn.Dropout(dp_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.bn0(x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        # out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "            # residual = torch.cat((residual, residual), 1)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, classification, num_classes=2):\n",
    "        self.inplanes = 12\n",
    "        self.classification = classification\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(64, self.inplanes, kernel_size=33, stride=1, padding=16,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv1d(self.inplanes, self.inplanes, kernel_size=33, stride=2, padding=16,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(self.inplanes)\n",
    "        self.downsample = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv1d(self.inplanes, self.inplanes, kernel_size=33, stride=1, padding=16,\n",
    "                               bias=False)\n",
    "        self.dropout = nn.Dropout(dp_rate)\n",
    "        self.layer1 = self._make_layer(block, 12, layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block, 24, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 48, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 96, layers[3], stride=2)\n",
    "        # self.layer5 = self._make_layer(block, self.inplanes, layers[4], stride=2)\n",
    "        self.bn_final = nn.BatchNorm1d(96*2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(2)\n",
    "        self.fc1 = nn.Linear(384,384)  # FIXED 716 t 512\n",
    "        self.bn3 = nn.BatchNorm1d(384)\n",
    "        self.fc2 = nn.Linear(384, 192)\n",
    "        self.bn4 = nn.BatchNorm1d(192)\n",
    "        self.fc3 = nn.Linear(192, 2)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        # x = self.maxpool(x)\n",
    "        out = self.conv2(x)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv3(out)\n",
    "        residual = self.downsample(x)\n",
    "        #print('residual : {}'.format(residual.shape))\n",
    "        #print('out : {}'.format(out.shape))\n",
    "        out += residual\n",
    "        x = self.relu(out)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # x = self.layer5(x)\n",
    "        x = self.bn_final(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(\"x shape : {}\".format(x.shape))\n",
    "        if self.classification:\n",
    "            x = self.fc1(x)\n",
    "            x = self.bn3(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2(x)\n",
    "            x = self.bn4(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc3(x)\n",
    "            # x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [ 2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41a1ed4f-a45c-4f32-ae7d-a7b002901dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy import signal\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "class Transform:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def scaled(self,signal, factor_list):\n",
    "        \"\"\"\"\n",
    "        scale the signal\n",
    "        \"\"\"\n",
    "        factor = round(np.random.uniform(factor_list[0],factor_list[1]),2)\n",
    "        signal[0] = 1 / (1 + np.exp(-signal[0]))\n",
    "        # print(signal.max())\n",
    "        return signal\n",
    "\n",
    "    def negate(self,signal):\n",
    "        \"\"\"\n",
    "        negate the signal\n",
    "        \"\"\"\n",
    "        signal[0] = signal[0] * (-1)\n",
    "        return signal\n",
    "\n",
    "    def hor_filp(self,signal):\n",
    "        \"\"\"\n",
    "        flipped horizontally\n",
    "        \"\"\"\n",
    "        hor_flipped = np.flip(signal,axis=1)\n",
    "        return hor_flipped\n",
    "\n",
    "\n",
    "\n",
    "    def cutout_resize(self,signal,pieces):\n",
    "        \"\"\"\n",
    "                signal: numpy array (batch x window)\n",
    "                pieces: number of segments along time\n",
    "                cutout 1 piece\n",
    "                \"\"\"\n",
    "        signal = signal.T\n",
    "        pieces = int(np.ceil(np.shape(signal)[0] / (np.shape(signal)[0] // pieces)).tolist())  # 向上取整\n",
    "        piece_length = int(np.shape(signal)[0] // pieces)\n",
    "        import random\n",
    "        sequence = []\n",
    "\n",
    "        cutout = random.randint(0, pieces)\n",
    "        # print(cutout)\n",
    "        # sequence1 = list(range(0, cutout))\n",
    "        # sequence2 = list(range(int(cutout + 1), pieces))\n",
    "        # sequence = np.hstack((sequence1, sequence2))\n",
    "        for i in range(pieces):\n",
    "            if i == cutout:\n",
    "                pass\n",
    "            else:\n",
    "                sequence.append(i)\n",
    "        # print(sequence)\n",
    "\n",
    "        cutout_signal = np.reshape(signal[:(np.shape(signal)[0] // pieces * pieces)],\n",
    "                                     (pieces, piece_length)).tolist()\n",
    "\n",
    "        tail = signal[(np.shape(signal)[0] // pieces * pieces):]\n",
    "\n",
    "        cutout_signal = np.asarray(cutout_signal)[sequence]\n",
    "\n",
    "        cutout_signal = np.hstack(cutout_signal)\n",
    "        cutout_signal = np.concatenate((cutout_signal, tail[:, 0]), axis=0)\n",
    "\n",
    "        cutout_signal = cv2.resize(cutout_signal, (1, 3072), interpolation=cv2.INTER_LINEAR)\n",
    "        cutout_signal = cutout_signal.T\n",
    "\n",
    "\n",
    "        return cutout_signal\n",
    "\n",
    "    def cutout_zero(self,signal,pieces):\n",
    "        \"\"\"\n",
    "                signal: numpy array (batch x window)\n",
    "                pieces: number of segments along time\n",
    "                cutout 1 piece\n",
    "                \"\"\"\n",
    "        signal = signal.T\n",
    "        ones = np.ones((np.shape(signal)[0],np.shape(signal)[1]))\n",
    "        # print(ones.shape)\n",
    "        # assert False\n",
    "        pieces = int(np.ceil(np.shape(signal)[0] / (np.shape(signal)[0] // pieces)).tolist())  # 向上取整\n",
    "        piece_length = int(np.shape(signal)[0] // pieces)\n",
    "\n",
    "\n",
    "        cutout = random.randint(1, pieces)\n",
    "        cutout_signal = np.reshape(signal[:(np.shape(signal)[0] // pieces * pieces)],\n",
    "                                     (pieces, piece_length)).tolist()\n",
    "        ones_pieces = np.reshape(ones[:(np.shape(signal)[0] // pieces * pieces)],\n",
    "                                   (pieces, piece_length)).tolist()\n",
    "        tail = signal[(np.shape(signal)[0] // pieces * pieces):]\n",
    "\n",
    "        cutout_signal = np.asarray(cutout_signal)\n",
    "        ones_pieces = np.asarray(ones_pieces)\n",
    "        for i in range(pieces):\n",
    "            if i == cutout:\n",
    "                ones_pieces[i]*=0\n",
    "\n",
    "        cutout_signal = cutout_signal * ones_pieces\n",
    "        cutout_signal = np.hstack(cutout_signal)\n",
    "        cutout_signal = np.concatenate((cutout_signal, tail[:, 0]), axis=0)\n",
    "        cutout_signal = cutout_signal[:,None]\n",
    "        cutout_signal = cutout_signal.T\n",
    "\n",
    "        return cutout_signal\n",
    "    # mic\n",
    "    \n",
    "\n",
    "    def move_avg(self,a,n, mode=\"same\"):\n",
    "        # a = a.T\n",
    "\n",
    "        result = np.convolve(a[0], np.ones((n,)) / n, mode=mode)\n",
    "        return result[None,:]\n",
    "\n",
    "    def bandpass_filter(self, x, order, cutoff, fs=100):\n",
    "        result = np.zeros((x.shape[0], x.shape[1]))\n",
    "        w1 = 2 * cutoff[0] / int(fs)\n",
    "        w2 = 2 * cutoff[1] / int(fs)\n",
    "        b, a = signal.butter(order, [w1, w2], btype='bandpass')  # 配置滤波器 8 表示滤波器的阶数\n",
    "        result = signal.filtfilt(b, a, x, axis=1)\n",
    "        # print(result.shape)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def lowpass_filter(self, x, order, cutoff, fs=100):\n",
    "        result = np.zeros((x.shape[0], x.shape[1]))\n",
    "        w1 = 2 * cutoff[0] / int(fs)\n",
    "        # w2 = 2 * cutoff[1] / fs\n",
    "        b, a = signal.butter(order, w1, btype='lowpass')  # 配置滤波器 8 表示滤波器的阶数\n",
    "        result = signal.filtfilt(b, a, x, axis=1)\n",
    "        # print(result.shape)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def highpass_filter(self, x, order, cutoff, fs=100):\n",
    "        result = np.zeros((x.shape[0], x.shape[1]))\n",
    "        w1 = 2 * cutoff[0] / int(fs)\n",
    "        # w2 = 2 * cutoff[1] / fs\n",
    "        b, a = signal.butter(order, w1, btype='highpass')  # 配置滤波器 8 表示滤波器的阶数\n",
    "        result = signal.filtfilt(b, a, x, axis=1)\n",
    "        # print(result.shape)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def time_warp(self,signal, sampling_freq, pieces, stretch_factor, squeeze_factor):\n",
    "        \"\"\"\n",
    "        signal: numpy array (batch x window)\n",
    "        sampling freq\n",
    "        pieces: number of segments along time\n",
    "        stretch factor\n",
    "        squeeze factor\n",
    "        \"\"\"\n",
    "        signal = signal.T\n",
    "\n",
    "        total_time = np.shape(signal)[0] // sampling_freq\n",
    "        segment_time = total_time / pieces\n",
    "        sequence = list(range(0, pieces))\n",
    "        stretch = np.random.choice(sequence, math.ceil(len(sequence) / 2), replace=False)\n",
    "        squeeze = list(set(sequence).difference(set(stretch)))\n",
    "        initialize = True\n",
    "        for i in sequence:\n",
    "            orig_signal = signal[int(i * np.floor(segment_time * sampling_freq)):int(\n",
    "                (i + 1) * np.floor(segment_time * sampling_freq))]\n",
    "            orig_signal = orig_signal.reshape(np.shape(orig_signal)[0],64, 1)\n",
    "            if i in stretch:\n",
    "                output_shape = int(np.ceil(np.shape(orig_signal)[0] * stretch_factor))\n",
    "                new_signal = cv2.resize(orig_signal, (1, output_shape), interpolation=cv2.INTER_LINEAR)\n",
    "                if initialize == True:\n",
    "                    time_warped = new_signal\n",
    "                    initialize = False\n",
    "                else:\n",
    "                    time_warped = np.vstack((time_warped, new_signal))\n",
    "            elif i in squeeze:\n",
    "                output_shape = int(np.ceil(np.shape(orig_signal)[0] * squeeze_factor))\n",
    "                new_signal = cv2.resize(orig_signal, (1, output_shape), interpolation=cv2.INTER_LINEAR)\n",
    "                if initialize == True:\n",
    "                    time_warped = new_signal\n",
    "                    initialize = False\n",
    "                else:\n",
    "                    time_warped = np.vstack((time_warped, new_signal))\n",
    "        time_warped = cv2.resize(time_warped, (1,3072), interpolation=cv2.INTER_LINEAR)\n",
    "        time_warped = time_warped.T\n",
    "        return time_warped\n",
    "    \n",
    "    def add_noise(self, signal, noise_amount):\n",
    "        \"\"\"\n",
    "        adding noise\n",
    "        \"\"\"\n",
    "        signal = signal.T\n",
    "        noise = (0.4 ** 0.5) * np.random.normal(1, noise_amount, np.shape(signal)[0])\n",
    "        noise = noise[:,None]\n",
    "        noised_signal = signal + noise\n",
    "        noised_signal = noised_signal.T\n",
    "        print(noised_signal.shape)\n",
    "        return noised_signal\n",
    "    \n",
    "    \n",
    "    \n",
    "    def add_noise_with_SNR(self,signal, noise_amount):\n",
    "        \"\"\"\n",
    "        adding noise\n",
    "        created using: https://stackoverflow.com/a/53688043/10700812\n",
    "        \"\"\"\n",
    "        noised_signal_R = np.zeros(signal.shape)\n",
    "        target_snr_db = noise_amount  # 20\n",
    "        #print(\"signal shape : {}\".format(signal.shape))\n",
    "        #print(\"signal shape : {}\".format(signal.shape))\n",
    "        for i in range(signal.shape[0]-1):\n",
    "            #print(\"signal shape : {}\".format(signal.shape))\n",
    "            #print(\"i : {}\".format(i))\n",
    "            signal_r = signal[i,:]\n",
    "            #print(\"signal shape : {}\".format(signal.shape))\n",
    "            x_watts = signal_r ** 2\n",
    "            #print(\"x_watts shape of {0} : {1}\".format(i,x_watts.shape))\n",
    "            sig_avg_watts = np.mean(x_watts)\n",
    "            sig_avg_db = 10 * np.log10(sig_avg_watts)  # Calculate noise then convert to watts\n",
    "            noise_avg_db = sig_avg_db - target_snr_db\n",
    "            noise_avg_watts = 10 ** (noise_avg_db / 10)\n",
    "            mean_noise = 0\n",
    "            noise_volts = np.random.normal(mean_noise, np.sqrt(noise_avg_watts),\n",
    "                                           len(x_watts))\n",
    "            # Generate an sample of white noise\n",
    "            #print(noise_volts.shape)\n",
    "            noised_signal = signal_r + noise_volts  # noise added signal\n",
    "\n",
    "            #print(\"noised_signal shape : {}\".format(noised_signal.shape))\n",
    "\n",
    "            noised_signal = noised_signal[None,:]\n",
    "            noised_signal_R[i,:]=noised_signal\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "           # Calculate signal power and convert to dB\n",
    "        \n",
    "        #print('x_watts : {}'.format(x_watts.shape))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print('sig_avg_watts : {}'.format(sig_avg_watts))\n",
    "        \n",
    "        \n",
    "        #print(noised_signal.shape)\n",
    "\n",
    "        return noised_signal_R\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def crop_resize(self, signal, size):\n",
    "        #print(signal.shape)\n",
    "        \n",
    "        signal = signal.T\n",
    "        size = signal.shape[0] * size\n",
    "        size = int(size)\n",
    "        start = random.randint(0, signal.shape[0]-size)\n",
    "        crop_signal = signal[start:start + size,:]\n",
    "        #print(crop_signal.shape)\n",
    "\n",
    "        crop_signal = cv2.resize(crop_signal, (64, 640), interpolation=cv2.INTER_LINEAR)\n",
    "        # print(crop_signal.shape)\n",
    "        crop_signal = crop_signal.T\n",
    "        #print(\"crop_signal.shape : {}\".format(crop_signal.shape))\n",
    "        return crop_signal\n",
    "    \n",
    "    \n",
    "    def permute(self,signal, pieces):\n",
    "        \"\"\"\n",
    "        signal: numpy array (batch x window)\n",
    "        pieces: number of segments along time\n",
    "        \"\"\"\n",
    "        #print('signal shape ; {}'.format(signal.shape))\n",
    "        permuted_signal_re = np.zeros(signal.shape)\n",
    "        signal = signal.T\n",
    "        \n",
    "        pieces = int(np.ceil(np.shape(signal)[0] / (np.shape(signal)[0] // pieces)).tolist()) #向上取整\n",
    "        piece_length = int(np.shape(signal)[0] // pieces)\n",
    "        #print(pieces*piece_length)\n",
    "        cal = pieces*piece_length\n",
    "        while cal != 640:\n",
    "            pieces = random.randint(5,20)\n",
    "            pieces = int(np.ceil(np.shape(signal)[0] / (np.shape(signal)[0] // pieces)).tolist()) #向上取整\n",
    "            piece_length = int(np.shape(signal)[0] // pieces)\n",
    "            #print(pieces*piece_length)\n",
    "            cal = pieces*piece_length\n",
    "            \n",
    "        sequence = list(range(0, pieces))\n",
    "        np.random.shuffle(sequence)\n",
    "        #print(signal[:(np.shape(signal)[0] // pieces * pieces)].shape)\n",
    "        for i in range(signal.shape[1]):\n",
    "            #print(i)\n",
    "            #print('signal shape loop ; {}'.format(signal.shape))\n",
    "            # 2,640\n",
    "            permuted_signal = np.reshape(signal[:(np.shape(signal)[0] // pieces * pieces),i],\n",
    "                                         (pieces, piece_length)).tolist()\n",
    "            #print('permuted_signal : {}'.format(len(permuted_signal)))\n",
    "            tail = signal[i,(np.shape(signal)[0] // pieces * pieces):]\n",
    "            \n",
    "            #print('tail shape  ; {}'.format(tail.shape))\n",
    "            permuted_signal = np.asarray(permuted_signal)[sequence]\n",
    "            permuted_signal = np.concatenate(permuted_signal, axis=0)\n",
    "            #print('permuted_signal shape  ; {}'.format(permuted_signal.shape))\n",
    "            permuted_signal = np.concatenate((permuted_signal,tail), axis=0)\n",
    "            permuted_signal = permuted_signal[:,None]\n",
    "            permuted_signal = permuted_signal.T\n",
    "            \n",
    "            permuted_signal = permuted_signal[None,:]\n",
    "            permuted_signal_re[i,:]=permuted_signal\n",
    "            \n",
    "            # print(i)\n",
    "            # if i == 0 :\n",
    "            #     permuted_signal_re = permuted_signal\n",
    "            # else:\n",
    "            #     print('permuted_signal_re shape  ; {}'.format(permuted_signal_re.shape))\n",
    "            #     print('permuted_signal shape  ; {}'.format(permuted_signal.shape))\n",
    "            #     permuted_signal_re = np.stack((permuted_signal_re,permuted_signal))\n",
    "            # #print(permuted_signal_re.shape)\n",
    "        return permuted_signal_re\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e917af6-f1c7-4361-b4ec-ace0d684544a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Apply filter.\n",
      "Filtering raw data in 474 contiguous segments\n",
      "Setting up band-pass filter from 0.05 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.05\n",
      "- Lower transition bandwidth: 0.05 Hz (-6 dB cutoff frequency: 0.03 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 10561 samples (66.006 sec)\n",
      "\n",
      ">>> Create Epochs.\n",
      "Used Annotations descriptions: ['T1', 'T2']\n",
      "Not setting metadata\n",
      "7110 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 7110 events and 641 original time points ...\n",
      "43 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[    672,       0,       1],\n",
       "        [   2000,       0,       0],\n",
       "        [   3328,       0,       0],\n",
       "        ...,\n",
       "        [9355488,       0,       1],\n",
       "        [9356816,       0,       0],\n",
       "        [9358144,       0,       1]]),\n",
       " {'T1': 0, 'T2': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# home directory + datasets folder\n",
    "#path = '/content/drive/MyDrive/MNE-eegbci-data/files/eegmmidb/'\n",
    "path = '1.0.0'\n",
    "base_url = 'https://physionet.org/files/eegmmidb/'\n",
    "# subjects = [1]\n",
    "runs = [3, 4, 7, 8, 11, 12]\n",
    "subjects = [i for i in range(1, 80)]\n",
    "#subjects = [1]\n",
    "# runs = [6,10,14]\n",
    "\n",
    "eeg = EEG(path, base_url, subjects, runs)\n",
    "raw=eeg.data_to_raw()\n",
    "# apply filter\n",
    "freq = (0.05, 40.)\n",
    "raw=eeg.filter(freq=freq)\n",
    "#raw=eeg.raw_ica()\n",
    "eeg.create_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcca7d47-2ced-4852-81c9-d4e921b68fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7067, 64, 641) (7067,)\n",
      "(7067, 64, 640)\n"
     ]
    }
   ],
   "source": [
    "X, y = eeg.get_X_y()\n",
    "\n",
    "print(X.shape, y.shape)\n",
    " \n",
    "#X = X[:, np.newaxis,:,:]\n",
    "X.shape\n",
    "\n",
    "# X2 = X[:,  7:8, :] \n",
    "# print(X2.shape)\n",
    "\n",
    "# X3= X[:,  13:14, :]\n",
    "# print(X3.shape)\n",
    "# X4 = np.concatenate((X2,X3), axis=1)\n",
    "# print(X4.shape)\n",
    "# X = X4\n",
    "X=X[:,:,:640]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aead17ed-830d-4cdb-86f7-0295d2dfceeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3bdda6f-001a-4baf-8f15-0417d4f44c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = resnet18(classification=False).to(device)\n",
    "#net = nn.DataParallel(net).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "batch_size = 512\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1 * (batch_size / 64), momentum=0.9, weight_decay=0.00001)\n",
    "\n",
    "epochs = 1000\n",
    "lr_schduler = CosineAnnealingLR(optimizer, T_max=epochs - 10, eta_min=0.05)#default =0.07\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=10, after_scheduler=lr_schduler)\n",
    "optimizer.zero_grad()\n",
    "optimizer.step()\n",
    "scheduler_warmup.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f5251a0-1423-4b04-9827-986eb041b302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4946, 64, 640) (4946,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b474c21b-a121-431b-9ba6-c996f2f6a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"x_train64.npy\",x_train)\n",
    "np.save(\"x_test64.npy\",x_test)\n",
    "np.save(\"y_train64.npy\",y_train)\n",
    "np.save(\"y_test64.npy\",y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc60be98-3102-47a7-9f7b-00cfe85d1a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "      \n",
    "x_train = torch.tensor(x_train, dtype=torch.float).to(device)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9c0f955-fa2f-44b1-a70e-c406ab100845",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = ['R', 'L']\n",
    "val_acc_list = []\n",
    "n_train_samples = x_train.shape[0]\n",
    "iter_per_epoch = n_train_samples // batch_size + 1\n",
    "best_acc = -1\n",
    "err = []\n",
    "best_err = 1\n",
    "margin = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ed86e63-47b8-407c-85e3-d68729c195f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs\"\n",
    "model_name = 'resnet17'\n",
    "model_save_dir = '%s/%s_%s' % (log_dir, model_name, time.strftime(\"%m%d%H%M\"))\n",
    "\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "log_templete = {\"acc\": None,\n",
    "                    \"cm\": None,\n",
    "                    \"f1\": None,\n",
    "                \"per F1\":None,\n",
    "                \"epoch\":None,\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe07ef3a-e3be-4ee3-9b19-e91a4fcaee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_plot_acc_loss(acc, loss):\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(acc, label='acc')\n",
    "    plt.plot(loss, label='loss')\n",
    "    #plt.title('loss {}'.format(iter))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a0b72b6-6d49-4f07-90b3-3a0fd8e474fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 lr?: 0.7385257253458138 error: 0.040436716538617024  train_loss = tensor(9.1628, device='cuda:1') Acc = 95.95632834613829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42, loss = 0.81:  10%|█         | 1/10 [00:08<01:14,  8.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_463/2748337781.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m#print(\"trans1 shape : {}\".format(trans1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'permute'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m#print(\"t2 shape : {}\".format(t2.shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_463/3957084077.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(x, mode)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'permute'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mpieces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpieces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cutout_resize'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_463/927076293.py\u001b[0m in \u001b[0;36mpermute\u001b[0;34m(self, signal, pieces)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;31m#print('tail shape  ; {}'.format(tail.shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m             \u001b[0mpermuted_signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermuted_signal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0mpermuted_signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermuted_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;31m#print('permuted_signal shape  ; {}'.format(permuted_signal.shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "acc =[]\n",
    "loss_train = [] \n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    net.train()\n",
    "    loss_sum = 0\n",
    "    evaluation = []\n",
    "    \n",
    "    iter = 0\n",
    "    with tqdm.tqdm(total=iter_per_epoch) as pbar:\n",
    "        error_counter = 0\n",
    "        \n",
    "        for X, y in train_iter:\n",
    "            trans1 = np.zeros(X.shape)\n",
    "            trans2 = np.zeros(X.shape)\n",
    "            #print(\"trans2 : {}\".format(trans2.shape))\n",
    "            #print(\"X shape : {}\".format(X.shape))\n",
    "            #print(\"X shape[3] : {}\".format(X.shape[3]))\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                #print(X[i].shape)\n",
    "                t1 = transform(X[i], \"crop_resize\")\n",
    "                #print(\"t1 shape : {}\".format(t1.shape))\n",
    "                trans1[i] = t1.reshape(64,X.shape[2])\n",
    "            #print(\"trans1 shape : {}\".format(trans1))   \n",
    "            for i in range(X.shape[0]):\n",
    "                t2 = transform(X[i], 'permute')\n",
    "                \n",
    "                #print(\"t2 shape : {}\".format(t2.shape))\n",
    "                trans2[i] = t2.reshape(64,X.shape[2])\n",
    "                \n",
    "            trans = np.concatenate((trans1,trans2))\n",
    "            \n",
    "            trans = torch.tensor(trans, dtype=torch.float, device=device)\n",
    "            \n",
    "            output = net(trans)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            l, lab_con, log_con = comtrast_loss(output, criterion)\n",
    "            _, log_p = torch.max(log_con.data,1)\n",
    "            evaluation.append((log_p == lab_con).tolist())\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += l\n",
    "            iter += 1\n",
    "            pbar.set_description(\"Epoch %d, loss = %.2f\" % (epoch, l.data))\n",
    "            pbar.update(1)\n",
    "        err = l.data\n",
    "    evaluation = [item for sublist in evaluation for item in sublist]\n",
    "\n",
    "\n",
    "    train_acc = sum(evaluation) / len(evaluation)\n",
    "    error = 1 - train_acc\n",
    "    \n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    acc.append(train_acc*100)\n",
    "    loss_train.append(loss_sum.data.cpu())\n",
    "    #print(acc)\n",
    "    #print(loss_train)\n",
    "    do_plot_acc_loss(acc, loss_train)\n",
    "    print(\"Epoch:\", epoch,\"lr?:\", current_lr, \"error:\", error, \" train_loss =\", loss_sum.data, \"Acc =\",train_acc*100)\n",
    "    #do_plot(loss_sum.data, error)\n",
    "    scheduler_warmup.step()\n",
    "    state = {\"state_dict\": net.state_dict(), \"epoch\": epoch}\n",
    "    save_ckpt(state, best_err > error, model_save_dir)\n",
    "    best_err = min(best_err, error)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db44b9ce-25ca-4732-8844-613139b303fb",
   "metadata": {},
   "source": [
    "### Train classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29917e18-96fd-41a3-91bf-df7fe172c35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Apply filter.\n",
      "Filtering raw data in 36 contiguous segments\n",
      "Setting up band-pass filter from 0.05 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.05\n",
      "- Lower transition bandwidth: 0.05 Hz (-6 dB cutoff frequency: 0.03 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 10561 samples (66.006 sec)\n",
      "\n",
      ">>> Create Epochs.\n",
      "Used Annotations descriptions: ['T1', 'T2']\n",
      "Not setting metadata\n",
      "540 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 540 events and 641 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[   656,      0,      1],\n",
       "        [  1968,      0,      0],\n",
       "        [  3280,      0,      0],\n",
       "        ...,\n",
       "        [707120,      0,      0],\n",
       "        [708432,      0,      1],\n",
       "        [709744,      0,      1]]),\n",
       " {'T1': 0, 'T2': 1})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# home directory + datasets folder\n",
    "#path = '/content/drive/MyDrive/MNE-eegbci-data/files/eegmmidb/'\n",
    "path = '1.0.0'\n",
    "base_url = 'https://physionet.org/files/eegmmidb/'\n",
    "# subjects = [1]\n",
    "runs = [3, 4, 7, 8, 11, 12]\n",
    "subjects = [i for i in range(80, 86)]\n",
    "\n",
    "#subjects = [i for i in range(80, 81)]\n",
    "#subjects = [1]\n",
    "# runs = [6,10,14]\n",
    "\n",
    "eeg = EEG(path, base_url, subjects, runs)\n",
    "raw=eeg.data_to_raw()\n",
    "# apply filter\n",
    "freq = (0.05, 40.)\n",
    "raw=eeg.filter(freq=freq)\n",
    "#raw=eeg.raw_ica()\n",
    "eeg.create_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a335f17-7a4a-4730-8317-f6c6e5469b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(540, 64, 641) (540,)\n",
      "(540, 64, 640)\n"
     ]
    }
   ],
   "source": [
    "X, y = eeg.get_X_y()\n",
    "\n",
    "print(X.shape, y.shape)\n",
    " \n",
    "#X = X[:, np.newaxis,:,:]\n",
    "X.shape\n",
    "\n",
    "# X2 = X[:,  7:8, :] \n",
    "# print(X2.shape)\n",
    "\n",
    "# X3= X[:,  13:14, :]\n",
    "# print(X3.shape)\n",
    "# X4 = np.concatenate((X2,X3), axis=1)\n",
    "# print(X4.shape)\n",
    "# X = X4\n",
    "X=X[:,:,:640]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "912f6a13-1368-44a6-9d76-e507f1a0fd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cfc45fd0-bee6-466c-acc6-6fc2c9afa36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('x_train64.npy')\n",
    "x_test= np.load('x_test64.npy')\n",
    "y_train= np.load('y_train64.npy')\n",
    "y_test= np.load('y_test64.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a086192e-54f6-49ba-a2df-c6aa3a78486e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4946, 64, 640) (4946,)\n"
     ]
    }
   ],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "      \n",
    "x_train = torch.tensor(x_train, dtype=torch.float).to(device)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09f07f1a-ff9b-45bc-97af-141d7050216d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAAI/CAYAAAC4QOfKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABs4ElEQVR4nO3ddZhU9eLH8c/ZoHNh6UZCugVRUERFsbtBxbp6r+0PG+uKeu3GBBs7UQkJle4G6e6GZev8/jhzJs/E2Z3d2Xi/nmefmTlzzsx3d2bnfOabhmmaAgAAQOySEl0AAACA4oYABQAA4BIBCgAAwCUCFAAAgEsEKAAAAJcIUAAAAC6lFOaT1axZ02zSpElhPiUAAECezJ49e6dpmulO9xVqgGrSpIlmzZpVmE8JAACQJ4ZhrAt3H014AAAALhGgAAAAXCJAAQAAuFSofaCcZGVlaePGjcrIyEh0UeKqXLlyatCggVJTUxNdFAAAEGcJD1AbN25U5cqV1aRJExmGkejixIVpmtq1a5c2btyopk2bJro4AAAgzhLehJeRkaEaNWqUmPAkSYZhqEaNGiWuVg0AAFgSHqAklajwZCuJvxMAALAUiQAFAABQnBCgAAAAXCJAeZx33nnq2rWr2rZtqxEjRkiSfv31V3Xp0kUdO3bUKaecIkk6ePCgrr32WrVv314dOnTQ119/nchiAwCABEj4KLyi4v3331daWpqOHDmi7t2769xzz9UNN9ygyZMnq2nTptq9e7ck6YknnlDVqlW1cOFCSdKePXsSWWwAAJAARSpAPfbjYi3ZvD+uj9mmXhU9enbbqPu98sor+vbbbyVJGzZs0IgRI9SnTx/vNARpaWmSpHHjxunzzz/3Hle9evW4lhcAABR9NOFJmjhxosaNG6epU6dq/vz56ty5szp27Og4ks40TUbYAQBQyhWpGqhYaooKwr59+1S9enVVqFBBy5Yt07Rp03T06FFNmjRJa9as8TbhpaWl6bTTTtNrr72ml156SZLVhEctFAAApQs1UJIGDBig7OxsdejQQQ8//LB69uyp9PR0jRgxQhdccIE6duyoSy+9VJL00EMPac+ePWrXrp06duyoP/74I8GlBwAAha1I1UAlStmyZTVmzBjH+84444yA25UqVdLIkSMLo1gAAKCIogYKAADAJQIUAACASwQoAAAAlwhQAAAALhGgAAAAXCJAAQAAuESAkjU1AQAAKLomLt+uwR/MkGmaiS6KJOaBAgAAxcCNo2YrMydXmTm5KpuSnOjiUAPlzzRN3XvvvWrXrp3at2+vL774QpK0ZcsW9enTR506dVK7du00ZcoU5eTkaPDgwd59X3zxxQSXHgCAkivJk1iyc6iBKnK++eYbzZs3T/Pnz9fOnTvVvXt39enTR59++qlOP/10Pfjgg8rJydHhw4c1b948bdq0SYsWLZIk7d27N7GFBwAgj0bP3KBT29RW9YplEl2UsJINQ5KUmZ2rimUTXBgVtQA1Zqi0dWF8H7NOe+mM4THt+ueff+ryyy9XcnKyateurb59+2rmzJnq3r27rrvuOmVlZem8885Tp06d1KxZM61evVr//ve/NXDgQJ122mnxLTcAAIVg+dYDuu/rBeq3uJbeuLKLyqUmvnnMSXKSFaCycnITXBILTXh+wnVM69OnjyZPnqz69evr6quv1qhRo1S9enXNnz9fJ510kl5//XUNGTKkkEsLAED+HcnKkST9sXy7Wj/8qyYs25bgEjlLSbYiS2YRCVBFqwYqxpqigtKnTx+9/fbbGjRokHbv3q3Jkyfrueee07p161S/fn3dcMMNOnTokObMmaMzzzxTZcqU0YUXXqjmzZtr8ODBCS17aXM0O0d7D2epdpVyiS4KUGxk5eRqx4GjqletvA5nZuuJn5Zq6BmtVbV8aqKLhgTK9VQe2HUIY5dsU7/WtRNYosi+nLVRd57aMtHFoAbK3/nnn68OHTqoY8eO6tevn5599lnVqVNHEydOVKdOndS5c2d9/fXXuv3227Vp0yaddNJJ6tSpkwYPHqynn3460cUvVe78Yp6O++945eYWjc6EiN3Og0d180eztT8jK9FFKXWe+nmpjh8+QXsPZ+rzGRv02Yz1em3CykQXS5L07pTV+m7upkQXo8TadzhLm/YecbwvuPVly74MbdnnvG9R8PL4ovGeLVo1UAly8OBBSZJhGHruuef03HPPBdw/aNAgDRo0KOS4OXPmFEr5EOqXhVslScSn4ueNP1bp18Vb1a1JdQ05sVnY/TbsPizDkBpUrxByn2mamrl2j7o3qS7D07HUlpNr6toPZ+rmvs10fPOacS9/cfbnPzslSTsOHFVqsvV3O5yZk8gieT3581JJ0nmd6ye4JCXTKS9M1M6DmVo7fKDmbdir1nUqe/s6BX8Pnbh8h3o9PUFrhw9MQEmLD2qgUKzlFpEJ1RA7O+9Ee+lOfPYPnfDMH473Xf7ONF3y9lSNnrVBH01dqyvfnea9b+/hTE1esUO3fuL7grNl3xEt3Lgv32UvbM/9tkx3jZ4XsC0319S4JdvyNJlgec8J83BmjncenaPZ7vuT7Dp4VD2eGqclm/e7PhaFb/ehTO08mClJ2rovQ+e9/pce+NY3YIua/LwhQKFYK4kB6q7R83TdhzMTXYwCY9cXmfmoP5y2erckafXOQ3r4+8X6659d3vuSPAkt2++k0Hv4BJ392p9hH2/rvgxNWbkjpuf+acFmHclHrU2Pp8bpg7/WaNKKHWoy9Gct2hQ+2L3+xyp9MyewWev9v9ZoyKhZ3lpYN5I8o5hyTdMbZPPyPzR55Q5tP3BUIyavCrlvy74jMf8tUTgmrdjuvb7viNV0vniTL/zmhAlQHR/7XZ9OXx+w37dzN4bd39+BjCy9NWmVZq7d7bq88zfs1fAxy9Rh2G/K9uswvvtQpvd6r6fHJ3xGcgIUijX7/+f+bxaq25NjE1uYOPlmziZNWLY9+o4JdMEbf6nJ0J/1xsR/XB/rO3HHfsyFb/6tJkN/Du3D4fAYdiDw/5CP9lw9nx6vq9+zloi44I2/dOW70/THsu1aue1AwH5z1+/RbZ/O1bAfFsde+CDbDxzVYz8u0aD3Z0iSRs/a4Or4JVusE9+hzGxXx81cu1sLNu6VZP09vE2feTgH2SHVns/Q/0R29qt/6ur3Zrh/UI+WD47R02OW5vn4RNq+P0Pfzyt6/bhy/SoZp66ymnFTkn1N30fDjGrbdyRLD33nq6n6dMZ63fnFfH0yfV3E5zNNU3d+MV/DxyzTxW9NlWQ1yf+6aIt3n50Hj+rr2Rsdjz/39b/01qRV2p+RrYNHnd/nW/ZlKCvBE2oWiQCV6BRZEBL5O70yfqWaDP05ILmXFDm5ZsDvZf+ZP5uxXjsPZuq1Cdbvnp8TXEHK9Gsu6fbkOJ3/xl8JLE3ezVm/V5L07K/LdcU709R+2G8xH2uffIePWaYmQ3/Wh3+t0dZ9GQH7ZGQF1vDMXrdHknTGS5MDQtvbk1d7r5tBwSk7hoR26Gh2wOMdzc7VnPV79dc/u3TthzN16ouTA/a3v71vzmMHW6emErcfFXaNVDXPyLmMrJyY5sW5+K2p3ueKpQbBtvtQpob9sFhNhv6sXxdZtV72a/jj/M1qMvRntXhwjHd/u6nIDf9gnJmTq7cnrY6wd97k5poBf6f1uw7rsxnrw96fF9e8P0O3fz5PBxwGSCzevE8/L/AFiNxcM+DzoCD5dxMc9uMSSVKKXRuZa0asUfV/p+w6eFSSFV4kKTsnN+S9lJtrqun9v2jc0sCpEM557U/d/LGvWf2Oz+fp7i/na/2uw95tR7NDy5GRFf5v5LR/YUp4gCpXrpx27dpVokKUaZratWuXypVLzBD7dzwnlUNFpHNoPJ36wiS1fvhX7+3g5of//b5CkvTh32sLs1gx+XbuRrV8aIxW77AGLew8eFRz1+/V878v107PB1N+bN2Xka+mpUj2Z2SFDeR/r9qlAxnZjicNR4F9vjXsxyW68aNZ3tsf/LUm4DUOLEe2nv11ueN92UHBKdJnytHsHB06mq2nxywNeLxHv48cvO1HDO64HqschzJ9NG1dxL+vP/9gmZxkaNWOg2r98K8BAUayfvdXxq8MO+oqOydXSTFWQN09ep73/+mbOVaNQVLQ72//zf2bI918gVscoRlTsn6f1yas1MY9hyPuF8lNH89WiwfHaN+RLGVk5ejs1/7U/d8s9IaYYT8uVosHx0R837z/5xot33og7P2b9lh/71zTaur1b8oc+MqfuvVTX4B46PtFavnQmJDH2HckS8/8uiwgzO09nKlnf12Wpy/Few5lOoZ0e1LKLk+O1b8+CT8gyunYNyeu0sY9h3XMg2N0xsuBXzLCja7dc9ja/u6U1Vq+9YDW77Zey12HrM++2ev2qNVDv+rPlTsDjovUxF1YATSchI/Ca9CggTZu3KgdO0pWm3m5cuXUoEGDhDx32dRkHTiarYysnBI3v8vqnYcCbh/IyHY1HP67uZuUmpykgR3qxrtoUf22yPpGtmzrATVLr+Td/uqEf7Ri2wG9fXW3sMeapqmnxyzT5T0aqWnNiiH3b9+foZ5Pj5ekAhk502HY7zq7Yz29ennnsPu0H/Z71OdevHmfY+3CAr8O3o95viHbYg2Fmdm5Sk1O8n4jzsoxtePAUaVX9q35sPPgUdWsVFbnvvaXljmcCL+I0pxmn1yT8pafwtb8dBj2uy7u2kDPXdzRW86KZXwfz29PWqWODavpxlG+oDlx+Q799o2veSUjK8c7qmrq6l16YewKvTB2heY9cqqqVQhcnmPjHl+witYHau8R3/9XZk6uNu094jjE3TRNzduw13t7/e7DAe9z0zS1cNM+tahVWeXLBM50Ha1CbMPuI/rf7yv088KtGnP7iZF3DmPsEuv/r+Njv6tyuRQdyLCahrJyclUmJUmjpq7z3DZVJiX0BTZNU4//tERlkpO04qkzHJ/D/jWWbz2g2z6dKyn8/6Pdt8g0zYBAPnzMMn02Y71a16ms7k3SVKtyWd04arZmrN2tjg2r6fS2dQIeJysnV7sOZqpOVd8X9v0ZWTJzpTnr9+jaD2fqrAifd3sPR//8fOi7hXri3HYBYcoOkiu2HdThzGwdzsxRzUplHZvV/IO/NdrS10Rrh6Bpq61+jH+tCgxQQ0bN0trhA7XjQOiXzCkrdyZ01GbCA1RqaqqaNm2a6GKUKOVSrYrFQ2HajhPF/gfYdyRLjWtUUGpy/itA7dDg5J/tB9UorYL2HM7UEz8t0XMXddQdX8yTJKUmd9VpQR9E4RzJzNHW/RmOwcUN+xuf0+sSbSj5+t2HNWLyao1bsk0T7jkp5P7tDh8u8WKf9H+cvzligIrFwFfCd+TOyTX14LehSzk98+uymB77nSmr9dK4lfrhtt7ebd2fGqdzO9Xz3u725DitHT7QMTyFcyAjS5XLWV9E7BNIcA1MsH+2H1TDtPIhK8ZHajr7es5GPXdxR01esUPXvD9Dx9at4r3v6TGhf4OPpgX2Q3n6l6U6kpWj/57fXle8M927/YZRszT6pl4B+9739QLv9Wj97fyLPHH5DvUePsFxv6wcM6CpqN/zkzT/kdNUtYL1t3v/r7V64qclSjKk1U8HhopogdQOeYdd9vuSpNU7DoY0K9rhySp3YC1GRnaOyqRYn00Hj2Zr6NcL9ODAY1WrshVQ/GfBPpCRpaHfWOEirWIZbzkvGzE15vLlmlKyYf1uW/dleJsVN+45ots/n6Calcp6a6idmoDv/XK+vpu3WSuePMNb7k6P/a5cU7qzvzXZZHBzmhRbE7ft42nrNaBtYAjzP37AS1O0fvdhfX1LL73355qQ4yPN72UHLvt/I1yg6/7UuJBtW/dnOOxZeBLehIf4mb1uj7Jycr2JflERG2Lc/alx6v7UOPV/YZIeD6pliCY313Q9Mq3/C5P02I+L9cyYZfppwRb1f2GS974bP5od8+P8+7M5Ovl/E73V57PW7nbVhyTYvV8tCGj3D2fict+JzT5hhxtynscWpZgUVj+DjXsO6/OZoTVAuw7F1qfmpXHW5HrBH+Dfz9sccNttd4G9h7MCOl9Lzif8zXuPaPrqXVq4cZ/6vzBJD35rLTS+Yfdhnff6X9p7ODNix287YF/j6Vy+dIu7/9+RU9dp9KyNIeFw5to9+mxG+Jo1/zAhWX+fGWt2+/5OMf69snND35tH/Goe7BoGp3+d5CgJyn4PuO3pkZmdq37PT9Ilb4cPNMHNQNNW+UZ0DvthsX5asEX//WWZbv449DPjk+nr9fOCLRrqCaT2Y/n/jtd/OFPTV+8KOdb2zhSrRnbQ+zPU73nfZ9Q2Tzjwb96/5ZM5umHULH00bZ3OenWKpqzcoe887+8/lm/XdR/OVG6u6X3+DZ4mT6d+RGt2HnI1Qu6q96aHfU/azXEXvjnVcXTo3PV7w77GKzwDNezPVP9+adEU4MdeTAhQxdT2AxkB1eWLNu3ThW/+rRfGrvBWI//ns7n6acFmnfnylICTxpCRs6J+Q/pn+wGtCWoui6fpa8J/oDjZdyQrTyPTpq/Z7e13Eq4/iG37/gzN9/ub2qZ42uSzckzNWrtbF701Va9NcD/6zF+f55znN/I3+ANfYLSHn2/ae0QDXpqs2z6do+ycXP3h+ZtEOwE5GTV1rQZ/MEN3fjFPL41bEXa/GWti/5B16qORkZWjySuiN9GHe3237XP3LXNPlCaJh75b5Orx7vtqgc557S/tO5zl19wV+vc+fvgEXTpimne6hK88I4zemPiP5m3Yq1FT16nHU+FrTKPVasXKqSP0sq2xh7Hv523WJW9P1bdzNyk319T8GOfPysoxQ36Hfs9P1PTVuzR+6TZvE1q4Y52MmLxKQ0bO1KWeABRp6ovRMzcEBKWMrBz9OH9z2P1twV9K7AESR7NzvK9hbq4ZUH579nb77fC75z6nWp3xy7brts/mhn3+4Z7axZlr9wRsD9e0OnbJNj383SIt2rRfN47yhbqbPpqtCcu2B/w+X4UZ5SZZwdkeIRcr/8ETN7n4EvrFrA1haxkf/8n6Mh2pKXm4Qw2sVLBfHGOR8CY85M2ZL/+pnQePetvX7VFMb05cpf7H1tK4pdbJyG6Hb3r/L3r07DZqUrOitzp3zc5DYZul+r9gdQxMSTL03uDu6tsyPWJ5xi/dpi6Nqqt6xTKO989eF/kkPGbhFp3YMl2VyqZoz6FMzV63R/3b+NZicup8GwvTNHU0zCiOISNnqkr5VL1wSSdd+8EM/bHcOsmvHT5Q17w/Q/WrldPTF3TwrQCem+v9Nrhkyz5l5eTql4VbdE7HejIMQ0/9vERz1u/V17ccL0matGKHjq1b2Vv1n595j/wD8LKtB7Rs6wFt3HNE8zbs1bMXddDmCOFw96FMzduwR/1a11Z2Tq46Pz5Ww85pq0eCOkzf0d95bSm7+SoWmTm53gU/523YqwplkjVq6lp9PG29bjv5mIjHBvd9ss1wOY9MtLD2yfTYv+FKVn8iydOvxPM6uGl9titmxkf5ApCXCS2dnP/G3yHbovUjGzJylt6+uqt+mL9J63dZ76UV2w7qExe1AdNX79K6oJrVw5k5unTENFWvEPk95FR7JUn//SXwxJntCVprdh7S7kNH1bVxmvc+/2bJs16dokWbYguNWTm5AUPl35q0St2bVNf1I339zX5euCXgmP/9vkK39WsR8/+0f/+dw5nZqlAm+qn342nR//ZHskJf14IMFfkZ6xVtyoFIAeqtSb75xlKTDb07qLsGvT8j4SsNEKCKKf9q3e37M/TEz76Tjx2eggWfoM58eYqOZOVo2RMDvJ1Pg2XnWqNfIgWovYczdf3IWerepLq+vPl4x30ufDP8N51/th/QLZ/M0YC2ddT7mBr6avZGzd+4T/MfPc3bCT47j/N9mHL+kJF8f6cXLunkDU82+yR85XGNfQEqO9fbxyAzO1dv/LFKL45boZQkq1P6O1MCm44GvT9DjdIqaPJ9J1tlifAr2PeFay5zOr/YNZD3fbUg9E4/t3w8W9PX7Na8R06VIUMHjmbr7i/nRzzGnz10uWalslH2tP4udn/l8163pmg4vnkNSdJrf/yjRmkVvNX9xc2RrBxvDYP9nliwca+OZOaoUY3Q5WYkq7nX7pjuVLsZzL/ZNp5+XBC5Jmbc0m36ddFW3fnFfG/YOZyZHTGYB4vULB6pVtA0TX0c1J8rHLsz8sn/myjJ+rIzZuEWdWhYzbvP36t2xhyeJGnz3gxv86/NPzxFkpdA0eaR33R2x3rRd8yjgpxceHEBdgt5/Y/QSVkd97uii/q2TC8Sy8zQhFfMTVi2TTd8NDvkm18s7GDx5M9LtH1/hkZ6hioHNwHMXLtHHSLM82O3+691UYYV2w6qydCf9eC3C73h6tfFW/Xw94u9TQb+HQ/zOlz10NFsTYqh+cjf3aN94eKsV//0zpdy31cLvB3f/1i+Qy96mr32HsnU9qDOjHZNxfrdh/X2pFXKzTU1Z31gFb2T4P46n81YryZDf9aOg3nvLGlXu+87Erlp66xXp6hvUNNiTq7pPTHuPHhU/Z6fqCd/Ct9/zel18m/WKa7hSbL6GNotNIZh6Pt5m3TOa3/p0hHTdPmIaY7HXOuy355TB9x4iDSXjs1+f9hhZ8W2AwU+l9zSLfv18PeLvDPL+3PqqxY82GLk32t1yydz1N+v75B/B/pYXPXedP0QQ1NfsG/nbszzEijBTYsTloVv3nTrrAgDNUqC1JSiE1uogSpGFm3ap7kb9urqno292677cJYaVC+fr8f9eNp6zVq7R8u2HlB65bKOc4Lsz8jWmxNX6ZaTmnu3vTVplU5vW0ffeuaG2XHgqK7/cKbeHdQt5nlyIjWnPPrDYp3Zvq7SK5dVZk7eOjJv2+9+dNrXcwL7Ddi1DeOXbdeg45uEPse+DPX4b2Dflql+HVGfHrNMTWtWjFgWuykguKnlfs8w9Ug1eNHYI8E27T2i9yOcoJ2+tTd/4JeA26t3HNLqHeEfw6kZyl7Atri7/5uFeunSTpKkZMPQ7Z/P894X7suDm8EG7epXSejCvsH/stNW73YMNvF0xstTwt73uENQD35/jfDMeReulrkg3flF7LW40YTr45MXwVO9FAfvTol94tTUpKIToIpOSRDVWa/+qYe/WxQya7P/nC55ZY/ciTSh2jO/LvNOarbvcJaGj1mmq9+brlf8OlSPX7bd2wkzHv7P069h35HETcng30HbHiHl7xWHDuVXvBv4LXjl9oMRn8M0rW/jjxbADOp28W/7dK5GTo2tqSSvdsRhQtBwKpdN/Pc9u69MrJ32K0Yp87vX+Ob+WrRpv3fG9UQ4mFG0pj354K+1jtsf9hsEEG1gSGEaF6GTfDQrtkX+fIinR89uow+v7R6yvXK5xP1/WXNDherXulbItq6Nqxd0cWJGgCoGPp2+Xl/6TfDnNKFYYTnr1T+Vk2vqoGc4dvAQaMnq4HntBzO0Zd8RHc7M1rpdef9GdPBott6etEoXvhnaMTZeog1rT3H5jcep2eO535xnz/aVQXH7HYeMnKWfFmzW4A9m6H+/Lfc2oe2OcTqA3xe7X6TWdoFDB+Z4SeQHvM0ewRfriLlo/6vRAlZheuqX4rH+XPD8V0XFkFGx9ZtKpNPb1taFXRt4+3L6K4qTLjuNzA2ehDWRis5/L8J6IGhywUiryheGl8at8HYoDl6zTJLu8XRQHvbDYh06mpOvJpzcXNNxEsF4avWQ87IhNrffcpduiX2SRluuacatGWLc0m3ekZYTl+9Q6zqVXR1/40ezNefhU71LzuTFtAjz3uRVpXIpUmwj6gtccDNvXuVljq2LuzbQlxGGpxcHZ7w8RXf0b5HoYhRrwy9or6HfhE48G4m92kFZhwCVVrGMtzUjNdlI+EK9Tp46v12iixCAGqgirqjNJi5ZnWntpqZIQ69Xbj+Y7/4v+V3cMxaZcX6OcEOyIzmanZuvIcKRuJl129blibG6yOUcMf6cJh3ML7uZo2Faecdv0MVRL88IRTfCvV+jNXGe3Cpd/+53TJ7mDJOkLo2q5ek4J0u37Hc1j1AiPXFe3k/aL1/WKX4FCdKuftU8H+u0CsSbV3X1Xk/3fEF+xWHlgTkPnxpwO9oUN/Hy5HntdOVxjaPvWIhi+hQyDGOtYRgLDcOYZxjGLM+2NMMwxhqGsdJzWXQaJkuQrk+OTXQRQvy9KrbahdU78t+ZMdZJ/IoSp3l4opkXwxD34uLu0fNVJg7L9ISTmyuleeZKePvqrlH2Lpp+v7OPnr2wg8qmJOurm3tFP8BPuBGp5aI0bZRLTdbdp7VSnSp5W+T85r7No+/kseyJAZ7nTHzQDe4z06lhNdUIM1+dk5ou9vV37+mtdG6n+gUyL9OzF3XI12oIwV9ARl7XQ/WrldfXtxyvt67qqms8g2VOahUajoLn9Bp5XQ/Xtdx5cVXPohWeJHc1UCebptnJNE271+NQSeNN02whabznNuJozc5DMQ0/dpKWx396+NSvlr/RjaXV13M2Rl2b738Xd1SjNOe5k2zhFo199YrO3olVOzao5rjPYIfRkkVJy9qVdUn3hpKkbk3Swu7XopZvMd77BrSSFH4+rmhNYvZJ0+7z1yTM3FXhuJkpvVxqstYOH6j3B4d2Vi5sA9sHruGWkmTof55Fm2OR135qdutBrDXLz17YIex9k+49KeD2Jd0aqmHQ/4+bmqDkoNfSPrZr4+oa0K6Obu7bXGuHD1SVcql66dJO+ntoP+++TiOs8xrmHj6rTcT7q0WZgDXR8vP14FxJIz3XR0o6L9+lKWSmaRZKE1FeuRnVceVxjQJuN6heXqnJhv5vQGtJ1hvxuYvC/4MiVGpyYtYJaFyjgnpEOKmWBBd1beAN+c+GeV/6L6bb2a/5qFFaBW+wKF8mWfMfPS3k2ODROx9ff1y+yntii/jNeBz8vxqJ/+jNW/o210uXdtIDZx4b5nEjf0Mv55nOwj7VfXpDT712ReyLQyfn4f/BbiqKZ/OfGxXLJIc0eSYnGa6+YFYsm7dOy/akkw+Geb2uDqpRubBrA8f9DEOq7VBrmFaxTMBkktEm0Bx3V5+I94dzXuf6qhfmy+QnQ6z/qyphOqDb5x8nE+7uqyt6RP5fuOHEZjGWMjFiDVCmpN8Nw5htGMaNnm21TdPcIkmey9DxhkXc02OWqcWDY5Ttmcq/qIWpgy76Pz11fvuA2W0fOauNVj51poac2FSNa1TQMxd20MXdGmrcXX018roekpw7EsIn0sSgzdOdl8CJh3W7Dqt+Puf2KmyPRPkm6cSuCWlZu7JG3xS5Gcv/3FC1fKrevKqrPhlynKqWT3Xs09OjaWAADd7nntOcl62RpCs8Acf/kNeu6BKxfG48mYc+NeVSk2QYhs7rXF/lyyRr/N19ozap3Xpy4P12TYp9ojUMqXWdKiHHObnlpOYhtRaSNPbOPvr9zvAnZv8jJt5zUkzPJSnsElNutalXRXWrBoaP1OQkdWxYTe9c0y0kQDZz+L/O62nBfsve0McXAvzfd8E1W+G6pq15eqDKpSZHDd7RarqOqRXfZraalcqq9zHWF4sUh8J/f2vvgHkDgzVLrxS1ifcczzntravi9/8XT7GeQXubptlF0hmSbjUMI+YoaxjGjYZhzDIMY9aOHe5mhC5IG3Yf9k7Cds5rf6ndo7+pxYNjElyqQG47kL96eWf9NbSf/rjnJG+zQGpykibde7JOb1tHknRMrUpqW8/60EyrWEZ3hln/rKh75Kw2uv6Epgl7fqeTdp84dqaMd8f2guZfWxSrYee0VaeG1dS6TmX1aJqmKfedrPcHWz0Egk9k/ueG1OQkVS2f6v3wtl+KMslJ3lrD4HN98O0mNSvqqfPb6TJPM5o/u8nHP4S5HeJ9bqd63jURgzk1gZxwTOQaruDms+bplXTnqb4muws61w855t7TA7/9V/LUpLx4aSf1aJKm9Eplw560/S1+7HT934DWjn15WtSuHLG/m32MKetvHiv7MW8/Je8j9ZKTDD1yVlud07GePh3iq4G0a/BObVNbbfzet58MOU5fOyxF1aFBYGftWMNdJ7/lZWz+obeMX43eMbUqBbwvgp9Tsr4kn9qmtv4VJpQ4HRNO4xoV1b2Ju27LD555rK7t3USS1bz+2x2+Jnb//89R1/VQ50bV1MrTL2rcXX1Cwrwt2oTLDdMqaO3wgRrQrm7E/RIlpgBlmuZmz+V2Sd9K6iFpm2EYdSXJc+m4iJNpmiNM0+xmmma39PSC7a2/bX+G7vpinuPQ+mAnPutbsmLJloJb3ycv9h3O0pZ9R7RwU2gH6vvPaO2t/XBq5qlfrXzUf/DqFcrozPZ19MyFHXRG+zrxKXQh6tWshq47oamGntFav/znRO9aa4XJqT9Ibxfl+PzGnhHvj2UJjVqVo69NV5C6+XXODTe5Xc1KvqaSv/z6UUhS50bV9d2tvb3rMDZMq+DtFxXy143w9bp8arIu79FQn914nD67oacu7dYw5KQe/HgpSUm68rjGGu7Q78RudsrL+ot2bUfnhtVcTfh3qt/C2bHe7z8j87W9o3+Z+NUzv9fxzWtq9M29lJKc5F3bz3ZJt8BmpNev6OKtKQm3KLf/0hovX9YpLtMTnNTaOlfkde6vn/59glb990y1b1BVhmHoeL+A2qaeLzT5z/HW+5iajouhB68TekuMnen/0y908ewUv/dlclKS97P6vtOt/m1XHtdIH19/nLdTdvDIyneu6ab7HJrFyqQk6a5TW4b8vQa0raM3ruwSUhNUJiUp7Lql4dzQp5kePbutJOsLUw3/vnh+b6Oujavr23/5/q+PqVVZN/dtrjPa1dF3t/YO+/gXdK6vCp6BEIn+bItV1ABlGEZFwzAq29clnSZpkaQfJA3y7DZI0vcFVchYPfnzUn0zd5N+i2EiwIZpzk0ks9ftydfohnjo+Pjv6vX0hJBOgpJ0+XGNNMTTLvzYuW31zIXt9brL5oXkJENvXNlVfVqm65j0SgEdbv3D13FNY++HM/qmXup9jLsgc1XP2PuC+GtZ2+r/kpqcpDb1qgR8wH19S6+wtSH5+TYbzKlj6cfTY5/gr2ezGpp070macHffgJBhi+Xk7VSGG/tE7zMwxbO4cX6d7NfPqExKki7oEloLckEX3wm5frXyuue0lhHDY3BOGn93X0lSv9a19c413fT4uW1DjjEMQ09f0EFdG6epW5M0PXNRBxmGoan39/PWthqGoWn3n6Kezaz3tH+Tw0MDj9UHns7OhiHv0kgntUrXsxd20KsOQ7n9j/U39f5TNPGek7xL/sTaTH5Nr8Zhm7j+GtpPz10U2uk5ye93MOX8fvFvWq1eIfR9VsnzHrJPWGkVy6qi32i+On7NXye2rKnLezTUH0Hl9N//3E71dYdfrbb9RcPufxWr+05vrSn3nayrezXWZd0b6sube3nLGkvfxHBD/LsFhVqnOXKTjNAaS3/H1q0SthZIsmb6vvf0VgFh6ZMhx2noGa09ZbPekynJhreJyq6teur89jqhRU3de3prXda9oWY+1D98QTxmP9RfMx/sr5TkpIBBB7Yz29eN2BcpHvzff06185XLWc3uTrVythcu7eT9v/zhthM044FT4l7OeIsl3teW9K2nqi1F0qemaf5qGMZMSaMNw7he0npJFxdcMeNn5bYDKpearA27nSdHvPDNv3Vii5p666quCZkl2H8ttJ8WbFaXRtW8S6Nc3LWBqpRL1WXdG6r/sbWVXrlsnppO/CUlGRp2Tlv1bJYmwzDUt2W6tu3PUPnUZNWoVNa7FtpxTdM0fU34dbF6NE3TiKu7qe2j4RcdDnbfgNb6eFr4tfDCOTmog/BVPRtpwrLtevmyTuraOE1jbj9RTYb+HHLcHf1b6LIeDdXr6QmunzOYUyfUcO+pm/o209uTrObiM9vX0WltrFq/xjXssBr6gZMVQ4hPTTb01lVdNHfDXr09abXqVCmnB8481ts0HU5+1060ndOxXuAM6w5FDq6pu61f5BBrhwK7yax5eiXNfqi/qlcoExAYYlG3anlvuDYMKwyU99z2P3HaX0gePPNYndCipupVK69ZD/VXWgzPef0JTb3LUNgnSP+mqvmPnqav52zUg98ucjzeZhhG2CauWEaD2sFzxNVddeNHs72h5roTmnrXlHPqj1KvWnnNfLC/KpZN1v9+W6Hb+h2jUVPXOj5H2ZRkPX1BaI1dNYdgZuvYoJpuPbm56yHoyUmG9wukXUtoz69WNiVZWTnu58eb/+hpIX1unFYZWPTY6TJNaeGmfVof1A/yr6H9VL9aebVvUFVvTFwlSep9TA399Y9vapc+LdPVPD0wyPQ+pqa3yblXsxpatGm/UpIM3XJKC13Tq3FgbY6k9MplHWtHnfgfm6jJLyv5nSud+kP5+3TIcWEnJ65Rqaz2Z2SrXGpSxPdVURH165FpmqtN0+zo+WlrmuZTnu27TNM8xTTNFp7Lgl11Mgb2y3b75/P04tgVAfdt2ntE70xerVNfnKwTn/1DHSO0F09ZuVO3RFgTriAd+4hvVuyMrFw1qF5BQzx9fRpU9zRvGIbS41zFOaBdXZ3eto7KpSarcY2KqlWlXMA3iWZ+HwhzHz5V957eSqv+e6YqlElWR8+3igpR5qG5vEdDLX18gPd2eb+ao5//c0LEjr2S1Zyw+LHTdVKrwADVr3VtLX18gM7tFFoD4s8wDNWtWl4fOKwDFc5P/z7Bu4Csv+C5UCTnSfOu6tlId5zi+736tkzXeUH9VQYfH3pyyQoz1089vxqBGhXLakC7ujq3Y+Tf259hRO93EKvgcOH00R3twzRYs5oV9eCZxwZM6lejUlnX4clbJrvDdNB2wyG03tCnmfcLSU2H57SnD/Dv0Or/t3SqsS2XmqzLujfSXafmra/hvx2agZzYzY6nta2jlU+doXkOIxPDTT6aXrmsKpRJ0SNntwk4Ed56cvOIo+cujzKCSrLeI/ee3lp1q+Y/tNtTutid4Idf0F5LHj89ZL/f7nDuolu1fKp3YW2b/Rnn3+RboUyKKpZNUc9mNbxTTdicmpZevqyzVjx5hvd2tMVu7S+AvY+pqaQkIyQ85Udw2K5eMXLfvZHX9dAoz6Ci/HjOb1qIaBO1Hn9MTV3cLbTvoSR9dH0PDTu7TbEIT1IJXsrl5fErdaffh1bv4YG1DtEmaJy8YoeaDP1ZL1zSMaAZoqCYpum4xlOtymV1/5nHqm618q6GP8fbRV0b6LMZVm1R9YpldOvJ1gf7kscH+E5ShqHXr+iimWt368O/14Y8xgNnHhuwjpH9od+genm1rVdVbetV1Y4DR8MueFuhTHLYWkE36yNF+kZ/34BWem3CPzrsqQlsV7+q2tWvqju+mBewn9PJyGleI0OGUvyaHIL7U0hWrcz/fg8M/OFmM6/g+f2v693U2zHT/lZtV6NXLpfiuEahZH37DTaoV+Owf/NyqUneE9fa4QMDavaSDUM/3naC9hy21thz6vju1DwZiWEYAaOW8ssOdf6dmfP8WJ73eedG1dW3Zbo27LFqJ16/oosmr9gRtnkiOcnQf05pofb1q6pWFXcny2g1zPMeOVU/L9wS0K/HaZZpSerZNLYm9kZpFbRs6wHddnKLsGHbf/h8YSuTkqTDmTmqWj5VFcoEfh7c2b+lt/NyLLwBKsamVqeRiHawTq9cVjsOHA34f3dyfPOaBfb3e+aiDurdoqauOq6RRk1dp4vCTI1gi9cs4jUrlY3L79SgegUNjqE/X1FRogJU8Hs719MMkhNlfOdP/z5BZ73qvL7cXaPna8yirXrHb9X0gvDulDWOi3mu2nFQyUlGQkecSVbHwIu7NtBah4WB/T9kB3aoq4Ed6noD1IC2dbydV+0Pu89v7OmtQQv+p6sT4ZtqvGb0Dfcw8x85TVUrpOrw0Ry99sc/AVMVvH5FF936qVUreW6neo41GE59TOpXLx9QC1Mpxmbhm/s218y1oYuT2o90SfcG3m+u9t+1bT2rVjVcZ1/JufP7Q2e1Ubv6VTX0m4Uh/f/s23az39U9G3uDflKS1N6vJtcpmF7dq4mG/bgkbHkKWtOaFTV3/V5VLpf/Cfnsmo+UJMM7FYjke89HE9z07OTbfx0fMJN99yjzgVWrUCbq/E8/3NZbSYYRcy3eR9cfp7nr9xTIoq01K5XVzoPhJ1m9uW/zqH1Y7zq1pSqUSdGAdoEDYEZe18N1ILDf37EGKP+/4ac3HBdQs2YH7GgBqiBVLZ/qnV9qUBGfTLYkKFETAfUOGgrc5tFf1eyBXyJOT/DHPSepXf2qesKhc6ptrIsJLSMxTVP7M7Ic7wu3Enq4SfMS4bmLO8Y8csNuavrXyc313EUd1Kp2Ze+3vZ7NaoT0EbBd27uJXry0o2pWKhsytLtzw/isFmRHhFqVy+qj630nQnuiwOM9neH9m0n9c8cdYaZ+CO7D8tZVXXXDic1kGIa3diL4G7OT09vW1inH1g4Ilz/edoIm33uyHjqrjepUKafGab7nqlO1nN71m9Mm0hQI9rfz0Tf1UpnkJL1xZRelJifp4m4NQ2pQ6lYt5+18ajdxPHFeu7DLYNx9WktVCRoFlNd11+LlqfPa64PB3dWydlCtRB6KZTdVF+Q6fJ0b+d7ja4cPjEtTfYcG1Vytm5ZeuaxOa1tQo3NDv8z6jxwbekbrkE7qNvut1LB6BV3UtYH3i9vfQ/vphhObqk8eJjutViFVDdPK67/nt3d97PHNawYMurG/e7iZsR3FW4kKUMHt9dGWQUlOMrz/AIWxSOH7f61Vh2G/h+1AF6xjg6pqEfzBX0z8ff8pWjt8oDo0qKaLuzXUbxEm2/NXLjVZ53duoFkP9dfzl/ja1Xs0SVPVPEzrb4+W8e+DYldIVquQqhNb+L6x2jVF9rdS/w6m/jPxOvXrme4ZMeIf+ga0q+MNEPaiy9FqoDo2qKq7T2vlvW2PGmvfoKoa1aigvi3TNe2BU0JqB/q3qR1TOLMDUY+maVrx1Bk602+Zi/cHd9cPt/mGGU+9/xRd06uJujauHtCh1Q4QwR1Wy6Yk65RjIw/HL2zlyyQH1PzYU5zkZRLZ167oom//dXxcarNKoliCpf2/9/QFvsDy5/9Z01tEm37ln6fO1KdDjgupyatXrbweHNgmT337UpOTNOW+fiG1WcFimWPJroEiQJUeJaoJz+0bd9r9vmGS/lWz39/aW+e+/lfAvjsOHM33t8FfF22RJP2xbHtMo1I27oktaBWkWQ/1j2lerYJQu0o5ta1XRYs379cJLr9dfjLkOP20YIvuG9A6ZN6U3DAfdPZJ1Z7Lxw4vUuCkeGWDRvI0qVHBu9RCuOUUMrOtv2H5Ms4nmb+G9lPZlKSQdc7eG9RdW/ZlOB6TF5FOclXLp6pDg2oa2L6utymkTEpSyISQI67upnf/XO24KK1/7deIIrjQ7+PnttNrE/5Rt8bul8qpVDYloIYIPlPuOzmmUcvvDuqmUVPXBUzimJpsaOI9JznOweQvKSlwPqfC9MmQ47QjyvqO7w3uro+mrlM1l5OuovgqUQGqkotJ12pVLhs2ELV3qO7u/tQ4SdbIj8tiGH3ixK7ZeOi7RSqTkqTjm9fwjqzzt/zJAbrl4zkhc8wkQriFSwvL5zf21BM/LfHOgBsr/2HDwcKFHPsb7DG1KmviPSeFdAq3O1QHD9l9d5BvVF+mp6YpeISSXQMVPArIFq5je8WyKTrGYW6XgvT6lZHnFWvfoKpevsx5biQ7kr57TTf1jzI5ZCK0rF1Zr0SY16mo6BhhvpyiyGnOOiedG1UPCaEpSUmuZilPhMrlUqPWPHZpVF1dCNiuPXthhwJtFi9IJSpA1aoc+o3YyaR7Q0+OkrTyqTN0ICNbSUmGLu3WUF/M2hCyz9BvFuY5QPmPjLrvqwWSAjvl2sqmJBeJVcyLgsrlUvWswySC+WHG0FfB6QP9km4NNWrquoBJAR85u01AwDm1TW3NWrcnZEqG8zvX16sT/nG1iGlx9OjZbVW/Wnmd1MrXNPr1Lb20ZMuBBJaqeJn/6Gmlap3K4nryRHwETxVRnJSoABWrRmkVHNvLU5OTvCe4/17QXinJhj6ZHjrRY7cnx8o0rWYXp2Hp4ew+lBmyzWnqAhQsO0DZb4Ff/nNiTMv5DDu7rR4481glJRk6tU1tfTRtXUhT0I19munqXo0dh1f/66RjCmRkU6zCrUcVT+meaTf8dW2cpq55aDIrrdyuu1dcnd+5vr6duynRxQDyrNQEqDIpSd7mlVg6GyYnGXrq/Pa67oSmOuX5SQH37TxoBaH1uw+Hju4JIysnV7scAhQKnz1fkl0D1aZelYB5dMJJSjJULskKQH1apjvOe2IYhmNn7qQkI6HhKZHz9gBOXry0k164JL61y0BhKnF1p/Z6UsEzjS9/YoD+c0qLgJmcYxFuuL0kHTpqNcld/+FMbx8pJ1k5uVGX10DhyQ2qgSqpBravq57N0mKaowhIhHjNig8kQomrgWpSs2LAt+3LR0xTn5bpMgxDd53aMk9LKkx/4BQd99/xIdvvGj1fF3Sur/HLtkuSvpy1QS1qVw4YsbXnUKY6PzHW/S+CAuM/c3pJFq0zOAAg70pcgAr2WYSV32NVu0o5fXlzL1381tSA7Wt2HtLzfmvu3evpGD77of4ql5qsict3eGevjkXHhtV0rmd1bhQce8bwzsVspFOsWtWurOXb6LQNAAXJMKMscxJP3bp1M2fNCl2eojjxXwsskuoVUrXncOis4z/edoJGTFmtH+dvlmStaF+7Slm9M2WNpt7fLy6LbiK6xZv3qWXtymHXDSvO9mdkaeeBowELQAMA3DMMY7Zpmo5ruZX4Gqh4a1O3SkwjtpzCkyS1q19Fz13UQae2qa2xS7Z5O1Fe1bMx4akQ2evGlURVyqWqCrNlA0CBKnlfvwvYW1d11b/7HZPn4w3DULnUZJ3TsZ5evbyzUpKTlJKcpMY1ivZEcgAAwIcA5VKjGhV092mt1LI2zSMAAJRWNOHlUcPqFbRi20FJ0tkd63n7NDlZ/d8zNXfDXh3JTMyacgAAIL6ogcoje/mOT4ccp1ejrK2VlGSoa+PqrhfEBQAARRMBKo/uPq2V3rqqi3o1ryFJGnZ2G3VsUFXf39o7YL9rejVORPEAAEABogkvj8qkJGlAO98Mz4N7N9Xg3k21/UCGd9unQ45TtyasAQYAQElDgIqz9EpldXKrdJ3Xub6OP4YmOwAASiICVJwZhqEPru2R6GIAAIACRB8oAAAAlwhQAAAALhGgAAAAXCJAAQAAuESAAgAAcIkABQAA4BIBCgAAwCUCFAAAgEsEKAAAAJcIUAAAAC4RoAAAAFwiQAEAALhEgAIAAHCJAAUAAOASAQoAAMAlAhQAAIBLBCgAAACXCFAAAAAuEaAAAABcIkABAAC4RIACAABwiQAFAADgEgEKAADAJQIUAACASwQoAAAAlwhQAAAALhGgAAAAXCJAAQAAuESAAgAAcIkABQAA4BIBCgAAwCUCFAAAgEsEKAAAAJcIUAAAAC4RoAAAAFwiQAEAALhEgAIAAHCJAAUAAOASAQoAAMAlAhQAAIBLBCgAAACXCFAAAAAuEaAAAABcIkABAAC4RIACAABwiQAFAADgEgEKAADAJQIUAACASwQoAAAAlwhQAAAALhGgAAAAXCJAAQAAuESAAgAAcIkABQAA4BIBCgAAwCUCFAAAgEsEKAAAAJcIUAAAAC4RoAAAAFwiQAEAALhEgAIAAHCJAAUAAOASAQoAAMAlAhQAAIBLBCgAAACXCFAAAAAuEaAAAABcIkABAAC4RIACAABwKeYAZRhGsmEYcw3D+MlzO80wjLGGYaz0XFYvuGICAAAUHW5qoG6XtNTv9lBJ403TbCFpvOc2AABAiRdTgDIMo4GkgZLe9dt8rqSRnusjJZ0X15IBAAAUUbHWQL0k6T5JuX7bapumuUWSPJe14ls0AACAoilqgDIM4yxJ203TnJ2XJzAM40bDMGYZhjFrx44deXkIAACAIiWWGqjeks4xDGOtpM8l9TMM42NJ2wzDqCtJnsvtTgebpjnCNM1upml2S09Pj1OxAQAAEidqgDJN837TNBuYptlE0mWSJpimeZWkHyQN8uw2SNL3BVZKAACAIiQ/80ANl3SqYRgrJZ3quQ0AAFDipbjZ2TTNiZImeq7vknRK/IsEAABQtDETOQAAgEsEKAAAAJcIUAAAAC4RoAAAAFwiQAEAALhEgAIAAHCJAAUAAOASAQoAAMAlAhQAAIBLBCgAAACXCFAAAAAuEaAAAABcIkABAAC4RIACAABwiQAFAADgEgEKAADAJQIUAACASwQoAAAAlwhQAAAALhGgAAAAXCJAAQAAuESAAgAAcIkABQAA4BIBCgAAwCUCFAAAgEsEKAAAAJcIUAAAAC4RoAAAAFwiQAEAALhEgAIAAHCJAAUAAOASAQoAAMAlAhQAAIBLBCgAAACXCFAAAAAuEaAAAABcIkABAAC4RIACAABwiQAFAADgEgEKAADAJQIUAACASwQoAAAAlwhQAAAALhGgAAAAXCJAAQAAuESAAgAAcIkABQAA4BIBCgAAwCUCFAAAgEsEKAAAAJcIUAAAAC4RoAAAAFwiQAEAALhEgAIAAHCJAAUAAOASAQoAAMAlAhQAAIBLBCgAAACXCFAAAAAuEaAAAABcIkABAAC4RIACAABwiQAFAADgEgEKAADAJQIUAACASwQoAAAAlwhQAAAALhGgAAAAXCJAAQAAuESAAgAAcIkABQAA4BIBCgAAwCUCFAAAgEsEKAAAAJcIUAAAAC4RoAAAAFwiQAEAALhEgAIAAHCJAAUAAOASAQoAAMAlAhQAAIBLBCgAAACXCFAAAAAuEaAAAABcIkABAAC4RIACAABwiQAFAADgEgEKAADAJQIUAACASwQoAAAAlwhQAAAALkUNUIZhlDMMY4ZhGPMNw1hsGMZjnu1phmGMNQxjpeeyesEXFwAAIPFiqYE6KqmfaZodJXWSNMAwjJ6Shkoab5pmC0njPbcBAABKvKgByrQc9NxM9fyYks6VNNKzfaSk8wqigAAAAEVNTH2gDMNINgxjnqTtksaapjldUm3TNLdIkueyVoGVEgAAoAiJKUCZppljmmYnSQ0k9TAMo12sT2AYxo2GYcwyDGPWjh078lhMAACAosPVKDzTNPdKmihpgKRthmHUlSTP5fYwx4wwTbObaZrd0tPT81daAACAIiCWUXjphmFU81wvL6m/pGWSfpA0yLPbIEnfF1AZAQAAipSUGPapK2mkYRjJsgLXaNM0fzIMY6qk0YZhXC9pvaSLC7CcAAAARUbUAGWa5gJJnR2275J0SkEUCgAAoChjJnIAAACXCFAAAAAuEaAAAABcIkABAAC4RIACAABwiQAFAADgEgEKAADAJQIUAACASwQoAAAAlwhQAAAALhGgAAAAXCJAAQAAuESAAgAAcIkABQAA4BIBCgAAwCUCFAAAgEsEKAAAAJcIUAAAAC4RoAAAAFwiQAEAALhEgAIAAHCJAAUAAOASAQoAAMAlAhQAAIBLBCgAAACXCFAAAAAuEaAAAABcIkABAAC4RIACAABwiQAFAADgEgEKAADAJQIUAACASwQoAAAAlwhQAAAALhGgAAAAXCJAAQAAuESAAgAAcIkABQAA4BIBCgAAwCUCFAAAgEsEKAAAAJcIUAAAAC4RoAAAAFwiQAEAALhEgAIAAHCJAAUAAOASAQoAAMAlAhQAAIBLBCgAAACXCFAAAAAuEaAAAABcIkABAAC4RIACAABwiQAFAADgEgEKAADAJQIUAACASwQoAAAAlwhQAAAALhGgAAAAXCJAAQAAuESAAgAAcIkABQAA4BIBCgAAwCUCFAAAgEsEKAAAAJcIUAAAAC4RoAAAAFwiQAEAALhEgAIAAHCJAAUAAOASAQoAAMAlAhQAAIBLBCgAAACXCFAAAAAuEaAAAABcIkABAAC4RIACAABwiQAFAADgEgEKAADAJQIUAACASwQoAAAAlwhQAAAALhGgAAAAXCJAAQAAuESAAgAAcIkABQAA4BIBCgAAwCUCFAAAgEsEKAAAAJcIUAAAAC4RoAAAAFyKGqAMw2hoGMYfhmEsNQxjsWEYt3u2pxmGMdYwjJWey+oFX1wAAIDEi6UGKlvS3aZpHiupp6RbDcNoI2mopPGmabaQNN5zGwAAoMSLGqBM09ximuYcz/UDkpZKqi/pXEkjPbuNlHReAZURAACgSHHVB8owjCaSOkuaLqm2aZpbJCtkSaoV99IBAAAUQTEHKMMwKkn6WtIdpmnud3HcjYZhzDIMY9aOHTvyUkYAAIAiJaYAZRhGqqzw9Ilpmt94Nm8zDKOu5/66krY7HWua5gjTNLuZptktPT09HmUGAABIqFhG4RmS3pO01DTNF/zu+kHSIM/1QZK+j3/xAAAAip6UGPbpLelqSQsNw5jn2faApOGSRhuGcb2k9ZIuLpASAgAAFDFRA5Rpmn9KMsLcfUp8iwMAAFD0MRM5AACASwQoAAAAlwhQAAAALhGgAAAAXCJAAQAAuESAAgAAcIkABQAAfHYslxZ+lehSFHmxTKQJAABKi9d7WJftL0psOYo4aqAAAABcIkABAAC4RIACAABwiQAFAEB+7FknTX0j0aUofDnZ0rYlodt3r5HG/J+Umxv7Yy3+Ttq6MG5FKwwEKAAA8uOj86Tf7pcO7Sr45zp6UMrOLPjnicUfT0pv9rJG7fn76lpp+lvS1vnhjz16UBreSPpnvHX7y0HSWycUXFkLAAEKAID8yNhnXZoualzy6un60sizQ7dnH5WmvBDfcGWavutH9kq7VgXev3GWdXlgi2/b9qXS5rm+278+IL3TL/Sxdyy3/m4TnohbcQsb0xgAAJAvRnwfbuNs6yHrd3W+f8O00G1TX5fGPyallJV63RqfcpimZHh+t/dOlXaukIbt892flGxd5ub4tr3R03f9vdOkHE+gO3pAKlvZuj7hSSnriHXdKL71OMW35AAAFJScbGnicOvEX9je7eertcnJktb+FRhSnGQeCryMB9PvOXeuCL0/yVMHE67mLcevNizDL3hNfk6a+prnRpzDZyGiBgoAgGCLvpYmPi0d3iWd+Vz8Hnf1RKl8mlS3g29bxn5p3wapTEWpehPf9mFVfdcvHinV6xz+ce2aIv9mt7zYNMd33SkY5eZKSUnS0h+lf8Z5tmVLX1wlVagR/fF/uTfwtuEQoLIypP2bpBrNYy93AlADBQBAsOwM6zLrsIuDIoSXnCwrnIw6V3r7RCs0Hdhq3ffJRdKbx0svd5T2b3Y+fs9a6eUOzvdJvqYwO/Qs+lo6uMNF2T3eOdl33SlA2X+XL67ybcvNsQLV7A/DP25utjTzPWnGiMDtphl63Pf/kl7tYtWmzXgnsPaqCCFAAQCQH3YtyvIxVq3R/i2h+/z+UGA4ebO39Hwr6/qG6b7tTsdK0rhHoxXCc2laowG/uk763zHRy75jufRKF+uY4Noru9lwywLftgMO5TOjNC/aj/XzXaHbN82Sfrw9cNuqCdbl+CekX+6Rfrkv+uMnAAEKAFByrfjd6kPkllPTUjSz3rMuX2gd+pz+I9Mkad966/L14wK3Zx+J7bmOHpCO7LGu52RLcz+yrs/9RMo5Gv343Fzpj6etde92r5JWjAmtcbJvv32ib9tr3UMfa8oLMTxfdvR9JCuA2r/X9DetywWfu5tTqpAQoAAAhS83V5r0XPzmTpr3mXXyzcqQvrtVmu5pKvr0YunDM90/Xri+RJmHpRfbW6PegmuLkvy6Fc/92Lpc8bvVlOZfy+Rvx7LA2yt+i618TzeQnmkiLfvZahbbv8navn+jtH6q8zE7/7GaDVf8Lj1VR5o03Hff97dKayYF7u/UhOdU27RlXvTyTn09+j6RrPszf8cXADqRAwAK39op1kSMWxdIl36U/8eb8KR1uesfad7H1k9yauA+f78mLftJGjBcKlNJqhlDE1fwKLEdy6zao98ekH5/WHp0t9+uyb7ryalW351PLw7sGB7N36/Evq9k9T2a/1ngthnv+K5PeUE60dN09lqYaRFsvz8SeDvc6LrgjuCxCC6jW7v+sYJin3ulOh3yVkMYZ9RAAQAKnz3E/eD28B2nY2WaVs2LJL3V27f9pzsC9/n9Qat2ZkTf6GHCtnOl1UfIrm1K8gtJZo7V0fmQp7O2/5xGc0ZatVWS1QG8oDgFE/8aqAlPWLN9790Q/bF2rw68HS5ABXcEj0VOPif4/OlOKyy+3ceaXyq/ow3jgAAFAKXZit+sJTRyYuyj8tYJ0isRhtM7ycmW1gdN/mifADdMk144NvpjLPnBWi8t+HE/vlD69f7ox391XfR9sjOtNdz8mxU3TLP6CP3xlDUFwdt9Ao/55kbf9aSgRp2Vv0d/zoJWqY708QXSu/2j75sVNIfU5nnSE+kFUqx82ThDWvBFoktBEx4AlGqfXmJdHtkjVYrhZOm04OuX11q1HPf+I6WUCb1/0nBr8sQT7pT63CftWBpau/Hbg9KpjwfW8PgbfbV12WS1tGulVLWBdGinNReRPR9RJIu/ib7P0h+sNdyO7JUaHx94X06WNQVBsGU/+a4H9w+yO0Mn0gFP7d7Bre6P/eTC+JYlng5uS3QJqIECgFLLv9YpP00si7+Rju6TngwKYLk51mg0e8HYP1+U/lvXmmU7uAZh6mvhOz/7e66Z9P7p0ott498PZtUf1uWCz6Uf/xN43/Ix0Y8PLv+6PIz+Q2yW/5roEhCgAKBEyM60anEO74683+Z5Vm2KJOVm+bb7X1/0jbXfvo3hH+e3B61RYB+eFX6fSc9aI+A2zwm9z7FGyG0gymeA8h8af2Cb1fE8nKN5mMyxKDThlVTr//b1MUsQmvAAoKhZ/K1UprLUIoZ+K5I1TN6eNDHzkHT2S6H77FlrTRsw72OpbifppkmBHXH9a6O+utZ3/eGdoaPZJN9aZmunOJdp1ypp26LYym+b+a7V16hcVWvh2QVfSKc9KR3/b+f93zvV3eMHWz9VauLpdD6maE7WiAi2LZIa9kjY0xOgAKCo+XKwdTksxlqPiU/73QgzOunTS31zDm2ZJ62fLtXy67y9ZqI1meK8TwOPy8l0DlCR7N1gLcXhllOt1LS3wgcoe1mRvFr+iy9ALfkuf4+FwmeE6S9XSGjCAwC3Vo6zaljyY8XvvqHxh3dbk0AGjzLLi2RPJ+4tCwInLwyesPH906ThDX23f77bWm5k+5LA/XKy5MqwqtK2xe6OicTMlZZ8H7/H8zf1NWnbEmnT7IJ5fBSsBE8FRYACADf2brBGJ73aJXp/o0g+vdjXBGWHm6+vD9xnWFVpwegYHsyv1im5jLXcxtsnWpM95ldOlvTDv6Wvh8R+zGeX5v95bZkHpdHXxO/xgr3Zy+rUXhyVqZzoEiRWbgxr8BUgAhQAONm3UVo9KXT7D7f5rj93jKevj6fWZt6nvusxPYdnckN7SL/TemFzRsX+eJLV3LZzhbtjIjmw2SrDwi+ld/PZ5ygvju4v/OcsLgb/KB13S6JL4V6VBvF5nFjX1ysgBCgAxc/qSVbtzDunFNxzvH6cNOqc0O3ZfsP9zRyrJurNXlaH7O9usa4HN2NlHpb2rPPdDl4YNdKsyqZpNcct+NJ67idqWeu+hTt+UQzzHbnhP3HkxhnxfezS5rbZsfdrC+dffmvq1esstXF4jxam/o+5P+ZfU6W7lub/uamBAgCX7FmlN83K2/Erx0pb5kfeJ/Ng4G3TtD6ww9XurP4j6PZE3/UvB0kvd/AFp1/u8d23b6M00m8qgE8uDnreXKs57psh1sSMOUelsQ8H7nPAb1HbvetUal2b+LmBIoq09l7Hy33XI9XQBM92XiOW9fzi5F/TQrfV62yFQqdgWKe9NPAFqd1FgdvLVZGq1Av/PDdNti6THSZl9ee0sHEhIkABKH7yO4HiJxdZNSvBzWMHdwTWMEnWEiKStYDq42nS4Z3OjznlhcDb/v2P7KbAWe9ZTXyz3vPd9/6AwOOC5w5a/7fDk/n9/rk50ooIwcE0rXXESoMEDmnPE/+1885/SzrpfmnIeCnJb3vvOwKPSQo6bVeqlf9yXPS+1Oyk6PtVqi1dHuMSKhXTpSu+lLpfL130nnTPSmu7/8i5W8PUaFaoaV3Wbhv5OaiBAgCXjDh9dP0QNDz+f8dY64b5G321FYBmvqOIws2HJEkpZa3LX+6xmvj87YthkVfb9Dety0PbfdseT4t8zOhrpFnvx/4cxVm4ZWAKklOtzCUO/daqNvJdv3eVdOF70ol3B+5z0lCpQTff+/u636VTHg3cx83Q/XNejW2/dhdK13wvdbtOqt9N+s9c3+/wn3m+/SqkWUvoRHPjJGtZnyp1fdsq1bL+Vnf6NW2nt5KGTLCu1+0oXTFaqt3eCmpXfyddFaU5Otxix4WEAAUg/haMtvrt5MW+jdYCt5H4B6iMCH1KVv1hrdPm30doT5gmLnuftVMCm98kaW6EGaoj+fNFa7qCeC058ueLvutTnpemvRn9mKU/xOe5i4tbZxbu86WUk055JHBbG4c18/xP9hVrSu0vCg1QtgHPWIsA1+0YWuOUnCpVa2QFHds9/wTuc9H70gXvSJ2uCn3s1p7m4oY9pYd2BDa9nfWidMN4Ka2Z9TsM2yelNQ08vk67wNsVHAJ8vU7Ov1etYwNDleSrTDWSpJanS7f8KSWnSM1Pdn5sSTr5IesywTVQTKQJIP6+ucG6dNNhdvUkqX5X6e2+VjOZfeyPt1v9lW6c6NvXP0BFmqfoo/OsywtGWP2eWp0hzf0ocJ/so1JSauBor+BFYxfGMpWAg3HD8nZcLMY/XnCPXdjKVonfaLv0lvF5nEjuWirtXmNNYFq1odUPyFY+zEnfqbYktbzzvq0GSK2Wh27v/5jVd+iOoAWd/ReBjvY/V9HTPNbxUueFn90Y9JPVzyk/vF9uwnzJGPCMNPlZ6fAu37YWp0p/PEkfKADQvk3WiLdvbwrtYzT7Q2nz3MB992/y3Q7XGTzLb5bqqa9Jn19uLZEy+bnA/Z6sZTXlBc/AjYKRXCZ0BNbNEZo/Y3Wjw5QT8XLyg4G3q9SzZjAf/JOntqSf1MUzV1XzMHNKhWtuOu2pwC8HkZxwR/j7ut8gpTgEsltnSLc49aNz4dKPrdopW1Kq1ONGqemJgfs16iWlHytXynrmsqoZJvj2vFm6yfP+SC4j3TDB11RLDRSAUi/Lsyjodr8Ta25uaPOFJL3YJvD2xxdID++yTmT+juzxXd+z1ro8uM35+ed9bPW9QMG7fqwVQAY+Lx3YKvV7KPYJSTtdKc37RPr3HGnd34FzcoVrNpKk80dIvz8oHdoRezk7Xi5VrmM1m5avHn3/hj2tQQn2sjenPm7NEXbsOdbEq9UbOx93/G3O2/31e0ja+U/kfQb+z/oJlt4q8HbzU6wvJXU7RX9e27FnB95+JMxAiuvyMAoyvZV05VdS497h96la3wpxDXtatW32XGsJroEiQAHIm5nvST/fJT2wRSpTwdqWfTS0/1As7CY5/2/pudlSkl8Tw7hh0gl3OR9/YLPVLyTgMf2aBOZ/bl3+OjR8GbYtDH8f8qfPvVYgyc7wjazq7jezeblqUodLrWDl388r2NkvS71vl2o0t36mvSltj7JszPH/tpqrmvWVnm8VeV9//R+TKteW+g+Tdq6Mvn+upynZnmag9+2++y771Dr551Wfe/N+bLA250j3b5LKVorfY+ZXixgmaPUPceWrSx2vCOyYnwA04QHIG3vYvn+T29hHpE8viXzcoZ1SRpj+LnvW+K7nZlkTUtr+fDFw7TZ/LznUHq2a4Lue30VnkXfXj7VqUGo0Dz8sPSnJ6qfW7sLIj5WcGlijcpInEA+ZELjfJaOsJi3JGk4vWbVJLT1TRlz+efjn6H6DdMtUKzzZaraQHt0buWx2XzynhZdbD5Qq1oh8fGEqSuEpL6rUlc5/U2rQNaHFIEABcGffJmt0m7fWyG+EW/AkkzlZ0vQRUo7fkgvPNbeC0EG/5hSnUWp5WcT2Mb8OvN8VwyUuipLqTcP3K3Iaph/2cZrEvm+d9tYQ+gbdQ+/z76hta3OO1Wk6+ETa5lzpjGeks1+Ret7q237FF9b+rc6QugxyLsMZz0i124RuNwyp1ZnSZZ+F3if5lhVJcghQKJFowgNKmwPbpOdbWv0OYqk6t21ZYIWmUedatU52k5nd7Hb0oLQxaGbwqa95RqKZ1vBp//5LY+6TLv5A2jxP2uXQvyP7qItfysPMsQJdXpoRIVWuZzWH3r1cqlDDqk2pVEc6uDVwP3uI+4Gt1t/7hdbW9h43SjNGBO7rds6utGYKGZHV5rzY5zSyJSVLXcOEJEkqVzXwdvk06b7VkaecuDxMeJIi10AVBee9FTgYA/lGgAJKG/tDdMYI5wCVm2M1zx13k7XkgiTtXm0tJxLAc6L58wXp2HOl6W+FDkWf4Zl8cvXE0KUbFn9jnVwXfeVczrxO/jjhSWmKQ2faoqh+V2nT7MJ/3sG/WB2qv/QEjHNek7pcbXXmPrTTau6ydbhY+jtMeLH3u+43SYa0wKFpLE+TnvrVava5V+r7fwUQTILWHzymf3zm60opl//HKAidLrd+EDcEKKC0sU8S4RawXfK9NcfKijHWyd1IDjPaxXP8nFGhS6LY7OkGlv8irXEYqh4uPEnSpOHh74ukuIQnyZrVOZ4BqnrTwH5kTrpdbw3Bl6QvPdu6XG1dVkgLP3lhJI08HaSD59iSfE1bbpzzqvSG5zGPu6VganWa9/MFw963S6cMy9/jdR8i7d8snVBKls0BAQoofexv2WEClD2lgH1iDzdUeO96d0+becDd/qVBvJeiqN/VF6Auet+36LLtlr8DO3Jf/a209s/Ij9llUPgaqGBO8/LY8/y4UetYd5Ow5oX/fE2nxmFS0jIVpDPyGPpRLNGJHCgtjuyRnm0mrfF0DDZN6al61mK2U16Qpr3l2Z7Y9aWKvWgryNuu/jZ8LWBe+S8p0upMT38ij/s3ho6Ca94vdBmSYDVbSBe867t99ivh9219ZuDtHjeGn227qDimf6JLgGKKAAUUd9mZ0qKvw5+M/3xR+vluq4P34V1Wx25JWjVeyjokrZ8qjX9M+vX/rIn/jh4svLIXdYN+dH/M/60N3Valfui25v18r1m360ODzNXfupv/59G9gZM1ppa3RrTZ8lITZDvmFGvQwM1/Ru6YfezZ0sM7rQEKklTLYTRbUTJ0Q+QpDYAIaMIDioPdq6WD262+JrM+kLbMsyYVlKQ/npL+ekkqU9lqbtu/Wep+ve9Yez02ew6cSF7tEueCF3N1Ozpvb9rXV5MXrEzF0G13LQmc08pm1/bV62QtBWKvb3f3cquDdvN+oUvPpFbwNbPa0pr5+rad+7q1Pputx03572dVIS10/bVwklOtwQk3Tgr/9ysq7EESQB5QAwUUZUf2WDVMr3SW3j/d2vbTHdZSDK945sX56yXfvp9dZs0O7nSyhnvh5vSp28F5+7Uul7JYNd66zAjq7+M/Cu7khwIXqL1pcujjVPOreep8lTXrtu3MZ6UbxrsrVzzU6xSfUW1AEUWAAgpL8EkyFs80sUKRbYffCu27V/vWhJIU0in8gzMDg9TKse6fv7Sp3sRawsMWbvRXn/ukf023Zq2uVEe6fb41NUDjXu6eLyfTutyzLvw+fe8NbMqr2UK69BPf7cu/sObTAlCoCFBAfmQeljIPRd9v7sfS8EaBAShWq/xqD17vEXjfm34n7OA+UOv+Crw94233z10S+HekjqTtBVYQOuEO6d7V0h2LrAB13ptW89XJD1r7nXiP1fRTq7W1eOs9y63g1STCYqiS1HWwdWkkS8llrev2kPcUz+1b/pauHRN6bI8bgzb4vdatBsS22C2AuKIPFJAfwxta89xEG3K93HNS3LHMt5bXvE+lX+6V7ltjTQlQ8xgp64j0VB1rFuh7V7krS0kfPdfpSmneJ9H38/fAZqtP0o4V0usOy4MM2+dZKNaw/v62ijUkedYu63SFdWn3bXLq4xRs0E/SyLOs641PsC7Pekka+IKv1kmSKtS0Lu3XLtxacckp0pn/8y1nktY88BJAoSNAAfkRPElgVoa0a6W1ppdt9URp2U+hx/56v5R5UBr7sDWL960zfDVMh3dZAcuVOA+Jj5eu10qz89nEdO7rUruL3AWou1f4wk56S+mRPdLqP6SPL7C23TLVuqzZIrbH63GjFX56/iv6vk1PDA3VhmHVPiX5DetvOUD6/UGp/UUxPP8Nvuu120j3rPQtlAug0NGEB8TTyx2kt06w1gizjTrXd337MmnBaOt6kuf7y3TP/Ev7NgQ+1vcxnKj9FbU+Tn2HWpdtz4/9mHAr3jc5QUr1WyJjwDO+6/0ecj6mcu3A20lJ1nB8m9OCsZEkp1pNbnZzWzzUPMYKWvXzsKp8pVp00gYSiBooIF5mfygd3GZdX/unc63CxP9alzWa+wKUbd+m/D3/ku/yd3y8nXy/dOJd7gJHuEBgr6d2yUfWNA09b7b6IaW3yv/fDQDygBoowI29662JJnf+I70UNJT9x9t917++Xvrs8vDTCbzTL3SF+x//E9+y5lVyHmtYrvtduvC9wG3hwpORHFtTmGQ1h1ZrZF1vc44VniSrb1L9rta2Op7Xwu6U3fmq8I9nPxYA5AM1UEAkWxdasyknJVu3X2ov1etidebdG2HouWQtoFucPLjVmnCxfFrg6L4mJ0prPQsBd7pSys6wZj4/6yVrTirJGrVWsYaUFePEiUaSr0N0sHtXSc/5dY7udVv0x7vZb6Hi/sOi7PtX6ESUAOASNVAofXZHWa3etmW+1Z/pj6ek+Z9L73rWzNo8RyEdtu0ZpIuz1PJWX6OylQK328uQnPWidN4bviH1/jObV/SMWLObJYNnPa/nmeHcHqKfWkFqf7G11MgJd1nbqnpqhirWlNpf4vf89fL+OzkpVyVwokoAyANqoFC6rJ5odeq+4B2pwyVSbq70amfppAekjpcG7rt/s3U55fnQxwmeFNNpn6LuzsXSiw7D5qs2tGp9sg5b81zZtW/2rNyNeoaftiE5RbpttlQ1aO23a8dI2Ud8C+12u9bq75TWzJpfKSlFOt6vpsnu89R1sNS0T55/RQAoKAQolC72zN2b5ngCVLa0Z6014i04QIVbnFeymrCKs45XSFUbON9nGNLpT/lub11kzWPV4rTYHtt/PiVbajnfKLoHtkgpfiPqklOkfg8G7n/aE1aIGjA8tucEgEJGEx5KF3vCwuDRXsHzORVlx5wa+76pFazLGkGhJrhz9/0bwz9GnXbS/60JnRZAsvobXfFl7OWRpDIVrCkFIqlUSzr/TatZEQCKIGqgULp4A1SSdHC7VMavv8+6v63AUa+TNH2EtGNpQooY1vH/kU593Ap/waP7TnnEah77PWhOpDsWWk2RdTsEHhMcoMpWzluZ7FFvAFDKEKBQynia5fZtlP7XwhphZ/vgDOuy/cXSQpe1KvF07huhk2hWrmc1a4Vz3C3S3I8Ct7U93+qQXbFm6P7lquW7mABQmtGEh5JnyQ/SxGec77NroPZ5mqy2LwndJ5HhSZI6Xxl4u/VZ0t1BtWGpQeuxpZSVcnN8ty/+0Prxd80PvuvH/9u6PO4WqRIj0gDALQIUSp7RV/tm/A620NP5e/OcwitPXthD+yXnxWvvXGQ1z9mSkn2L3kqSHGb0btZXemi7dZw9VcEZw6V7lselyABQmhCgUHJlZ1q1Mmsm+7Zt84QOuyaqqPLvW+Q0Eq1CmjWj9on3+LaVr2ZNQnnczVLrgc6Pm1KWmbgBIA4MM9JQ7Tjr1q2bOWvWrEJ7PpRSdmfpY/pL66ZKWYekq76RPr4gcWX6v7XW+ngTh0vbFkmNjpfW/+28rz3H0qFdViiy52ECABQqwzBmm6bZzek+aqBQcv0zzgpPkjWPUSKVry4de7Y0ZLzU/BRp4P+c96tYy+96DcITABRRBCiUDEf2RL5/5jvxfb4mJzpvv3OxdEuYmiXJmkzy6m+k2n4zgJ/+tDV7d+120jmvxLecAIACQYBC8bdtsfRME+nvV63FcAvD4J+knrcGbrtxojW7d22H5VGcNDlRqtJA6vUva/buW/6SWp0R96ICAOKPeaBQ/M0ZZV0GTyJZENpd6FsYd8B/pbVTpK0LrNv1Oofuf+tMKWOv82MN/qlAiggAKHgEKBRv66ZK098qvOfrcZPU6Djf7Rv+kL6+Tjrl0cD9rv7OWiA3vWXhlQ0AUGhowkPxdXB7+Pme8qv3Hb7rHfwWGW7YI3C/5BTpklFSjeaB25ufLDUN008KAFDsUQOF4mPZL1LzftZcRoZhLcVSUOq0ty6Ty0jnvy1VbyK1vyR0EWIAQKlEgELxMOcj6YfbfLcv+qDgnqtOe6uvU8V0Ka2pFZpOfqDgng8AUOzQhIeiLfOwtPCrwPAkSV9dm/fH7H6D73pw36Vh+6Sb/7RCU7O+zNoNAHBEgELRkJUh5Tosr/LbA9LX18f3uc541ne9wyXSrTPi+/gAgBKPAIXEM03pqdrSiD6B29dMkWbHuanOrl2ypZST0lvF9zkAACUefaCQePZ6jFsXSh9dIG2YIeUcjX1CSjdSylkBauh6a9LNijWt7eWqWpNaAgAQAwIUEs/M8V1fNd53ffPc+Dz+tb9KHwywrhueStdyVa0Rfbah6+PzXACAUoEmPCTG5nnS369Z13NzIu6aJxVqWiP1Ol4uNe4l3TZL6nWblNYs/s8FACh1qIFCYozoa122PlM6sC3vj9PkRGs5lWB9/09qd4H1I0k1W0inP5X35wEAwA81UCg82UelMf8n7Vnn2/ZKZ1/zWl5c9Y3v+iUfSe0vtq5Xb5z3xwQAIApqoFA4dv4jvdbVur4hn9MGnPaU9PuD1vWUMr7tbc6RWp8ldR8iNeqZv+cAACACaqBQMPaskzbM9N3+7hbf9c1z8vfYx98W/r6kJMITAKDAUQOFgvFyB+ty2D7rciOTVQIASg5qoFDw5n6S92OvHSM1PyX6fvW75v05AABwiRooxF/WEd/1YVXz91iNj/ddb3WmZHqWe7n6O2viTUl6ZE/+ngMAAJcIUIi/L/Ox0K+tfjfppKGeG56ZyrtdL7Xob11vfrL1I1n9ngAAKERRzzyGYbxvGMZ2wzAW+W1LMwxjrGEYKz2X1Qu2mCg2crKllb/l7zHSmkkXvSe1ONW6PfB5qc15UtMT8108AADiIZav7h9KCp6oZ6ik8aZptpA03nMbpd3qidITNXzNbHlx/VjpP3Ol6k1829KaSZeMlFLK5reEAADERdQAZZrmZEm7gzafK2mk5/pISefFt1gollaOzfuxDT1TDzTsEZ+yAABQgPLaB6q2aZpbJMk0zS2GYdSKY5lQnORkSUkp0t710tTX8vYYNVtK1/0qmWZ8ywYAQAEp8E7khmHcKOlGSWrUqFFBPx0Ky5snSBVrWM12na6U5uVxqoJTn7BmDjcM6wcAgGIgr8OXthmGUVeSPJfbw+1omuYI0zS7mabZLT09PY9PhyJn20IrPEnRw9PAF6S250vJnmVX+j/muy+tqVSmQoEUEQCAgpLXAPWDpEGe64MkfR+f4qDI27tB+u5f7o7pdp108YdWZ3BJanGa9OBW6awXrbXrAAAoZqI24RmG8ZmkkyTVNAxjo6RHJQ2XNNowjOslrZd0cUEWEkXIz3e7n6bAbppL8nu7pZa3ghUAAMVQ1ABlmublYe6KYX0NlDix9lM64zlpzL2B2y4ZJc18V0pvHf9yAQBQiJiJHNF9cbVUvrqUsU/aMj/6/n2HSj1uCA1QNZpLA54umDICAFCICFCILCdLWvqDu2NOvr9gygIAQBFBgEJkn16a92M7X20tAAwAQAlDgIKzBV9Kk4ZLu/6Jvu9Nk6Ul30tTng/cfm4eJ9YEAKCII0Ah0IrfpSp1pW+GxLb//ZukspWkuh2lirWkBt0KtnwAABQBBCgE+tTljBRlK/mu97w5vmUBAKCIyutEmoDUckCiSwAAQEIQoOBOz1uty2YnS1d8kdiyAACQIDThwZ26HaX/zJUq10t0SQAASBgCFHw2zQ5/X/ch0sFtUodLYp+NHACAEooAVdrlZEv7N0oV06V3+oXfr2kfqc25hVcuAACKMAJUaff19dKS76LvV79rgRcFAIDigk7kpdHRg9KwqtKsD5zDU70u0h2LpEd2S7XbSxd9IFVtUOjFBACgqKIGqrTJzZW2L7Wu/3SH8z7H3SxVa2hdv+XPQikWAADFCTVQpc2U56X3+oe/v1xVqeXphVceAACKIWqgSpul30e+f+j6wikHAADFGDVQpc3WheHvSz+28MoBAEAxRoCCpXY76bJPEl0KAACKBZrwSovso9LKsc733TpTSm9ZuOUBAKAYI0CVFt/eJC3+1vk+whMAAK7QhFdaLPvZefvgXwq3HAAAlAAEqNLgsyuknMzAbZVqS0PGS016J6ZMAAAUYzThlXRbF0nLHWqfbpjA7OIAAOQRNVAl3ahzQred/jThCQCAfCBAlXSHd4Vua9yr8MsBAEAJQhNeSXVkj/T3q6HbT7pfqtup0IsDAEBJQoAqqd47Xdq5PHDbyQ9Jfe9NTHkAAChBaMIrqYLD07FnE54AAIgTAlRJtPavwNtNTpT6P5aYsgAAUALRhFfSrP1L+vDMwG2Df0pMWQAAKKGogSppfn8o8HbfoYkpBwAAJRgBqqTZPCfwdhKVjAAAxBsBqqSr3znRJQAAoMQhQJVkV4yWjumf6FIAAFDiEKBKkq2LAm+3PD0x5QAAoIQjQJUkb/VOdAkAACgVCFAlxYLRgbfvXJyYcgAAUAoQoEqKb27wXb99vlS1QeLKAgBACUeAKgn2bQq8Xb1JQooBAEBpQYAqCT46z3e9+SkJKwYAAKUFAaq4W/CltHOFdb3ZydIlIxNbHgAASgGmqS7uvhniu37ll1JyauLKAgBAKUENVElx0fuEJwAACgkBqjjL2O+73u7CxJUDAIBShgBVnA1vmOgSAABQKhGgiqujBxNdAgAASi0CVHH10x2+62nNElYMAABKIwJUcbXwS+uy3UXSf+YmtiwAAJQyBKjiaPL/fNcvei9x5QAAoJQiQBVHE55IdAkAACjVCFDFzc5/fNdpugMAICEIUMVJ9lHpta6+23QeBwAgIQhQxcnHfpNlXkjfJwAAEoUAVVws/lZaO8W63vIMqf1FiS0PAAClGAGqODiwVfpysO/2FZ8nrCgAAIAAVfTNGSU938p3+9G9CSsKAACwpCS6AHBw9ID02eW+JjvbWS9KhpGYMgEAAC8CVKKZpnW5cqz0yz3S3nXO+w3+RWrSu/DKBQAAwiJA5YcdfuxaIdP0bcvJlLIOSxl7peSy0vJfpF3/SDtXSKsmWPskpUq5WZGf48L36DAOAEARU7IC1LKfpVkfSJkHrZ8dy6WaraSkJOnQLqlCmrRtsZTeyrqvTnvJSLJ+so5YgefIbqlyXevx9qyVsjOkmi2lrAzrMctVkbIzrWCUddjar0IN6fAu9+UNF57uWiZVqZuXvwAAACgEJStAZR6WDu+UylSSKtSUappSSlkpY5+UlCylVrDCUtkqUnpr67YkpZaTKteRkstIB7dJ5atb+1dMt0JUrTZSUorVN6lMBSmlvLWfTGnXKiuI7V5jBaKD26znbt7Peu4je60AN2eUVLud1GWQ1PxkqWoDqwYquWS9BAAAlAaGaTc5FYJu3bqZs2bNKrTnAwAAyCvDMGabptnN6T6mMQAAAHCJAAUAAOASAQoAAMAlAhQAAIBLBCgAAACXCFAAAAAuEaAAAABcIkABAAC4RIACAABwiQAFAADgEgEKAADAJQIUAACASwQoAAAAlwhQAAAALhGgAAAAXCJAAQAAuESAAgAAcIkABQAA4BIBCgAAwCUCFAAAgEsEKAAAAJcIUAAAAC4RoAAAAFwyTNMsvCczjB2S1hXw09SUtLOAnwMFg9eu+OK1K5543YovXrvC0dg0zXSnOwo1QBUGwzBmmabZLdHlgHu8dsUXr13xxOtWfPHaJR5NeAAAAC4RoAAAAFwqiQFqRKILgDzjtSu+eO2KJ1634ovXLsFKXB8oAACAglYSa6AAAAAKVIkKUIZhDDAMY7lhGP8YhjE00eUp7QzDeN8wjO2GYSzy25ZmGMZYwzBWei6r+913v+e1W24Yxul+27sahrHQc98rhmEYhf27lDaGYTQ0DOMPwzCWGoax2DCM2z3bef2KMMMwyhmGMcMwjPme1+0xz3Zet2LCMIxkwzDmGobxk+c2r10RVWIClGEYyZJel3SGpDaSLjcMo01iS1XqfShpQNC2oZLGm6bZQtJ4z215XqvLJLX1HPOG5zWVpDcl3Siphecn+DERf9mS7jZN81hJPSXd6nmNeP2KtqOS+pmm2VFSJ0kDDMPoKV634uR2SUv9bvPaFVElJkBJ6iHpH9M0V5ummSnpc0nnJrhMpZppmpMl7Q7afK6kkZ7rIyWd57f9c9M0j5qmuUbSP5J6GIZRV1IV0zSnmlaHvVF+x6CAmKa5xTTNOZ7rB2R9oNcXr1+RZloOem6men5M8boVC4ZhNJA0UNK7fpt57YqokhSg6kva4Hd7o2cbipbapmlukayTtKRanu3hXr/6nuvB21FIDMNoIqmzpOni9SvyPE1A8yRtlzTWNE1et+LjJUn3Scr128ZrV0SVpADl1MbLEMPiI9zrx+uaQIZhVJL0taQ7TNPcH2lXh228fglgmmaOaZqdJDWQVSPRLsLuvG5FhGEYZ0nabprm7FgPcdjGa1eISlKA2iipod/tBpI2J6gsCG+bp4pZnsvtnu3hXr+NnuvB21HADMNIlRWePjFN8xvPZl6/YsI0zb2SJsrq/8LrVvT1lnSOYRhrZXVB6WcYxsfitSuySlKAmimphWEYTQ3DKCOrc90PCS4TQv0gaZDn+iBJ3/ttv8wwjLKGYTSV1fFxhqfK+oBhGD09I0mu8TsGBcTzt35P0lLTNF/wu4vXrwgzDCPdMIxqnuvlJfWXtEy8bkWeaZr3m6bZwDTNJrLOXxNM07xKvHZFVkqiCxAvpmlmG4Zxm6TfJCVLet80zcUJLlapZhjGZ5JOklTTMIyNkh6VNFzSaMMwrpe0XtLFkmSa5mLDMEZLWiJrBNitpmnmeB7qFlkj+spLGuP5QcHqLelqSQs9/Wkk6QHx+hV1dSWN9IzGSpI02jTNnwzDmCpet+KK/7kiipnIAQAAXCpJTXgAAACFggAFAADgEgEKAADAJQIUAACASwQoAAAAlwhQAAAALhGgAAAAXCJAAQAAuPT/2s3GFUb+EJYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss = tensor(15.4999, device='cuda:1') val_acc = 51.53229608675153\n",
      "Epoch: 4584 lr: 0.019140583972485498  train_loss = tensor(0.0069, device='cuda:1')  train_acc = 0.9995956328346138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4585, loss = 0.00:  70%|███████   | 7/10 [00:01<00:00,  4.61it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_463/1538003768.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mloss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0miter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             F.sgd(params_with_grad,\n\u001b[0m\u001b[1;32m    137\u001b[0m                   \u001b[0md_p_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                   \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = resnet18(classification=True).to(device)\n",
    "#net = nn.DataParallel(net)\n",
    "checkpoint = torch.load(os.path.join(model_save_dir,'best_w.pth'))\n",
    "#checkpoint = torch.load(os.path.join(\"logs/resnet17_05170339\",'best_w.pth'))\n",
    "net.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.0000000001, momentum=0.9, weight_decay=0.0000000001)\n",
    "\n",
    "epochs_t = 15000\n",
    "\n",
    "lr_schduler = CosineAnnealingLR(optimizer, T_max=epochs_t - 10, eta_min=0.09)#default =0.07\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=10, after_scheduler=lr_schduler)\n",
    "optimizer.zero_grad()\n",
    "optimizer.step()\n",
    "scheduler_warmup.step()\n",
    "\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "val_acc_list = []\n",
    "loss_list = []\n",
    "acc_plot = []\n",
    "n_train_samples = x_train.shape[0]\n",
    "iter_per_epoch = n_train_samples // batch_size + 1\n",
    "best_acc = -1\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs_t):\n",
    "    net.train()\n",
    "    loss_sum = 0\n",
    "    evaluation = []\n",
    "    iter = 0\n",
    "    with tqdm.tqdm(total=iter_per_epoch) as pbar:\n",
    "        for X, y in train_iter:\n",
    "            #print(\"X shape : {}\".format(X.shape))\n",
    "            output = net(X)\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            evaluation.append((predicted == y).tolist())\n",
    "            optimizer.zero_grad()\n",
    "            l = criterion(output, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += l\n",
    "            iter += 1\n",
    "            pbar.set_description(\"Epoch %d, loss = %.2f\" % (epoch, l.data))\n",
    "            pbar.update(1)\n",
    "    evaluation = [item for sublist in evaluation for item in sublist]\n",
    "    train_acc = sum(evaluation) / len(evaluation)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    scheduler_warmup.step()\n",
    "    #scheduler_warmup.step()\n",
    "    val_loss = 0\n",
    "    evaluation = []\n",
    "    pred_v = []\n",
    "    true_v = []\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for X, y in test_iter:\n",
    "            output = net(X)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            evaluation.append((predicted == y).tolist())\n",
    "            l = criterion(output, y)\n",
    "            val_loss += l\n",
    "            pred_v.append(predicted.tolist())\n",
    "            true_v.append(y.tolist())\n",
    "    evaluation = [item for sublist in evaluation for item in sublist]\n",
    "    pred_v = [item for sublist in pred_v for item in sublist]\n",
    "    true_v = [item for sublist in true_v for item in sublist]\n",
    "\n",
    "    running_acc = sum(evaluation)*100 / len(evaluation)\n",
    "    val_acc_list.append(running_acc)\n",
    "    loss_list.append(val_loss.cpu())\n",
    "    do_plot_acc_loss(val_acc_list, loss_list)\n",
    "    print(\"val_loss =\", val_loss, \"val_acc =\", running_acc)\n",
    "    print(\"Epoch:\", epoch,\"lr:\", current_lr,\" train_loss =\", loss_sum.data, \" train_acc =\", train_acc)\n",
    "\n",
    "    state = {\"state_dict\": net.state_dict(), \"epoch\": epoch}\n",
    "    save_ckpt(state, best_acc < running_acc, model_save_dir, 'best_cls.pth')\n",
    "    best_acc = max(best_acc, running_acc)\n",
    "\n",
    "print(\"Highest acc:\", max(val_acc_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3126f035-0257-4933-9893-21eb7550ca1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbe8263-2b0f-473e-b4e1-1c1f57502866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a06601-f3d9-406b-b31e-a3e80f6abaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(classification=True).to(device)\n",
    "checkpoint = torch.load(os.path.join(model_save_dir,'best_cls.pth'))\n",
    "model.load_state_dict(checkpoint['state_dict'], strict=True)\n",
    "epoch_b = checkpoint['epoch']\n",
    "# model.train()\n",
    "model.eval()\n",
    "val_loss = 0\n",
    "evaluation = []\n",
    "pred_v = []\n",
    "true_v = []\n",
    "with torch.no_grad():\n",
    "    for X, y in test_iter:\n",
    "        output = model(X)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        evaluation.append((predicted == y).tolist())\n",
    "        l = criterion(output, y)\n",
    "        val_loss += l\n",
    "        pred_v.append(predicted.tolist())\n",
    "        true_v.append(y.tolist())\n",
    "evaluation = [item for sublist in evaluation for item in sublist]\n",
    "pred_v = [item for sublist in pred_v for item in sublist]\n",
    "true_v = [item for sublist in true_v for item in sublist]\n",
    "\n",
    "highest_acc = sum(evaluation) / len(evaluation)\n",
    "print(\"epoch=\" , epoch_b, \"val_acc =\", highest_acc)\n",
    "def calculate_all_prediction(confMatrix):\n",
    "    '''\n",
    "    计算总精度：对角线上所有值除以总数\n",
    "    '''\n",
    "    total_sum = confMatrix.sum()\n",
    "    correct_sum = (np.diag(confMatrix)).sum()\n",
    "    prediction = round(100 * float(correct_sum) / float(total_sum), 2)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def calculate_label_prediction(confMatrix, labelidx):\n",
    "    '''\n",
    "    计算某一个类标预测精度：该类被预测正确的数除以该类的总数\n",
    "    '''\n",
    "    label_total_sum = confMatrix.sum(axis=0)[labelidx]\n",
    "    label_correct_sum = confMatrix[labelidx][labelidx]\n",
    "    prediction = 0\n",
    "    if label_total_sum != 0:\n",
    "        prediction = round(100 * float(label_correct_sum) / float(label_total_sum), 2)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def calculate_label_recall(confMatrix, labelidx):\n",
    "    '''\n",
    "    计算某一个类标的召回率：\n",
    "    '''\n",
    "    label_total_sum = confMatrix.sum(axis=1)[labelidx]\n",
    "    label_correct_sum = confMatrix[labelidx][labelidx]\n",
    "    recall = 0\n",
    "    if label_total_sum != 0:\n",
    "        recall = round(100 * float(label_correct_sum) / float(label_total_sum), 2)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def calculate_f1(prediction, recall):\n",
    "    if (prediction + recall) == 0:\n",
    "        return 0\n",
    "    return round(2 * prediction * recall / (prediction + recall), 2)\n",
    "\n",
    "cm = confusion_matrix(true_v, pred_v)\n",
    "f1_macro = f1_score(true_v, pred_v, average='macro')\n",
    "\n",
    "i=0\n",
    "f1 = []\n",
    "for i in range(5):\n",
    "    r = calculate_label_recall(cm,i)\n",
    "    p = calculate_label_prediction(cm,i)\n",
    "    f = calculate_f1(p,r)\n",
    "    f1.append(f)\n",
    "\n",
    "\n",
    "log_templete[\"acc\"] = '{:.3%}'.format(highest_acc)\n",
    "log_templete[\"epoch\"] = epoch_b\n",
    "\n",
    "\n",
    "log_templete[\"cm\"] = str(cm)\n",
    "log_templete[\"f1\"] = str(f1_macro)\n",
    "log_templete[\"per F1\"] = str(f1)\n",
    "log = log_templete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49149ca0-806f-4288-ad69-b7859cf8744c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
