{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f5c784b-e99a-40e1-9453-a7d754508a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#comment this if you are not using puffer?\n",
    "os.environ['http_proxy'] = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148b7e57-a8b7-4695-ad8e-775cb0fe0e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mne\n",
      "  Downloading mne-1.0.3-py3-none-any.whl (7.5 MB)\n",
      "     |████████████████████████████████| 7.5 MB 1.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.9/site-packages (from mne) (1.21.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from mne) (21.3)\n",
      "Collecting pooch>=1.5\n",
      "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "     |████████████████████████████████| 56 kB 2.4 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from mne) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from mne) (3.0.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from mne) (4.62.3)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from mne) (5.1.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from mne) (3.5.1)\n",
      "Collecting appdirs>=1.3.0\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from pooch>=1.5->mne) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->mne) (3.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->mne) (2.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (4.28.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->mne) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.10)\n",
      "Installing collected packages: appdirs, pooch, mne\n",
      "Successfully installed appdirs-1.4.4 mne-1.0.3 pooch-1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a06ff5a-770e-490f-8b8a-2341de2d96f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "     |████████████████████████████████| 60.5 MB 52.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from opencv-python) (1.21.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.64\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c352b33-cc7e-47b9-bb02-cc55034373c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting warmup-scheduler\n",
      "  Downloading warmup_scheduler-0.3.tar.gz (2.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: warmup-scheduler\n",
      "  Building wheel for warmup-scheduler (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for warmup-scheduler: filename=warmup_scheduler-0.3-py3-none-any.whl size=2983 sha256=5e22b29a7614b1b90993d49a0b9a972c507c1d5f13d87d5d4fbb383ac8456dcc\n",
      "  Stored in directory: /home/st122148/.cache/pip/wheels/a0/ac/20/d906225888dae79c4e45a06a155207b311486f479f2b8cacba\n",
      "Successfully built warmup-scheduler\n",
      "Installing collected packages: warmup-scheduler\n",
      "Successfully installed warmup-scheduler-0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install warmup-scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3fe08b-8f7c-4439-a50a-06ac2d537926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import os\n",
    "import sys\n",
    "from mne.datasets import eegbci\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from mne.datasets import eegbci\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4a67bea-12f3-413f-a6ba-9c00854fe16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from net import resnet18, resnet34, resnet50, resnet101, resnet152\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import tqdm\n",
    "import mit_utils as utils\n",
    "# import analytics\n",
    "import time\n",
    "import os, shutil\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import random\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24c5c92a-1dfe-458f-84ae-861d039e98c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG:\n",
    "    def __init__(self, path, base_url, subjects, runs):\n",
    "        self.subpath = ''\n",
    "        self.path = path\n",
    "        self.base_url = base_url\n",
    "        self.subjects = subjects\n",
    "        self.runs = runs\n",
    "        \n",
    "        # download data if does not exist in path.\n",
    "        # self.load_data()\n",
    "        self.data_to_raw()\n",
    "    \n",
    "    def load_data(self):\n",
    "        print(f\">>> Start download from: {self.base_url}.\")\n",
    "        print(f\"Downloading files to: {self.path}.\")\n",
    "        for subject in self.subjects:\n",
    "            eegbci.load_data(subject,self.runs,path=self.path,base_url=self.base_url)\n",
    "        print(\"Done.\")\n",
    "    \n",
    "    \n",
    "        \n",
    "        print(\"Done.\")\n",
    "        return self.raw\n",
    "    def filter(self, freq):\n",
    "        raw = self.raw\n",
    "        low, high = freq\n",
    "        print(f\">>> Apply filter.\")\n",
    "        self.raw.filter(low, high, fir_design='firwin', verbose=20)\n",
    "        return  raw\n",
    "    def raw_ica(self):\n",
    "        raw = self.raw\n",
    "        ica = mne.preprocessing.ICA(n_components=64, max_iter=100)\n",
    "        ica.fit(raw)\n",
    "        ica.exclude = [1, 2]  # details on how we picked these are omitted here\n",
    "        ica.plot_properties(raw, picks=ica.exclude)\n",
    "        ica.apply(raw)\n",
    "        print('ICA DONE ????')\n",
    "        return  raw\n",
    "        \n",
    "    def get_events(self):\n",
    "        event_id = dict(T1=0, T2=1) # the events we want to extract\n",
    "        events, event_id = mne.events_from_annotations(self.raw, event_id=event_id)\n",
    "        return events, event_id\n",
    "    \n",
    "    def get_epochs(self, events, event_id):\n",
    "        picks = mne.pick_types(self.raw.info, eeg=True, exclude='bads')\n",
    "        tmin = 0\n",
    "        tmax = 4\n",
    "        epochs = mne.Epochs(self.raw, events, event_id, tmin, tmax, proj=True, \n",
    "                            picks=picks, baseline=None, preload=True)\n",
    "        return epochs\n",
    "    \n",
    "    def create_epochs(self):\n",
    "        print(\">>> Create Epochs.\")\n",
    "        events, event_id = self.get_events()\n",
    "        self.epochs = self.get_epochs(events, event_id)\n",
    "        return events , event_id\n",
    "        \n",
    "        print(\"Done.\")\n",
    "    \n",
    "    def get_X_y(self):\n",
    "        if self.epochs is None:\n",
    "            events , event_id=self.create_epochs()\n",
    "        self.X = self.epochs.get_data()\n",
    "        self.y = self.epochs.events[:, -1]\n",
    "        return self.X, self.y\n",
    "    \n",
    "    \n",
    "    def data_to_raw(self):\n",
    "        fullpath = os.path.join(self.path, *self.subpath.split(sep='/'))\n",
    "        #print(f\">>> Extract all subjects from: {fullpath}.\")\n",
    "        extension = \"edf\"\n",
    "        raws = []\n",
    "        count = 1\n",
    "        for i, subject in enumerate(self.subjects):\n",
    "            sname = f\"S{str(subject).zfill(3)}\".upper()\n",
    "            \n",
    "            for j, run in enumerate(self.runs):\n",
    "                rname = f\"{sname}R{str(run).zfill(2)}\".upper()\n",
    "                path_file = os.path.join(fullpath, sname, f'{rname}.{extension}')\n",
    "                #print(path_file)\n",
    "                #print(f\"Loading file #{count}/{len(self.subjects)*len(self.runs)}: {f'{rname}.{extension}'}\")\n",
    "                raw = mne.io.read_raw_edf( path_file , preload=True, verbose='WARNING' )\n",
    "                raws.append(raw)\n",
    "                count += 1\n",
    "\n",
    "        raw = mne.io.concatenate_raws(raws)\n",
    "        eegbci.standardize(raw)\n",
    "        montage = mne.channels.make_standard_montage('standard_1005')\n",
    "        raw.set_montage(montage)\n",
    "        self.raw = raw\n",
    "        \n",
    "        \n",
    "        \n",
    "def do_plot(train_loss, valid_loss):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(train_loss, label='train_loss')\n",
    "    plt.plot(valid_loss, label='valid_loss')\n",
    "    plt.title('loss {}'.format(iter))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e1694-ae3c-4a9f-9ab9-19fa54692d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba306842-10d9-4f07-ac2f-f2a39c09f12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def save_ckpt(state, is_best, model_save_dir, message='best_w.pth'):\n",
    "    current_w = os.path.join(model_save_dir, 'latest_w.pth')\n",
    "    best_w = os.path.join(model_save_dir, message)\n",
    "    torch.save(state, current_w)\n",
    "    if is_best: shutil.copyfile(current_w, best_w)\n",
    "\n",
    "def transform(x, mode):\n",
    "    x_ = x.cpu().numpy()\n",
    "\n",
    "    Trans = Transform()\n",
    "    if mode == 'time_warp':\n",
    "        pieces = random.randint(5,20)\n",
    "        stretch = random.uniform(1.5,4)\n",
    "        squeeze = random.uniform(0.25,0.67)\n",
    "        x_ = Trans.time_warp(x_, 100, pieces, stretch, squeeze)\n",
    "    elif mode == 'noise':\n",
    "        factor = random.uniform(10,20)\n",
    "        x_ = Trans.add_noise_with_SNR(x_,factor)\n",
    "    elif mode == 'scale':\n",
    "        x_ = Trans.scaled(x_,[0.3,3])\n",
    "    elif mode == 'negate':\n",
    "        x_ = Trans.negate(x_)\n",
    "    elif mode == 'hor_flip':\n",
    "        x_ = Trans.hor_filp(x_)\n",
    "        \n",
    "    elif mode == 'permute':\n",
    "        pieces = random.randint(5,20)\n",
    "        x_ = Trans.permute(x_,pieces)\n",
    "        \n",
    "    elif mode == 'cutout_resize':\n",
    "        pieces = random.randint(5, 20)\n",
    "        x_ = Trans.cutout_resize(x_, pieces)\n",
    "    elif mode == 'cutout_zero':\n",
    "        pieces = random.randint(5, 20)\n",
    "        x_ = Trans.cutout_zero(x_, pieces)\n",
    "    elif mode == 'crop_resize':\n",
    "        size = random.uniform(0.25,0.75)\n",
    "        x_ = Trans.crop_resize(x_, size)\n",
    "    elif mode == 'move_avg':\n",
    "        n = random.randint(3, 10)\n",
    "        x_ = Trans.move_avg(x_,n, mode=\"same\")\n",
    "    #     to test\n",
    "    elif mode == 'lowpass':\n",
    "        order = random.randint(3, 10)\n",
    "        cutoff = random.uniform(5,20)\n",
    "        x_ = Trans.lowpass_filter(x_, order, [cutoff])\n",
    "    elif mode == 'highpass':\n",
    "        order = random.randint(3, 10)\n",
    "        cutoff = random.uniform(5, 10)\n",
    "        x_ = Trans.highpass_filter(x_, order, [cutoff])\n",
    "    elif mode == 'bandpass':\n",
    "        order = random.randint(3, 10)\n",
    "        cutoff_l = random.uniform(1, 5)\n",
    "        cutoff_h = random.uniform(20, 40)\n",
    "        cutoff = [cutoff_l, cutoff_h]\n",
    "        x_ = Trans.bandpass_filter(x_, order, cutoff)\n",
    "\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "\n",
    "    x_ = x_.copy()\n",
    "    x_ = x_[:,None,:]\n",
    "    return x_\n",
    "\n",
    "def comtrast_loss(x, criterion):\n",
    "    LARGE_NUM = 1e9\n",
    "    temperature = 0.1\n",
    "    x = F.normalize(x, dim=-1)\n",
    "\n",
    "    num = int(x.shape[0] / 2)\n",
    "    hidden1, hidden2 = torch.split(x, num)\n",
    "\n",
    "\n",
    "    hidden1_large = hidden1\n",
    "    hidden2_large = hidden2\n",
    "    labels = torch.arange(0,num).to(device)\n",
    "    masks = F.one_hot(torch.arange(0,num), num).to(device)\n",
    "\n",
    "\n",
    "    logits_aa = torch.matmul(hidden1, hidden1_large.T) / temperature\n",
    "    logits_aa = logits_aa - masks * LARGE_NUM\n",
    "    logits_bb = torch.matmul(hidden2, hidden2_large.T) / temperature\n",
    "    logits_bb = logits_bb - masks * LARGE_NUM\n",
    "    logits_ab = torch.matmul(hidden1, hidden2_large.T) / temperature\n",
    "    logits_ba = torch.matmul(hidden2, hidden1_large.T) / temperature\n",
    "    # print(labels)\n",
    "    #\n",
    "    # print(torch.cat([logits_ab, logits_aa], 1).shape)\n",
    "\n",
    "    loss_a = criterion(torch.cat([logits_ab, logits_aa], 1),\n",
    "        labels)\n",
    "    loss_b = criterion(torch.cat([logits_ba, logits_bb], 1),\n",
    "        labels)\n",
    "    loss = torch.mean(loss_a + loss_b)\n",
    "    return loss, labels, logits_ab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e20e1b7-3be3-4c2e-bd06-ae16476baacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed1d.pth',\n",
    "}\n",
    "\n",
    "dp_rate = 0\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv1d(in_planes, out_planes, kernel_size=33, stride=stride,\n",
    "                     padding=16, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn0 = nn.BatchNorm1d(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes*2)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dropout = nn.Dropout(dp_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.bn0(x)\n",
    "        out = self.relu(out)\n",
    "        # out = self.dropout(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "            # residual = torch.cat((residual,residual),1)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.bn0 = nn.BatchNorm1d(inplanes)\n",
    "        self.conv1 = nn.Conv1d(inplanes, planes, kernel_size=33, bias=False, padding=16)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=65, stride=stride,\n",
    "                               padding=32, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.conv3 = nn.Conv1d(planes, planes * 4, kernel_size=1, bias=False, padding=0)\n",
    "        self.bn3 = nn.BatchNorm1d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dropout = nn.Dropout(dp_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.bn0(x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        # out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "            # residual = torch.cat((residual, residual), 1)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, classification, num_classes=2):\n",
    "        self.inplanes = 12\n",
    "        self.classification = classification\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(2, self.inplanes, kernel_size=33, stride=1, padding=16,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv1d(self.inplanes, self.inplanes, kernel_size=33, stride=2, padding=16,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(self.inplanes)\n",
    "        self.downsample = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv1d(self.inplanes, self.inplanes, kernel_size=33, stride=1, padding=16,\n",
    "                               bias=False)\n",
    "        self.dropout = nn.Dropout(dp_rate)\n",
    "        self.layer1 = self._make_layer(block, 12, layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block, 24, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 48, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 96, layers[3], stride=2)\n",
    "        # self.layer5 = self._make_layer(block, self.inplanes, layers[4], stride=2)\n",
    "        self.bn_final = nn.BatchNorm1d(96*2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(2)\n",
    "        self.fc1 = nn.Linear(384,384)  # FIXED 716 t 512\n",
    "        self.bn3 = nn.BatchNorm1d(384)\n",
    "        self.fc2 = nn.Linear(384, 192)\n",
    "        self.bn4 = nn.BatchNorm1d(192)\n",
    "        self.fc3 = nn.Linear(192, 2)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        # x = self.maxpool(x)\n",
    "        out = self.conv2(x)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv3(out)\n",
    "        residual = self.downsample(x)\n",
    "        #print('residual : {}'.format(residual.shape))\n",
    "        #print('out : {}'.format(out.shape))\n",
    "        out += residual\n",
    "        x = self.relu(out)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # x = self.layer5(x)\n",
    "        x = self.bn_final(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(\"x shape : {}\".format(x.shape))\n",
    "        if self.classification:\n",
    "            x = self.fc1(x)\n",
    "            x = self.bn3(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2(x)\n",
    "            x = self.bn4(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc3(x)\n",
    "            # x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [ 2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41a1ed4f-a45c-4f32-ae7d-a7b002901dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy import signal\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "class Transform:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def scaled(self,signal, factor_list):\n",
    "        \"\"\"\"\n",
    "        scale the signal\n",
    "        \"\"\"\n",
    "        factor = round(np.random.uniform(factor_list[0],factor_list[1]),2)\n",
    "        signal[0] = 1 / (1 + np.exp(-signal[0]))\n",
    "        # print(signal.max())\n",
    "        return signal\n",
    "\n",
    "    def negate(self,signal):\n",
    "        \"\"\"\n",
    "        negate the signal\n",
    "        \"\"\"\n",
    "        signal[0] = signal[0] * (-1)\n",
    "        return signal\n",
    "\n",
    "    def hor_filp(self,signal):\n",
    "        \"\"\"\n",
    "        flipped horizontally\n",
    "        \"\"\"\n",
    "        hor_flipped = np.flip(signal,axis=1)\n",
    "        return hor_flipped\n",
    "\n",
    "\n",
    "\n",
    "    def cutout_resize(self,signal,pieces):\n",
    "        \"\"\"\n",
    "                signal: numpy array (batch x window)\n",
    "                pieces: number of segments along time\n",
    "                cutout 1 piece\n",
    "                \"\"\"\n",
    "        signal = signal.T\n",
    "        pieces = int(np.ceil(np.shape(signal)[0] / (np.shape(signal)[0] // pieces)).tolist())  # 向上取整\n",
    "        piece_length = int(np.shape(signal)[0] // pieces)\n",
    "        import random\n",
    "        sequence = []\n",
    "\n",
    "        cutout = random.randint(0, pieces)\n",
    "        # print(cutout)\n",
    "        # sequence1 = list(range(0, cutout))\n",
    "        # sequence2 = list(range(int(cutout + 1), pieces))\n",
    "        # sequence = np.hstack((sequence1, sequence2))\n",
    "        for i in range(pieces):\n",
    "            if i == cutout:\n",
    "                pass\n",
    "            else:\n",
    "                sequence.append(i)\n",
    "        # print(sequence)\n",
    "\n",
    "        cutout_signal = np.reshape(signal[:(np.shape(signal)[0] // pieces * pieces)],\n",
    "                                     (pieces, piece_length)).tolist()\n",
    "\n",
    "        tail = signal[(np.shape(signal)[0] // pieces * pieces):]\n",
    "\n",
    "        cutout_signal = np.asarray(cutout_signal)[sequence]\n",
    "\n",
    "        cutout_signal = np.hstack(cutout_signal)\n",
    "        cutout_signal = np.concatenate((cutout_signal, tail[:, 0]), axis=0)\n",
    "\n",
    "        cutout_signal = cv2.resize(cutout_signal, (1, 3072), interpolation=cv2.INTER_LINEAR)\n",
    "        cutout_signal = cutout_signal.T\n",
    "\n",
    "\n",
    "        return cutout_signal\n",
    "\n",
    "    def cutout_zero(self,signal,pieces):\n",
    "        \"\"\"\n",
    "                signal: numpy array (batch x window)\n",
    "                pieces: number of segments along time\n",
    "                cutout 1 piece\n",
    "                \"\"\"\n",
    "        signal = signal.T\n",
    "        ones = np.ones((np.shape(signal)[0],np.shape(signal)[1]))\n",
    "        # print(ones.shape)\n",
    "        # assert False\n",
    "        pieces = int(np.ceil(np.shape(signal)[0] / (np.shape(signal)[0] // pieces)).tolist())  # 向上取整\n",
    "        piece_length = int(np.shape(signal)[0] // pieces)\n",
    "\n",
    "\n",
    "        cutout = random.randint(1, pieces)\n",
    "        cutout_signal = np.reshape(signal[:(np.shape(signal)[0] // pieces * pieces)],\n",
    "                                     (pieces, piece_length)).tolist()\n",
    "        ones_pieces = np.reshape(ones[:(np.shape(signal)[0] // pieces * pieces)],\n",
    "                                   (pieces, piece_length)).tolist()\n",
    "        tail = signal[(np.shape(signal)[0] // pieces * pieces):]\n",
    "\n",
    "        cutout_signal = np.asarray(cutout_signal)\n",
    "        ones_pieces = np.asarray(ones_pieces)\n",
    "        for i in range(pieces):\n",
    "            if i == cutout:\n",
    "                ones_pieces[i]*=0\n",
    "\n",
    "        cutout_signal = cutout_signal * ones_pieces\n",
    "        cutout_signal = np.hstack(cutout_signal)\n",
    "        cutout_signal = np.concatenate((cutout_signal, tail[:, 0]), axis=0)\n",
    "        cutout_signal = cutout_signal[:,None]\n",
    "        cutout_signal = cutout_signal.T\n",
    "\n",
    "        return cutout_signal\n",
    "    # mic\n",
    "    \n",
    "\n",
    "    def move_avg(self,a,n, mode=\"same\"):\n",
    "        # a = a.T\n",
    "\n",
    "        result = np.convolve(a[0], np.ones((n,)) / n, mode=mode)\n",
    "        return result[None,:]\n",
    "\n",
    "    def bandpass_filter(self, x, order, cutoff, fs=100):\n",
    "        result = np.zeros((x.shape[0], x.shape[1]))\n",
    "        w1 = 2 * cutoff[0] / int(fs)\n",
    "        w2 = 2 * cutoff[1] / int(fs)\n",
    "        b, a = signal.butter(order, [w1, w2], btype='bandpass')  # 配置滤波器 8 表示滤波器的阶数\n",
    "        result = signal.filtfilt(b, a, x, axis=1)\n",
    "        # print(result.shape)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def lowpass_filter(self, x, order, cutoff, fs=100):\n",
    "        result = np.zeros((x.shape[0], x.shape[1]))\n",
    "        w1 = 2 * cutoff[0] / int(fs)\n",
    "        # w2 = 2 * cutoff[1] / fs\n",
    "        b, a = signal.butter(order, w1, btype='lowpass')  # 配置滤波器 8 表示滤波器的阶数\n",
    "        result = signal.filtfilt(b, a, x, axis=1)\n",
    "        # print(result.shape)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def highpass_filter(self, x, order, cutoff, fs=100):\n",
    "        result = np.zeros((x.shape[0], x.shape[1]))\n",
    "        w1 = 2 * cutoff[0] / int(fs)\n",
    "        # w2 = 2 * cutoff[1] / fs\n",
    "        b, a = signal.butter(order, w1, btype='highpass')  # 配置滤波器 8 表示滤波器的阶数\n",
    "        result = signal.filtfilt(b, a, x, axis=1)\n",
    "        # print(result.shape)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def time_warp(self,signal, sampling_freq, pieces, stretch_factor, squeeze_factor):\n",
    "        \"\"\"\n",
    "        signal: numpy array (batch x window)\n",
    "        sampling freq\n",
    "        pieces: number of segments along time\n",
    "        stretch factor\n",
    "        squeeze factor\n",
    "        \"\"\"\n",
    "        signal = signal.T\n",
    "\n",
    "        total_time = np.shape(signal)[0] // sampling_freq\n",
    "        segment_time = total_time / pieces\n",
    "        sequence = list(range(0, pieces))\n",
    "        stretch = np.random.choice(sequence, math.ceil(len(sequence) / 2), replace=False)\n",
    "        squeeze = list(set(sequence).difference(set(stretch)))\n",
    "        initialize = True\n",
    "        for i in sequence:\n",
    "            orig_signal = signal[int(i * np.floor(segment_time * sampling_freq)):int(\n",
    "                (i + 1) * np.floor(segment_time * sampling_freq))]\n",
    "            orig_signal = orig_signal.reshape(np.shape(orig_signal)[0],64, 1)\n",
    "            if i in stretch:\n",
    "                output_shape = int(np.ceil(np.shape(orig_signal)[0] * stretch_factor))\n",
    "                new_signal = cv2.resize(orig_signal, (1, output_shape), interpolation=cv2.INTER_LINEAR)\n",
    "                if initialize == True:\n",
    "                    time_warped = new_signal\n",
    "                    initialize = False\n",
    "                else:\n",
    "                    time_warped = np.vstack((time_warped, new_signal))\n",
    "            elif i in squeeze:\n",
    "                output_shape = int(np.ceil(np.shape(orig_signal)[0] * squeeze_factor))\n",
    "                new_signal = cv2.resize(orig_signal, (1, output_shape), interpolation=cv2.INTER_LINEAR)\n",
    "                if initialize == True:\n",
    "                    time_warped = new_signal\n",
    "                    initialize = False\n",
    "                else:\n",
    "                    time_warped = np.vstack((time_warped, new_signal))\n",
    "        time_warped = cv2.resize(time_warped, (1,3072), interpolation=cv2.INTER_LINEAR)\n",
    "        time_warped = time_warped.T\n",
    "        return time_warped\n",
    "    \n",
    "    def add_noise(self, signal, noise_amount):\n",
    "        \"\"\"\n",
    "        adding noise\n",
    "        \"\"\"\n",
    "        signal = signal.T\n",
    "        noise = (0.4 ** 0.5) * np.random.normal(1, noise_amount, np.shape(signal)[0])\n",
    "        noise = noise[:,None]\n",
    "        noised_signal = signal + noise\n",
    "        noised_signal = noised_signal.T\n",
    "        print(noised_signal.shape)\n",
    "        return noised_signal\n",
    "    \n",
    "    \n",
    "    \n",
    "    def add_noise_with_SNR(self,signal, noise_amount):\n",
    "        \"\"\"\n",
    "        adding noise\n",
    "        created using: https://stackoverflow.com/a/53688043/10700812\n",
    "        \"\"\"\n",
    "        noised_signal_R = np.zeros(signal.shape)\n",
    "        target_snr_db = noise_amount  # 20\n",
    "        #print(\"signal shape : {}\".format(signal.shape))\n",
    "        for i in range(signal.shape[0]-1):\n",
    "            signal = signal[i,:]\n",
    "            x_watts = signal ** 2\n",
    "            #print(\"x_watts shape of {0} : {1}\".format(i,x_watts.shape))\n",
    "            sig_avg_watts = np.mean(x_watts)\n",
    "            sig_avg_db = 10 * np.log10(sig_avg_watts)  # Calculate noise then convert to watts\n",
    "            noise_avg_db = sig_avg_db - target_snr_db\n",
    "            noise_avg_watts = 10 ** (noise_avg_db / 10)\n",
    "            mean_noise = 0\n",
    "            noise_volts = np.random.normal(mean_noise, np.sqrt(noise_avg_watts),\n",
    "                                           len(x_watts))\n",
    "            # Generate an sample of white noise\n",
    "            #print(noise_volts.shape)\n",
    "            noised_signal = signal + noise_volts  # noise added signal\n",
    "\n",
    "            #print(\"noised_signal shape : {}\".format(noised_signal.shape))\n",
    "\n",
    "            noised_signal = noised_signal[None,:]\n",
    "            noised_signal_R[i,:]=noised_signal\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "           # Calculate signal power and convert to dB\n",
    "        \n",
    "        #print('x_watts : {}'.format(x_watts.shape))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print('sig_avg_watts : {}'.format(sig_avg_watts))\n",
    "        \n",
    "        \n",
    "        #print(noised_signal.shape)\n",
    "\n",
    "        return noised_signal_R\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def crop_resize(self, signal, size):\n",
    "        #print(signal.shape)\n",
    "        \n",
    "        signal = signal.T\n",
    "        size = signal.shape[0] * size\n",
    "        size = int(size)\n",
    "        start = random.randint(0, signal.shape[0]-size)\n",
    "        crop_signal = signal[start:start + size,:]\n",
    "        #print(crop_signal.shape)\n",
    "\n",
    "        crop_signal = cv2.resize(crop_signal, (2, 640), interpolation=cv2.INTER_LINEAR)\n",
    "        # print(crop_signal.shape)\n",
    "        crop_signal = crop_signal.T\n",
    "        #print(\"crop_signal.shape : {}\".format(crop_signal.shape))\n",
    "        return crop_signal\n",
    "    \n",
    "    \n",
    "    def permute(self,signal, pieces):\n",
    "        \"\"\"\n",
    "        signal: numpy array (batch x window)\n",
    "        pieces: number of segments along time\n",
    "        \"\"\"\n",
    "        #print('signal shape ; {}'.format(signal.shape))\n",
    "        signal = signal.T\n",
    "        \n",
    "        pieces = int(np.ceil(np.shape(signal)[0] / (np.shape(signal)[0] // pieces)).tolist()) #向上取整\n",
    "        piece_length = int(np.shape(signal)[0] // pieces)\n",
    "        #print(pieces*piece_length)\n",
    "        cal = pieces*piece_length\n",
    "        while cal != 640:\n",
    "            pieces = random.randint(5,20)\n",
    "            pieces = int(np.ceil(np.shape(signal)[0] / (np.shape(signal)[0] // pieces)).tolist()) #向上取整\n",
    "            piece_length = int(np.shape(signal)[0] // pieces)\n",
    "            #print(pieces*piece_length)\n",
    "            cal = pieces*piece_length\n",
    "            \n",
    "        sequence = list(range(0, pieces))\n",
    "        np.random.shuffle(sequence)\n",
    "        #print(signal[:(np.shape(signal)[0] // pieces * pieces)].shape)\n",
    "        for i in range(signal.shape[1]):\n",
    "            #print(i)\n",
    "            #print('signal shape loop ; {}'.format(signal.shape))\n",
    "            # 2,640\n",
    "            permuted_signal = np.reshape(signal[:(np.shape(signal)[0] // pieces * pieces),i],\n",
    "                                         (pieces, piece_length)).tolist()\n",
    "            #print('permuted_signal : {}'.format(len(permuted_signal)))\n",
    "            tail = signal[i,(np.shape(signal)[0] // pieces * pieces):]\n",
    "            \n",
    "            #print('tail shape  ; {}'.format(tail.shape))\n",
    "            permuted_signal = np.asarray(permuted_signal)[sequence]\n",
    "            permuted_signal = np.concatenate(permuted_signal, axis=0)\n",
    "            #print('permuted_signal shape  ; {}'.format(permuted_signal.shape))\n",
    "            permuted_signal = np.concatenate((permuted_signal,tail), axis=0)\n",
    "            permuted_signal = permuted_signal[:,None]\n",
    "            permuted_signal = permuted_signal.T\n",
    "            if i == 0 :\n",
    "                permuted_signal_re = permuted_signal\n",
    "            else:\n",
    "                permuted_signal_re = np.stack((permuted_signal_re,permuted_signal))\n",
    "            #print(permuted_signal_re.shape)\n",
    "        return permuted_signal_re\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e917af6-f1c7-4361-b4ec-ace0d684544a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Apply filter.\n",
      "Filtering raw data in 474 contiguous segments\n",
      "Setting up band-pass filter from 0.05 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.05\n",
      "- Lower transition bandwidth: 0.05 Hz (-6 dB cutoff frequency: 0.03 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 10561 samples (66.006 sec)\n",
      "\n",
      ">>> Create Epochs.\n",
      "Used Annotations descriptions: ['T1', 'T2']\n",
      "Not setting metadata\n",
      "7110 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 7110 events and 641 original time points ...\n",
      "43 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[    672,       0,       1],\n",
       "        [   2000,       0,       0],\n",
       "        [   3328,       0,       0],\n",
       "        ...,\n",
       "        [9355488,       0,       1],\n",
       "        [9356816,       0,       0],\n",
       "        [9358144,       0,       1]]),\n",
       " {'T1': 0, 'T2': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# home directory + datasets folder\n",
    "#path = '/content/drive/MyDrive/MNE-eegbci-data/files/eegmmidb/'\n",
    "path = '1.0.0'\n",
    "base_url = 'https://physionet.org/files/eegmmidb/'\n",
    "# subjects = [1]\n",
    "runs = [3, 4, 7, 8, 11, 12]\n",
    "subjects = [i for i in range(1, 80)]\n",
    "#subjects = [1]\n",
    "# runs = [6,10,14]\n",
    "\n",
    "eeg = EEG(path, base_url, subjects, runs)\n",
    "raw=eeg.data_to_raw()\n",
    "# apply filter\n",
    "freq = (0.05, 40.)\n",
    "raw=eeg.filter(freq=freq)\n",
    "#raw=eeg.raw_ica()\n",
    "eeg.create_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcca7d47-2ced-4852-81c9-d4e921b68fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7067, 64, 641) (7067,)\n",
      "(7067, 1, 641)\n",
      "(7067, 1, 641)\n",
      "(7067, 2, 641)\n",
      "(7067, 2, 640)\n"
     ]
    }
   ],
   "source": [
    "X, y = eeg.get_X_y()\n",
    "\n",
    "print(X.shape, y.shape)\n",
    " \n",
    "#X = X[:, np.newaxis,:,:]\n",
    "X.shape\n",
    "\n",
    "X2 = X[:,  7:8, :] \n",
    "print(X2.shape)\n",
    "\n",
    "X3= X[:,  13:14, :]\n",
    "print(X3.shape)\n",
    "X4 = np.concatenate((X2,X3), axis=1)\n",
    "print(X4.shape)\n",
    "X = X4\n",
    "X=X[:,:,:640]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aead17ed-830d-4cdb-86f7-0295d2dfceeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3bdda6f-001a-4baf-8f15-0417d4f44c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = resnet18(classification=False).to(device)\n",
    "#net = nn.DataParallel(net).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "batch_size = 512\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1 * (batch_size / 64), momentum=0.9, weight_decay=0.00001)\n",
    "\n",
    "epochs = 5000\n",
    "lr_schduler = CosineAnnealingLR(optimizer, T_max=epochs - 10, eta_min=0.05)#default =0.07\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=10, after_scheduler=lr_schduler)\n",
    "optimizer.zero_grad()\n",
    "optimizer.step()\n",
    "scheduler_warmup.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f5251a0-1423-4b04-9827-986eb041b302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4946, 2, 640) (4946,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b474c21b-a121-431b-9ba6-c996f2f6a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"x_train.npy\",x_train)\n",
    "np.save(\"x_test.npy\",x_test)\n",
    "np.save(\"y_train.npy\",y_train)\n",
    "np.save(\"y_test.npy\",y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc60be98-3102-47a7-9f7b-00cfe85d1a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "      \n",
    "x_train = torch.tensor(x_train, dtype=torch.float).to(device)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9c0f955-fa2f-44b1-a70e-c406ab100845",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = ['R', 'L']\n",
    "val_acc_list = []\n",
    "n_train_samples = x_train.shape[0]\n",
    "iter_per_epoch = n_train_samples // batch_size + 1\n",
    "best_acc = -1\n",
    "err = []\n",
    "best_err = 1\n",
    "margin = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ed86e63-47b8-407c-85e3-d68729c195f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs\"\n",
    "model_name = 'resnet17'\n",
    "model_save_dir = '%s/%s_%s' % (log_dir, model_name, time.strftime(\"%m%d%H%M\"))\n",
    "\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "log_templete = {\"acc\": None,\n",
    "                    \"cm\": None,\n",
    "                    \"f1\": None,\n",
    "                \"per F1\":None,\n",
    "                \"epoch\":None,\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe07ef3a-e3be-4ee3-9b19-e91a4fcaee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_plot_acc_loss(acc, loss):\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(acc, label='acc')\n",
    "    plt.plot(loss, label='loss')\n",
    "    #plt.title('loss {}'.format(iter))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b72b6-6d49-4f07-90b3-3a0fd8e474fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 lr?: 0.7999993311290928 error: 0.473918317832592  train_loss = tensor(49.8510, device='cuda:1') Acc = 52.6081682167408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, loss = 4.98:  60%|██████    | 6/10 [00:04<00:02,  1.46it/s]"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "acc =[]\n",
    "loss_train = [] \n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    net.train()\n",
    "    loss_sum = 0\n",
    "    evaluation = []\n",
    "    \n",
    "    iter = 0\n",
    "    with tqdm.tqdm(total=iter_per_epoch) as pbar:\n",
    "        error_counter = 0\n",
    "        \n",
    "        for X, y in train_iter:\n",
    "            trans1 = np.zeros(X.shape)\n",
    "            trans2 = np.zeros(X.shape)\n",
    "            #print(\"trans2 : {}\".format(trans2.shape))\n",
    "            #print(\"X shape : {}\".format(X.shape))\n",
    "            #print(\"X shape[3] : {}\".format(X.shape[3]))\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                #print(X[i].shape)\n",
    "                t1 = transform(X[i], \"noise\")\n",
    "                #print(\"t1 shape : {}\".format(t1.shape))\n",
    "                trans1[i] = t1.reshape(2,X.shape[2])\n",
    "            #print(\"trans1 shape : {}\".format(trans1))   \n",
    "            for i in range(X.shape[0]):\n",
    "                t2 = transform(X[i], 'permute')\n",
    "                \n",
    "                #print(\"t2 shape : {}\".format(t2.shape))\n",
    "                trans2[i] = t2.reshape(2,X.shape[2])\n",
    "                \n",
    "            trans = np.concatenate((trans1,trans2))\n",
    "            \n",
    "            trans = torch.tensor(trans, dtype=torch.float, device=device)\n",
    "            \n",
    "            output = net(trans)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            l, lab_con, log_con = comtrast_loss(output, criterion)\n",
    "            _, log_p = torch.max(log_con.data,1)\n",
    "            evaluation.append((log_p == lab_con).tolist())\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += l\n",
    "            iter += 1\n",
    "            pbar.set_description(\"Epoch %d, loss = %.2f\" % (epoch, l.data))\n",
    "            pbar.update(1)\n",
    "        err = l.data\n",
    "    evaluation = [item for sublist in evaluation for item in sublist]\n",
    "\n",
    "\n",
    "    train_acc = sum(evaluation) / len(evaluation)\n",
    "    error = 1 - train_acc\n",
    "    \n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    acc.append(train_acc*100)\n",
    "    loss_train.append(loss_sum.data.cpu())\n",
    "    #print(acc)\n",
    "    #print(loss_train)\n",
    "    do_plot_acc_loss(acc, loss_train)\n",
    "    print(\"Epoch:\", epoch,\"lr?:\", current_lr, \"error:\", error, \" train_loss =\", loss_sum.data, \"Acc =\",train_acc*100)\n",
    "    #do_plot(loss_sum.data, error)\n",
    "    scheduler_warmup.step()\n",
    "    state = {\"state_dict\": net.state_dict(), \"epoch\": epoch}\n",
    "    save_ckpt(state, best_err > error, model_save_dir)\n",
    "    best_err = min(best_err, error)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db44b9ce-25ca-4732-8844-613139b303fb",
   "metadata": {},
   "source": [
    "### Train classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29917e18-96fd-41a3-91bf-df7fe172c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# home directory + datasets folder\n",
    "#path = '/content/drive/MyDrive/MNE-eegbci-data/files/eegmmidb/'\n",
    "path = '1.0.0'\n",
    "base_url = 'https://physionet.org/files/eegmmidb/'\n",
    "# subjects = [1]\n",
    "runs = [3, 4, 7, 8, 11, 12]\n",
    "subjects = [i for i in range(80, 86)]\n",
    "\n",
    "#subjects = [i for i in range(80, 81)]\n",
    "#subjects = [1]\n",
    "# runs = [6,10,14]\n",
    "\n",
    "eeg = EEG(path, base_url, subjects, runs)\n",
    "raw=eeg.data_to_raw()\n",
    "# apply filter\n",
    "freq = (0.05, 40.)\n",
    "raw=eeg.filter(freq=freq)\n",
    "#raw=eeg.raw_ica()\n",
    "eeg.create_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a335f17-7a4a-4730-8317-f6c6e5469b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = eeg.get_X_y()\n",
    "\n",
    "print(X.shape, y.shape)\n",
    " \n",
    "#X = X[:, np.newaxis,:,:]\n",
    "X.shape\n",
    "\n",
    "X2 = X[:,  7:8, :] \n",
    "print(X2.shape)\n",
    "\n",
    "X3= X[:,  13:14, :]\n",
    "print(X3.shape)\n",
    "X4 = np.concatenate((X2,X3), axis=1)\n",
    "print(X4.shape)\n",
    "X = X4\n",
    "X=X[:,:,:640]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f6a13-1368-44a6-9d76-e507f1a0fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a086192e-54f6-49ba-a2df-c6aa3a78486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "      \n",
    "x_train = torch.tensor(x_train, dtype=torch.float).to(device)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ff7cb6-cd6b-4aea-9dd4-0c146f68c2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f07f1a-ff9b-45bc-97af-141d7050216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = resnet18(classification=True).to(device)\n",
    "#net = nn.DataParallel(net)\n",
    "checkpoint = torch.load(os.path.join(model_save_dir,'best_w.pth'))\n",
    "#checkpoint = torch.load(os.path.join(\"logs/resnet17_05170339\",'best_w.pth'))\n",
    "net.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001, momentum=0.9, weight_decay=0.00001)\n",
    "\n",
    "epochs_t = 1500\n",
    "\n",
    "lr_schduler = CosineAnnealingLR(optimizer, T_max=epochs_t - 10, eta_min=0.09)#default =0.07\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=10, after_scheduler=lr_schduler)\n",
    "optimizer.zero_grad()\n",
    "optimizer.step()\n",
    "scheduler_warmup.step()\n",
    "\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "val_acc_list = []\n",
    "loss_list = []\n",
    "acc_plot = []\n",
    "n_train_samples = x_train.shape[0]\n",
    "iter_per_epoch = n_train_samples // batch_size + 1\n",
    "best_acc = -1\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs_t):\n",
    "    net.train()\n",
    "    loss_sum = 0\n",
    "    evaluation = []\n",
    "    iter = 0\n",
    "    with tqdm.tqdm(total=iter_per_epoch) as pbar:\n",
    "        for X, y in train_iter:\n",
    "            #print(\"X shape : {}\".format(X.shape))\n",
    "            output = net(X)\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            evaluation.append((predicted == y).tolist())\n",
    "            optimizer.zero_grad()\n",
    "            l = criterion(output, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += l\n",
    "            iter += 1\n",
    "            pbar.set_description(\"Epoch %d, loss = %.2f\" % (epoch, l.data))\n",
    "            pbar.update(1)\n",
    "    evaluation = [item for sublist in evaluation for item in sublist]\n",
    "    train_acc = sum(evaluation) / len(evaluation)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    scheduler_warmup.step()\n",
    "    #scheduler_warmup.step()\n",
    "    val_loss = 0\n",
    "    evaluation = []\n",
    "    pred_v = []\n",
    "    true_v = []\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for X, y in test_iter:\n",
    "            output = net(X)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            evaluation.append((predicted == y).tolist())\n",
    "            l = criterion(output, y)\n",
    "            val_loss += l\n",
    "            pred_v.append(predicted.tolist())\n",
    "            true_v.append(y.tolist())\n",
    "    evaluation = [item for sublist in evaluation for item in sublist]\n",
    "    pred_v = [item for sublist in pred_v for item in sublist]\n",
    "    true_v = [item for sublist in true_v for item in sublist]\n",
    "\n",
    "    running_acc = sum(evaluation)*100 / len(evaluation)\n",
    "    val_acc_list.append(running_acc)\n",
    "    loss_list.append(val_loss.cpu())\n",
    "    do_plot_acc_loss(val_acc_list, loss_list)\n",
    "    print(\"val_loss =\", val_loss, \"val_acc =\", running_acc)\n",
    "    print(\"Epoch:\", epoch,\"lr:\", current_lr,\" train_loss =\", loss_sum.data, \" train_acc =\", train_acc)\n",
    "\n",
    "    state = {\"state_dict\": net.state_dict(), \"epoch\": epoch}\n",
    "    save_ckpt(state, best_acc < running_acc, model_save_dir, 'best_cls.pth')\n",
    "    best_acc = max(best_acc, running_acc)\n",
    "\n",
    "print(\"Highest acc:\", max(val_acc_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3126f035-0257-4933-9893-21eb7550ca1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbe8263-2b0f-473e-b4e1-1c1f57502866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a06601-f3d9-406b-b31e-a3e80f6abaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(classification=True).to(device)\n",
    "checkpoint = torch.load(os.path.join(model_save_dir,'best_cls.pth'))\n",
    "model.load_state_dict(checkpoint['state_dict'], strict=True)\n",
    "epoch_b = checkpoint['epoch']\n",
    "# model.train()\n",
    "model.eval()\n",
    "val_loss = 0\n",
    "evaluation = []\n",
    "pred_v = []\n",
    "true_v = []\n",
    "with torch.no_grad():\n",
    "    for X, y in test_iter:\n",
    "        output = model(X)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        evaluation.append((predicted == y).tolist())\n",
    "        l = criterion(output, y)\n",
    "        val_loss += l\n",
    "        pred_v.append(predicted.tolist())\n",
    "        true_v.append(y.tolist())\n",
    "evaluation = [item for sublist in evaluation for item in sublist]\n",
    "pred_v = [item for sublist in pred_v for item in sublist]\n",
    "true_v = [item for sublist in true_v for item in sublist]\n",
    "\n",
    "highest_acc = sum(evaluation) / len(evaluation)\n",
    "print(\"epoch=\" , epoch_b, \"val_acc =\", highest_acc)\n",
    "def calculate_all_prediction(confMatrix):\n",
    "    '''\n",
    "    计算总精度：对角线上所有值除以总数\n",
    "    '''\n",
    "    total_sum = confMatrix.sum()\n",
    "    correct_sum = (np.diag(confMatrix)).sum()\n",
    "    prediction = round(100 * float(correct_sum) / float(total_sum), 2)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def calculate_label_prediction(confMatrix, labelidx):\n",
    "    '''\n",
    "    计算某一个类标预测精度：该类被预测正确的数除以该类的总数\n",
    "    '''\n",
    "    label_total_sum = confMatrix.sum(axis=0)[labelidx]\n",
    "    label_correct_sum = confMatrix[labelidx][labelidx]\n",
    "    prediction = 0\n",
    "    if label_total_sum != 0:\n",
    "        prediction = round(100 * float(label_correct_sum) / float(label_total_sum), 2)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def calculate_label_recall(confMatrix, labelidx):\n",
    "    '''\n",
    "    计算某一个类标的召回率：\n",
    "    '''\n",
    "    label_total_sum = confMatrix.sum(axis=1)[labelidx]\n",
    "    label_correct_sum = confMatrix[labelidx][labelidx]\n",
    "    recall = 0\n",
    "    if label_total_sum != 0:\n",
    "        recall = round(100 * float(label_correct_sum) / float(label_total_sum), 2)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def calculate_f1(prediction, recall):\n",
    "    if (prediction + recall) == 0:\n",
    "        return 0\n",
    "    return round(2 * prediction * recall / (prediction + recall), 2)\n",
    "\n",
    "cm = confusion_matrix(true_v, pred_v)\n",
    "f1_macro = f1_score(true_v, pred_v, average='macro')\n",
    "\n",
    "i=0\n",
    "f1 = []\n",
    "for i in range(5):\n",
    "    r = calculate_label_recall(cm,i)\n",
    "    p = calculate_label_prediction(cm,i)\n",
    "    f = calculate_f1(p,r)\n",
    "    f1.append(f)\n",
    "\n",
    "\n",
    "log_templete[\"acc\"] = '{:.3%}'.format(highest_acc)\n",
    "log_templete[\"epoch\"] = epoch_b\n",
    "\n",
    "\n",
    "log_templete[\"cm\"] = str(cm)\n",
    "log_templete[\"f1\"] = str(f1_macro)\n",
    "log_templete[\"per F1\"] = str(f1)\n",
    "log = log_templete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49149ca0-806f-4288-ad69-b7859cf8744c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
