{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f5c784b-e99a-40e1-9453-a7d754508a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#comment this if you are not using puffer?\n",
    "os.environ['http_proxy'] = 'http://192.41.170.23:3128'\n",
    "os.environ['https_proxy'] = 'http://192.41.170.23:3128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148b7e57-a8b7-4695-ad8e-775cb0fe0e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mne\n",
      "  Downloading mne-1.0.3-py3-none-any.whl (7.5 MB)\n",
      "     |████████████████████████████████| 7.5 MB 1.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.9/site-packages (from mne) (1.21.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from mne) (21.3)\n",
      "Collecting pooch>=1.5\n",
      "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "     |████████████████████████████████| 56 kB 2.4 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from mne) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from mne) (3.0.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from mne) (4.62.3)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.9/site-packages (from mne) (5.1.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from mne) (3.5.1)\n",
      "Collecting appdirs>=1.3.0\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from pooch>=1.5->mne) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging->mne) (3.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->mne) (2.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (4.28.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->mne) (1.3.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->mne) (1.16.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.10)\n",
      "Installing collected packages: appdirs, pooch, mne\n",
      "Successfully installed appdirs-1.4.4 mne-1.0.3 pooch-1.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a06ff5a-770e-490f-8b8a-2341de2d96f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "     |████████████████████████████████| 60.5 MB 52.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.9/site-packages (from opencv-python) (1.21.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.64\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c352b33-cc7e-47b9-bb02-cc55034373c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting warmup-scheduler\n",
      "  Downloading warmup_scheduler-0.3.tar.gz (2.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: warmup-scheduler\n",
      "  Building wheel for warmup-scheduler (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for warmup-scheduler: filename=warmup_scheduler-0.3-py3-none-any.whl size=2983 sha256=5e22b29a7614b1b90993d49a0b9a972c507c1d5f13d87d5d4fbb383ac8456dcc\n",
      "  Stored in directory: /home/st122148/.cache/pip/wheels/a0/ac/20/d906225888dae79c4e45a06a155207b311486f479f2b8cacba\n",
      "Successfully built warmup-scheduler\n",
      "Installing collected packages: warmup-scheduler\n",
      "Successfully installed warmup-scheduler-0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install warmup-scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d3fe08b-8f7c-4439-a50a-06ac2d537926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import os\n",
    "import sys\n",
    "from mne.datasets import eegbci\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from mne.datasets import eegbci\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy import signal\n",
    "\n",
    "import torch\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4a67bea-12f3-413f-a6ba-9c00854fe16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from net import resnet18, resnet34, resnet50, resnet101, resnet152\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import tqdm\n",
    "import mit_utils as utils\n",
    "# import analytics\n",
    "import time\n",
    "import os, shutil\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import random\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24c5c92a-1dfe-458f-84ae-861d039e98c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG:\n",
    "    def __init__(self, path, base_url, subjects, runs):\n",
    "        self.subpath = ''\n",
    "        self.path = path\n",
    "        self.base_url = base_url\n",
    "        self.subjects = subjects\n",
    "        self.runs = runs\n",
    "        \n",
    "        # download data if does not exist in path.\n",
    "        # self.load_data()\n",
    "        self.data_to_raw()\n",
    "    \n",
    "    def load_data(self):\n",
    "        print(f\">>> Start download from: {self.base_url}.\")\n",
    "        print(f\"Downloading files to: {self.path}.\")\n",
    "        for subject in self.subjects:\n",
    "            eegbci.load_data(subject,self.runs,path=self.path,base_url=self.base_url)\n",
    "        print(\"Done.\")\n",
    "    \n",
    "    \n",
    "        \n",
    "        print(\"Done.\")\n",
    "        return self.raw\n",
    "    def filter(self, freq):\n",
    "        raw = self.raw\n",
    "        low, high = freq\n",
    "        print(f\">>> Apply filter.\")\n",
    "        self.raw.filter(low, high, fir_design='firwin', verbose=20)\n",
    "        return  raw\n",
    "    def raw_ica(self):\n",
    "        raw = self.raw\n",
    "        ica = mne.preprocessing.ICA(n_components=64, max_iter=100)\n",
    "        ica.fit(raw)\n",
    "        ica.exclude = [1, 2]  # details on how we picked these are omitted here\n",
    "        ica.plot_properties(raw, picks=ica.exclude)\n",
    "        ica.apply(raw)\n",
    "        print('ICA DONE ????')\n",
    "        return  raw\n",
    "        \n",
    "    def get_events(self):\n",
    "        event_id = dict(T1=0, T2=1) # the events we want to extract\n",
    "        events, event_id = mne.events_from_annotations(self.raw, event_id=event_id)\n",
    "        return events, event_id\n",
    "    \n",
    "    def get_epochs(self, events, event_id):\n",
    "        picks = mne.pick_types(self.raw.info, eeg=True, exclude='bads')\n",
    "        tmin = 0\n",
    "        tmax = 4\n",
    "        epochs = mne.Epochs(self.raw, events, event_id, tmin, tmax, proj=True, \n",
    "                            picks=picks, baseline=None, preload=True)\n",
    "        return epochs\n",
    "    \n",
    "    def create_epochs(self):\n",
    "        print(\">>> Create Epochs.\")\n",
    "        events, event_id = self.get_events()\n",
    "        self.epochs = self.get_epochs(events, event_id)\n",
    "        return events , event_id\n",
    "        \n",
    "        print(\"Done.\")\n",
    "    \n",
    "    def get_X_y(self):\n",
    "        if self.epochs is None:\n",
    "            events , event_id=self.create_epochs()\n",
    "        self.X = self.epochs.get_data()\n",
    "        self.y = self.epochs.events[:, -1]\n",
    "        return self.X, self.y\n",
    "    \n",
    "    \n",
    "    def data_to_raw(self):\n",
    "        fullpath = os.path.join(self.path, *self.subpath.split(sep='/'))\n",
    "        #print(f\">>> Extract all subjects from: {fullpath}.\")\n",
    "        extension = \"edf\"\n",
    "        raws = []\n",
    "        count = 1\n",
    "        for i, subject in enumerate(self.subjects):\n",
    "            sname = f\"S{str(subject).zfill(3)}\".upper()\n",
    "            \n",
    "            for j, run in enumerate(self.runs):\n",
    "                rname = f\"{sname}R{str(run).zfill(2)}\".upper()\n",
    "                path_file = os.path.join(fullpath, sname, f'{rname}.{extension}')\n",
    "                #print(path_file)\n",
    "                #print(f\"Loading file #{count}/{len(self.subjects)*len(self.runs)}: {f'{rname}.{extension}'}\")\n",
    "                raw = mne.io.read_raw_edf( path_file , preload=True, verbose='WARNING' )\n",
    "                raws.append(raw)\n",
    "                count += 1\n",
    "\n",
    "        raw = mne.io.concatenate_raws(raws)\n",
    "        eegbci.standardize(raw)\n",
    "        montage = mne.channels.make_standard_montage('standard_1005')\n",
    "        raw.set_montage(montage)\n",
    "        self.raw = raw\n",
    "        \n",
    "        \n",
    "        \n",
    "def do_plot(train_loss, valid_loss):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(train_loss, label='train_loss')\n",
    "    plt.plot(valid_loss, label='valid_loss')\n",
    "    plt.title('loss {}'.format(iter))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e1694-ae3c-4a9f-9ab9-19fa54692d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba306842-10d9-4f07-ac2f-f2a39c09f12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def save_ckpt(state, is_best, model_save_dir, message='best_w.pth'):\n",
    "    current_w = os.path.join(model_save_dir, 'latest_w.pth')\n",
    "    best_w = os.path.join(model_save_dir, message)\n",
    "    torch.save(state, current_w)\n",
    "    if is_best: shutil.copyfile(current_w, best_w)\n",
    "\n",
    "def transform(x, mode):\n",
    "    x_ = x.cpu().numpy()\n",
    "\n",
    "    Trans = Transform()\n",
    "    if mode == 'time_warp':\n",
    "        pieces = random.randint(5,20)\n",
    "        stretch = random.uniform(1.5,4)\n",
    "        squeeze = random.uniform(0.25,0.67)\n",
    "        x_ = Trans.time_warp(x_, 100, pieces, stretch, squeeze)\n",
    "    elif mode == 'noise':\n",
    "        factor = random.uniform(10,20)\n",
    "        x_ = Trans.add_noise_with_SNR(x_,factor)\n",
    "    elif mode == 'scale':\n",
    "        x_ = Trans.scaled(x_,[0.3,3])\n",
    "    elif mode == 'negate':\n",
    "        x_ = Trans.negate(x_)\n",
    "    elif mode == 'hor_flip':\n",
    "        x_ = Trans.hor_filp(x_)\n",
    "        \n",
    "    elif mode == 'permute':\n",
    "        pieces = random.randint(5,20)\n",
    "        x_ = Trans.permute(x_,pieces)\n",
    "        \n",
    "    elif mode == 'cutout_resize':\n",
    "        pieces = random.randint(5, 20)\n",
    "        x_ = Trans.cutout_resize(x_, pieces)\n",
    "    elif mode == 'cutout_zero':\n",
    "        pieces = random.randint(5, 20)\n",
    "        x_ = Trans.cutout_zero(x_, pieces)\n",
    "    elif mode == 'crop_resize':\n",
    "        size = random.uniform(0.25,0.75)\n",
    "        x_ = Trans.crop_resize(x_, size)\n",
    "    elif mode == 'move_avg':\n",
    "        n = random.randint(3, 10)\n",
    "        x_ = Trans.move_avg(x_,n, mode=\"same\")\n",
    "    #     to test\n",
    "    elif mode == 'lowpass':\n",
    "        order = random.randint(3, 10)\n",
    "        cutoff = random.uniform(5,20)\n",
    "        x_ = Trans.lowpass_filter(x_, order, [cutoff])\n",
    "    elif mode == 'highpass':\n",
    "        order = random.randint(3, 10)\n",
    "        cutoff = random.uniform(5, 10)\n",
    "        x_ = Trans.highpass_filter(x_, order, [cutoff])\n",
    "    elif mode == 'bandpass':\n",
    "        order = random.randint(3, 10)\n",
    "        cutoff_l = random.uniform(1, 5)\n",
    "        cutoff_h = random.uniform(20, 40)\n",
    "        cutoff = [cutoff_l, cutoff_h]\n",
    "        x_ = Trans.bandpass_filter(x_, order, cutoff)\n",
    "\n",
    "    else:\n",
    "        print(\"Error\")\n",
    "\n",
    "    x_ = x_.copy()\n",
    "    x_ = x_[:,None,:]\n",
    "    return x_\n",
    "\n",
    "def comtrast_loss(x, criterion):\n",
    "    LARGE_NUM = 1e9\n",
    "    temperature = 0.1\n",
    "    x = F.normalize(x, dim=-1)\n",
    "\n",
    "    num = int(x.shape[0] / 2)\n",
    "    hidden1, hidden2 = torch.split(x, num)\n",
    "\n",
    "\n",
    "    hidden1_large = hidden1\n",
    "    hidden2_large = hidden2\n",
    "    labels = torch.arange(0,num).to(device)\n",
    "    masks = F.one_hot(torch.arange(0,num), num).to(device)\n",
    "\n",
    "\n",
    "    logits_aa = torch.matmul(hidden1, hidden1_large.T) / temperature\n",
    "    logits_aa = logits_aa - masks * LARGE_NUM\n",
    "    logits_bb = torch.matmul(hidden2, hidden2_large.T) / temperature\n",
    "    logits_bb = logits_bb - masks * LARGE_NUM\n",
    "    logits_ab = torch.matmul(hidden1, hidden2_large.T) / temperature\n",
    "    logits_ba = torch.matmul(hidden2, hidden1_large.T) / temperature\n",
    "    # print(labels)\n",
    "    #\n",
    "    # print(torch.cat([logits_ab, logits_aa], 1).shape)\n",
    "\n",
    "    loss_a = criterion(torch.cat([logits_ab, logits_aa], 1),\n",
    "        labels)\n",
    "    loss_b = criterion(torch.cat([logits_ba, logits_bb], 1),\n",
    "        labels)\n",
    "    loss = torch.mean(loss_a + loss_b)\n",
    "    return loss, labels, logits_ab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e20e1b7-3be3-4c2e-bd06-ae16476baacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed1d.pth',\n",
    "}\n",
    "\n",
    "dp_rate = 0\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv1d(in_planes, out_planes, kernel_size=33, stride=stride,\n",
    "                     padding=16, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 2\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn0 = nn.BatchNorm1d(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes*2)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dropout = nn.Dropout(dp_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.bn0(x)\n",
    "        out = self.relu(out)\n",
    "        # out = self.dropout(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "            # residual = torch.cat((residual,residual),1)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.bn0 = nn.BatchNorm1d(inplanes)\n",
    "        self.conv1 = nn.Conv1d(inplanes, planes, kernel_size=33, bias=False, padding=16)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.conv2 = nn.Conv1d(planes, planes, kernel_size=65, stride=stride,\n",
    "                               padding=32, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.conv3 = nn.Conv1d(planes, planes * 4, kernel_size=1, bias=False, padding=0)\n",
    "        self.bn3 = nn.BatchNorm1d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dropout = nn.Dropout(dp_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.bn0(x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        # out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "            # residual = torch.cat((residual, residual), 1)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, classification, num_classes=2):\n",
    "        self.inplanes = 12\n",
    "        self.classification = classification\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(2, self.inplanes, kernel_size=33, stride=1, padding=16,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv1d(self.inplanes, self.inplanes, kernel_size=33, stride=2, padding=16,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(self.inplanes)\n",
    "        self.downsample = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv1d(self.inplanes, self.inplanes, kernel_size=33, stride=1, padding=16,\n",
    "                               bias=False)\n",
    "        self.dropout = nn.Dropout(dp_rate)\n",
    "        self.layer1 = self._make_layer(block, 12, layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block, 24, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 48, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 96, layers[3], stride=2)\n",
    "        # self.layer5 = self._make_layer(block, self.inplanes, layers[4], stride=2)\n",
    "        self.bn_final = nn.BatchNorm1d(96*2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(2)\n",
    "        self.fc1 = nn.Linear(384,384)  # FIXED 716 t 512\n",
    "        self.bn3 = nn.BatchNorm1d(384)\n",
    "        self.fc2 = nn.Linear(384, 192)\n",
    "        self.bn4 = nn.BatchNorm1d(192)\n",
    "        self.fc3 = nn.Linear(192, 2)\n",
    "        self.softmax = nn.Softmax(1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight.data, mode='fan_in', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        # x = self.maxpool(x)\n",
    "        out = self.conv2(x)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv3(out)\n",
    "        residual = self.downsample(x)\n",
    "        #print('residual : {}'.format(residual.shape))\n",
    "        #print('out : {}'.format(out.shape))\n",
    "        out += residual\n",
    "        x = self.relu(out)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # x = self.layer5(x)\n",
    "        x = self.bn_final(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #print(\"x shape : {}\".format(x.shape))\n",
    "        if self.classification:\n",
    "            x = self.fc1(x)\n",
    "            x = self.bn3(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2(x)\n",
    "            x = self.bn4(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc3(x)\n",
    "            # x = self.softmax(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [ 2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41a1ed4f-a45c-4f32-ae7d-a7b002901dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy import signal\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "class Transform:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def scaled(self,signal, factor_list):\n",
    "        \"\"\"\"\n",
    "        scale the signal\n",
    "        \"\"\"\n",
    "        factor = round(np.random.uniform(factor_list[0],factor_list[1]),2)\n",
    "        signal[0] = 1 / (1 + np.exp(-signal[0]))\n",
    "        # print(signal.max())\n",
    "        return signal\n",
    "\n",
    "    def negate(self,signal):\n",
    "        \"\"\"\n",
    "        negate the signal\n",
    "        \"\"\"\n",
    "        signal[0] = signal[0] * (-1)\n",
    "        return signal\n",
    "\n",
    "    def hor_filp(self,signal):\n",
    "        \"\"\"\n",
    "        flipped horizontally\n",
    "        \"\"\"\n",
    "        hor_flipped = np.flip(signal,axis=1)\n",
    "        return hor_flipped\n",
    "\n",
    "\n",
    "\n",
    "    def cutout_resize(self,signal,pieces):\n",
    "        \"\"\"\n",
    "                signal: numpy array (batch x window)\n",
    "                pieces: number of segments along time\n",
    "                cutout 1 piece\n",
    "                \"\"\"\n",
    "        signal = signal.T\n",
    "        pieces = int(np.ceil(np.shape(signal)[0] / (np.shape(signal)[0] // pieces)).tolist())  # 向上取整\n",
    "        piece_length = int(np.shape(signal)[0] // pieces)\n",
    "        import random\n",
    "        sequence = []\n",
    "\n",
    "        cutout = random.randint(0, pieces)\n",
    "        # print(cutout)\n",
    "        # sequence1 = list(range(0, cutout))\n",
    "        # sequence2 = list(range(int(cutout + 1), pieces))\n",
    "        # sequence = np.hstack((sequence1, sequence2))\n",
    "        for i in range(pieces):\n",
    "            if i == cutout:\n",
    "                pass\n",
    "            else:\n",
    "                sequence.append(i)\n",
    "        # print(sequence)\n",
    "\n",
    "        cutout_signal = np.reshape(signal[:(np.shape(signal)[0] // pieces * pieces)],\n",
    "                                     (pieces, piece_length)).tolist()\n",
    "\n",
    "        tail = signal[(np.shape(signal)[0] // pieces * pieces):]\n",
    "\n",
    "        cutout_signal = np.asarray(cutout_signal)[sequence]\n",
    "\n",
    "        cutout_signal = np.hstack(cutout_signal)\n",
    "        cutout_signal = np.concatenate((cutout_signal, tail[:, 0]), axis=0)\n",
    "\n",
    "        cutout_signal = cv2.resize(cutout_signal, (1, 3072), interpolation=cv2.INTER_LINEAR)\n",
    "        cutout_signal = cutout_signal.T\n",
    "\n",
    "\n",
    "        return cutout_signal\n",
    "\n",
    "    def cutout_zero(self,signal,pieces):\n",
    "        \"\"\"\n",
    "                signal: numpy array (batch x window)\n",
    "                pieces: number of segments along time\n",
    "                cutout 1 piece\n",
    "                \"\"\"\n",
    "        signal = signal.T\n",
    "        ones = np.ones((np.shape(signal)[0],np.shape(signal)[1]))\n",
    "        # print(ones.shape)\n",
    "        # assert False\n",
    "        pieces = int(np.ceil(np.shape(signal)[0] / (np.shape(signal)[0] // pieces)).tolist())  # 向上取整\n",
    "        piece_length = int(np.shape(signal)[0] // pieces)\n",
    "\n",
    "\n",
    "        cutout = random.randint(1, pieces)\n",
    "        cutout_signal = np.reshape(signal[:(np.shape(signal)[0] // pieces * pieces)],\n",
    "                                     (pieces, piece_length)).tolist()\n",
    "        ones_pieces = np.reshape(ones[:(np.shape(signal)[0] // pieces * pieces)],\n",
    "                                   (pieces, piece_length)).tolist()\n",
    "        tail = signal[(np.shape(signal)[0] // pieces * pieces):]\n",
    "\n",
    "        cutout_signal = np.asarray(cutout_signal)\n",
    "        ones_pieces = np.asarray(ones_pieces)\n",
    "        for i in range(pieces):\n",
    "            if i == cutout:\n",
    "                ones_pieces[i]*=0\n",
    "\n",
    "        cutout_signal = cutout_signal * ones_pieces\n",
    "        cutout_signal = np.hstack(cutout_signal)\n",
    "        cutout_signal = np.concatenate((cutout_signal, tail[:, 0]), axis=0)\n",
    "        cutout_signal = cutout_signal[:,None]\n",
    "        cutout_signal = cutout_signal.T\n",
    "\n",
    "        return cutout_signal\n",
    "    # mic\n",
    "    \n",
    "\n",
    "    def move_avg(self,a,n, mode=\"same\"):\n",
    "        # a = a.T\n",
    "\n",
    "        result = np.convolve(a[0], np.ones((n,)) / n, mode=mode)\n",
    "        return result[None,:]\n",
    "\n",
    "    def bandpass_filter(self, x, order, cutoff, fs=100):\n",
    "        result = np.zeros((x.shape[0], x.shape[1]))\n",
    "        w1 = 2 * cutoff[0] / int(fs)\n",
    "        w2 = 2 * cutoff[1] / int(fs)\n",
    "        b, a = signal.butter(order, [w1, w2], btype='bandpass')  # 配置滤波器 8 表示滤波器的阶数\n",
    "        result = signal.filtfilt(b, a, x, axis=1)\n",
    "        # print(result.shape)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def lowpass_filter(self, x, order, cutoff, fs=100):\n",
    "        result = np.zeros((x.shape[0], x.shape[1]))\n",
    "        w1 = 2 * cutoff[0] / int(fs)\n",
    "        # w2 = 2 * cutoff[1] / fs\n",
    "        b, a = signal.butter(order, w1, btype='lowpass')  # 配置滤波器 8 表示滤波器的阶数\n",
    "        result = signal.filtfilt(b, a, x, axis=1)\n",
    "        # print(result.shape)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def highpass_filter(self, x, order, cutoff, fs=100):\n",
    "        result = np.zeros((x.shape[0], x.shape[1]))\n",
    "        w1 = 2 * cutoff[0] / int(fs)\n",
    "        # w2 = 2 * cutoff[1] / fs\n",
    "        b, a = signal.butter(order, w1, btype='highpass')  # 配置滤波器 8 表示滤波器的阶数\n",
    "        result = signal.filtfilt(b, a, x, axis=1)\n",
    "        # print(result.shape)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def time_warp(self,signal, sampling_freq, pieces, stretch_factor, squeeze_factor):\n",
    "        \"\"\"\n",
    "        signal: numpy array (batch x window)\n",
    "        sampling freq\n",
    "        pieces: number of segments along time\n",
    "        stretch factor\n",
    "        squeeze factor\n",
    "        \"\"\"\n",
    "        signal = signal.T\n",
    "\n",
    "        total_time = np.shape(signal)[0] // sampling_freq\n",
    "        segment_time = total_time / pieces\n",
    "        sequence = list(range(0, pieces))\n",
    "        stretch = np.random.choice(sequence, math.ceil(len(sequence) / 2), replace=False)\n",
    "        squeeze = list(set(sequence).difference(set(stretch)))\n",
    "        initialize = True\n",
    "        for i in sequence:\n",
    "            orig_signal = signal[int(i * np.floor(segment_time * sampling_freq)):int(\n",
    "                (i + 1) * np.floor(segment_time * sampling_freq))]\n",
    "            orig_signal = orig_signal.reshape(np.shape(orig_signal)[0],64, 1)\n",
    "            if i in stretch:\n",
    "                output_shape = int(np.ceil(np.shape(orig_signal)[0] * stretch_factor))\n",
    "                new_signal = cv2.resize(orig_signal, (1, output_shape), interpolation=cv2.INTER_LINEAR)\n",
    "                if initialize == True:\n",
    "                    time_warped = new_signal\n",
    "                    initialize = False\n",
    "                else:\n",
    "                    time_warped = np.vstack((time_warped, new_signal))\n",
    "            elif i in squeeze:\n",
    "                output_shape = int(np.ceil(np.shape(orig_signal)[0] * squeeze_factor))\n",
    "                new_signal = cv2.resize(orig_signal, (1, output_shape), interpolation=cv2.INTER_LINEAR)\n",
    "                if initialize == True:\n",
    "                    time_warped = new_signal\n",
    "                    initialize = False\n",
    "                else:\n",
    "                    time_warped = np.vstack((time_warped, new_signal))\n",
    "        time_warped = cv2.resize(time_warped, (1,3072), interpolation=cv2.INTER_LINEAR)\n",
    "        time_warped = time_warped.T\n",
    "        return time_warped\n",
    "    \n",
    "    def add_noise(self, signal, noise_amount):\n",
    "        \"\"\"\n",
    "        adding noise\n",
    "        \"\"\"\n",
    "        signal = signal.T\n",
    "        noise = (0.4 ** 0.5) * np.random.normal(1, noise_amount, np.shape(signal)[0])\n",
    "        noise = noise[:,None]\n",
    "        noised_signal = signal + noise\n",
    "        noised_signal = noised_signal.T\n",
    "        print(noised_signal.shape)\n",
    "        return noised_signal\n",
    "    \n",
    "    \n",
    "    \n",
    "    def add_noise_with_SNR(self,signal, noise_amount):\n",
    "        \"\"\"\n",
    "        adding noise\n",
    "        created using: https://stackoverflow.com/a/53688043/10700812\n",
    "        \"\"\"\n",
    "        noised_signal_R = np.zeros(signal.shape)\n",
    "        target_snr_db = noise_amount  # 20\n",
    "        #print(\"signal shape : {}\".format(signal.shape))\n",
    "        for i in range(signal.shape[0]-1):\n",
    "            signal = signal[i,:]\n",
    "            x_watts = signal ** 2\n",
    "            #print(\"x_watts shape of {0} : {1}\".format(i,x_watts.shape))\n",
    "            sig_avg_watts = np.mean(x_watts)\n",
    "            sig_avg_db = 10 * np.log10(sig_avg_watts)  # Calculate noise then convert to watts\n",
    "            noise_avg_db = sig_avg_db - target_snr_db\n",
    "            noise_avg_watts = 10 ** (noise_avg_db / 10)\n",
    "            mean_noise = 0\n",
    "            noise_volts = np.random.normal(mean_noise, np.sqrt(noise_avg_watts),\n",
    "                                           len(x_watts))\n",
    "            # Generate an sample of white noise\n",
    "            #print(noise_volts.shape)\n",
    "            noised_signal = signal + noise_volts  # noise added signal\n",
    "\n",
    "            #print(\"noised_signal shape : {}\".format(noised_signal.shape))\n",
    "\n",
    "            noised_signal = noised_signal[None,:]\n",
    "            noised_signal_R[i,:]=noised_signal\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "           # Calculate signal power and convert to dB\n",
    "        \n",
    "        #print('x_watts : {}'.format(x_watts.shape))\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print('sig_avg_watts : {}'.format(sig_avg_watts))\n",
    "        \n",
    "        \n",
    "        #print(noised_signal.shape)\n",
    "\n",
    "        return noised_signal_R\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def crop_resize(self, signal, size):\n",
    "        #print(signal.shape)\n",
    "        \n",
    "        signal = signal.T\n",
    "        size = signal.shape[0] * size\n",
    "        size = int(size)\n",
    "        start = random.randint(0, signal.shape[0]-size)\n",
    "        crop_signal = signal[start:start + size,:]\n",
    "        #print(crop_signal.shape)\n",
    "\n",
    "        crop_signal = cv2.resize(crop_signal, (2, 640), interpolation=cv2.INTER_LINEAR)\n",
    "        # print(crop_signal.shape)\n",
    "        crop_signal = crop_signal.T\n",
    "        #print(\"crop_signal.shape : {}\".format(crop_signal.shape))\n",
    "        return crop_signal\n",
    "    \n",
    "    \n",
    "    def permute(self,signal, pieces):\n",
    "        \"\"\"\n",
    "        signal: numpy array (batch x window)\n",
    "        pieces: number of segments along time\n",
    "        \"\"\"\n",
    "        #print('signal shape ; {}'.format(signal.shape))\n",
    "        signal = signal.T\n",
    "        \n",
    "        pieces = int(np.ceil(np.shape(signal)[0] / (np.shape(signal)[0] // pieces)).tolist()) #向上取整\n",
    "        piece_length = int(np.shape(signal)[0] // pieces)\n",
    "        #print(pieces*piece_length)\n",
    "        cal = pieces*piece_length\n",
    "        while cal != 640:\n",
    "            pieces = random.randint(5,20)\n",
    "            pieces = int(np.ceil(np.shape(signal)[0] / (np.shape(signal)[0] // pieces)).tolist()) #向上取整\n",
    "            piece_length = int(np.shape(signal)[0] // pieces)\n",
    "            #print(pieces*piece_length)\n",
    "            cal = pieces*piece_length\n",
    "            \n",
    "        sequence = list(range(0, pieces))\n",
    "        np.random.shuffle(sequence)\n",
    "        #print(signal[:(np.shape(signal)[0] // pieces * pieces)].shape)\n",
    "        for i in range(signal.shape[1]):\n",
    "            #print(i)\n",
    "            #print('signal shape loop ; {}'.format(signal.shape))\n",
    "            # 2,640\n",
    "            permuted_signal = np.reshape(signal[:(np.shape(signal)[0] // pieces * pieces),i],\n",
    "                                         (pieces, piece_length)).tolist()\n",
    "            #print('permuted_signal : {}'.format(len(permuted_signal)))\n",
    "            tail = signal[i,(np.shape(signal)[0] // pieces * pieces):]\n",
    "            \n",
    "            #print('tail shape  ; {}'.format(tail.shape))\n",
    "            permuted_signal = np.asarray(permuted_signal)[sequence]\n",
    "            permuted_signal = np.concatenate(permuted_signal, axis=0)\n",
    "            #print('permuted_signal shape  ; {}'.format(permuted_signal.shape))\n",
    "            permuted_signal = np.concatenate((permuted_signal,tail), axis=0)\n",
    "            permuted_signal = permuted_signal[:,None]\n",
    "            permuted_signal = permuted_signal.T\n",
    "            if i == 0 :\n",
    "                permuted_signal_re = permuted_signal\n",
    "            else:\n",
    "                permuted_signal_re = np.stack((permuted_signal_re,permuted_signal))\n",
    "            #print(permuted_signal_re.shape)\n",
    "        return permuted_signal_re\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e917af6-f1c7-4361-b4ec-ace0d684544a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Apply filter.\n",
      "Filtering raw data in 474 contiguous segments\n",
      "Setting up band-pass filter from 0.05 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.05\n",
      "- Lower transition bandwidth: 0.05 Hz (-6 dB cutoff frequency: 0.03 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 10561 samples (66.006 sec)\n",
      "\n",
      ">>> Create Epochs.\n",
      "Used Annotations descriptions: ['T1', 'T2']\n",
      "Not setting metadata\n",
      "7110 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 7110 events and 641 original time points ...\n",
      "43 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[    672,       0,       1],\n",
       "        [   2000,       0,       0],\n",
       "        [   3328,       0,       0],\n",
       "        ...,\n",
       "        [9355488,       0,       1],\n",
       "        [9356816,       0,       0],\n",
       "        [9358144,       0,       1]]),\n",
       " {'T1': 0, 'T2': 1})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# home directory + datasets folder\n",
    "#path = '/content/drive/MyDrive/MNE-eegbci-data/files/eegmmidb/'\n",
    "path = '1.0.0'\n",
    "base_url = 'https://physionet.org/files/eegmmidb/'\n",
    "# subjects = [1]\n",
    "runs = [3, 4, 7, 8, 11, 12]\n",
    "subjects = [i for i in range(1, 80)]\n",
    "#subjects = [1]\n",
    "# runs = [6,10,14]\n",
    "\n",
    "eeg = EEG(path, base_url, subjects, runs)\n",
    "raw=eeg.data_to_raw()\n",
    "# apply filter\n",
    "freq = (0.05, 40.)\n",
    "raw=eeg.filter(freq=freq)\n",
    "#raw=eeg.raw_ica()\n",
    "eeg.create_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcca7d47-2ced-4852-81c9-d4e921b68fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7067, 64, 641) (7067,)\n",
      "(7067, 1, 641)\n",
      "(7067, 1, 641)\n",
      "(7067, 2, 641)\n",
      "(7067, 2, 640)\n"
     ]
    }
   ],
   "source": [
    "X, y = eeg.get_X_y()\n",
    "\n",
    "print(X.shape, y.shape)\n",
    " \n",
    "#X = X[:, np.newaxis,:,:]\n",
    "X.shape\n",
    "\n",
    "X2 = X[:,  7:8, :] \n",
    "print(X2.shape)\n",
    "\n",
    "X3= X[:,  13:14, :]\n",
    "print(X3.shape)\n",
    "X4 = np.concatenate((X2,X3), axis=1)\n",
    "print(X4.shape)\n",
    "X = X4\n",
    "X=X[:,:,:640]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aead17ed-830d-4cdb-86f7-0295d2dfceeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3bdda6f-001a-4baf-8f15-0417d4f44c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = resnet18(classification=False).to(device)\n",
    "#net = nn.DataParallel(net).to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "batch_size = 512\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1 * (batch_size / 64), momentum=0.9, weight_decay=0.00001)\n",
    "\n",
    "epochs = 5000\n",
    "lr_schduler = CosineAnnealingLR(optimizer, T_max=epochs - 10, eta_min=0.05)#default =0.07\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=10, after_scheduler=lr_schduler)\n",
    "optimizer.zero_grad()\n",
    "optimizer.step()\n",
    "scheduler_warmup.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f5251a0-1423-4b04-9827-986eb041b302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4946, 2, 640) (4946,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b474c21b-a121-431b-9ba6-c996f2f6a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"x_train.npy\",x_train)\n",
    "np.save(\"x_test.npy\",x_test)\n",
    "np.save(\"y_train.npy\",y_train)\n",
    "np.save(\"y_test.npy\",y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc60be98-3102-47a7-9f7b-00cfe85d1a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "      \n",
    "x_train = torch.tensor(x_train, dtype=torch.float).to(device)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9c0f955-fa2f-44b1-a70e-c406ab100845",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = ['R', 'L']\n",
    "val_acc_list = []\n",
    "n_train_samples = x_train.shape[0]\n",
    "iter_per_epoch = n_train_samples // batch_size + 1\n",
    "best_acc = -1\n",
    "err = []\n",
    "best_err = 1\n",
    "margin = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ed86e63-47b8-407c-85e3-d68729c195f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs\"\n",
    "model_name = 'resnet17'\n",
    "model_save_dir = '%s/%s_%s' % (log_dir, model_name, time.strftime(\"%m%d%H%M\"))\n",
    "\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "log_templete = {\"acc\": None,\n",
    "                    \"cm\": None,\n",
    "                    \"f1\": None,\n",
    "                \"per F1\":None,\n",
    "                \"epoch\":None,\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe07ef3a-e3be-4ee3-9b19-e91a4fcaee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_plot_acc_loss(acc, loss):\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(acc, label='acc')\n",
    "    plt.plot(loss, label='loss')\n",
    "    #plt.title('loss {}'.format(iter))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b72b6-6d49-4f07-90b3-3a0fd8e474fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 lr?: 0.7999874401571209 error: 0.32308936514355036  train_loss = tensor(37.3926, device='cuda:1') Acc = 67.69106348564496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, loss = 3.63:  30%|███       | 3/10 [00:02<00:04,  1.42it/s]"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "acc =[]\n",
    "loss_train = [] \n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    net.train()\n",
    "    loss_sum = 0\n",
    "    evaluation = []\n",
    "    \n",
    "    iter = 0\n",
    "    with tqdm.tqdm(total=iter_per_epoch) as pbar:\n",
    "        error_counter = 0\n",
    "        \n",
    "        for X, y in train_iter:\n",
    "            trans1 = np.zeros(X.shape)\n",
    "            trans2 = np.zeros(X.shape)\n",
    "            #print(\"trans2 : {}\".format(trans2.shape))\n",
    "            #print(\"X shape : {}\".format(X.shape))\n",
    "            #print(\"X shape[3] : {}\".format(X.shape[3]))\n",
    "            \n",
    "            for i in range(X.shape[0]):\n",
    "                #print(X[i].shape)\n",
    "                t1 = transform(X[i], \"noise\")\n",
    "                #print(\"t1 shape : {}\".format(t1.shape))\n",
    "                trans1[i] = t1.reshape(2,X.shape[2])\n",
    "            #print(\"trans1 shape : {}\".format(trans1))   \n",
    "            for i in range(X.shape[0]):\n",
    "                t2 = transform(X[i], 'permute')\n",
    "                \n",
    "                #print(\"t2 shape : {}\".format(t2.shape))\n",
    "                trans2[i] = t2.reshape(2,X.shape[2])\n",
    "                \n",
    "            trans = np.concatenate((trans1,trans2))\n",
    "            \n",
    "            trans = torch.tensor(trans, dtype=torch.float, device=device)\n",
    "            \n",
    "            output = net(trans)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            l, lab_con, log_con = comtrast_loss(output, criterion)\n",
    "            _, log_p = torch.max(log_con.data,1)\n",
    "            evaluation.append((log_p == lab_con).tolist())\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += l\n",
    "            iter += 1\n",
    "            pbar.set_description(\"Epoch %d, loss = %.2f\" % (epoch, l.data))\n",
    "            pbar.update(1)\n",
    "        err = l.data\n",
    "    evaluation = [item for sublist in evaluation for item in sublist]\n",
    "\n",
    "\n",
    "    train_acc = sum(evaluation) / len(evaluation)\n",
    "    error = 1 - train_acc\n",
    "    \n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    acc.append(train_acc*100)\n",
    "    loss_train.append(loss_sum.data.cpu())\n",
    "    #print(acc)\n",
    "    #print(loss_train)\n",
    "    do_plot_acc_loss(acc, loss_train)\n",
    "    print(\"Epoch:\", epoch,\"lr?:\", current_lr, \"error:\", error, \" train_loss =\", loss_sum.data, \"Acc =\",train_acc*100)\n",
    "    #do_plot(loss_sum.data, error)\n",
    "    scheduler_warmup.step()\n",
    "    state = {\"state_dict\": net.state_dict(), \"epoch\": epoch}\n",
    "    save_ckpt(state, best_err > error, model_save_dir)\n",
    "    best_err = min(best_err, error)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db44b9ce-25ca-4732-8844-613139b303fb",
   "metadata": {},
   "source": [
    "### Train classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29917e18-96fd-41a3-91bf-df7fe172c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# home directory + datasets folder\n",
    "#path = '/content/drive/MyDrive/MNE-eegbci-data/files/eegmmidb/'\n",
    "path = '1.0.0'\n",
    "base_url = 'https://physionet.org/files/eegmmidb/'\n",
    "# subjects = [1]\n",
    "runs = [3, 4, 7, 8, 11, 12]\n",
    "subjects = [i for i in range(80, 86)]\n",
    "\n",
    "#subjects = [i for i in range(80, 81)]\n",
    "#subjects = [1]\n",
    "# runs = [6,10,14]\n",
    "\n",
    "eeg = EEG(path, base_url, subjects, runs)\n",
    "raw=eeg.data_to_raw()\n",
    "# apply filter\n",
    "freq = (0.05, 40.)\n",
    "raw=eeg.filter(freq=freq)\n",
    "#raw=eeg.raw_ica()\n",
    "eeg.create_epochs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a335f17-7a4a-4730-8317-f6c6e5469b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = eeg.get_X_y()\n",
    "\n",
    "print(X.shape, y.shape)\n",
    " \n",
    "#X = X[:, np.newaxis,:,:]\n",
    "X.shape\n",
    "\n",
    "X2 = X[:,  7:8, :] \n",
    "print(X2.shape)\n",
    "\n",
    "X3= X[:,  13:14, :]\n",
    "print(X3.shape)\n",
    "X4 = np.concatenate((X2,X3), axis=1)\n",
    "print(X4.shape)\n",
    "X = X4\n",
    "X=X[:,:,:640]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f6a13-1368-44a6-9d76-e507f1a0fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a086192e-54f6-49ba-a2df-c6aa3a78486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "      \n",
    "x_train = torch.tensor(x_train, dtype=torch.float).to(device)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataset = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ff7cb6-cd6b-4aea-9dd4-0c146f68c2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f07f1a-ff9b-45bc-97af-141d7050216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = resnet18(classification=True).to(device)\n",
    "#net = nn.DataParallel(net)\n",
    "checkpoint = torch.load(os.path.join(model_save_dir,'best_w.pth'))\n",
    "#checkpoint = torch.load(os.path.join(\"logs/resnet17_05170339\",'best_w.pth'))\n",
    "net.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.00001, momentum=0.9, weight_decay=0.00001)\n",
    "\n",
    "epochs_t = 1500\n",
    "\n",
    "lr_schduler = CosineAnnealingLR(optimizer, T_max=epochs_t - 10, eta_min=0.09)#default =0.07\n",
    "scheduler_warmup = GradualWarmupScheduler(optimizer, multiplier=1, total_epoch=10, after_scheduler=lr_schduler)\n",
    "optimizer.zero_grad()\n",
    "optimizer.step()\n",
    "scheduler_warmup.step()\n",
    "\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "val_acc_list = []\n",
    "loss_list = []\n",
    "acc_plot = []\n",
    "n_train_samples = x_train.shape[0]\n",
    "iter_per_epoch = n_train_samples // batch_size + 1\n",
    "best_acc = -1\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs_t):\n",
    "    net.train()\n",
    "    loss_sum = 0\n",
    "    evaluation = []\n",
    "    iter = 0\n",
    "    with tqdm.tqdm(total=iter_per_epoch) as pbar:\n",
    "        for X, y in train_iter:\n",
    "            #print(\"X shape : {}\".format(X.shape))\n",
    "            output = net(X)\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            evaluation.append((predicted == y).tolist())\n",
    "            optimizer.zero_grad()\n",
    "            l = criterion(output, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += l\n",
    "            iter += 1\n",
    "            pbar.set_description(\"Epoch %d, loss = %.2f\" % (epoch, l.data))\n",
    "            pbar.update(1)\n",
    "    evaluation = [item for sublist in evaluation for item in sublist]\n",
    "    train_acc = sum(evaluation) / len(evaluation)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    scheduler_warmup.step()\n",
    "    #scheduler_warmup.step()\n",
    "    val_loss = 0\n",
    "    evaluation = []\n",
    "    pred_v = []\n",
    "    true_v = []\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for X, y in test_iter:\n",
    "            output = net(X)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            evaluation.append((predicted == y).tolist())\n",
    "            l = criterion(output, y)\n",
    "            val_loss += l\n",
    "            pred_v.append(predicted.tolist())\n",
    "            true_v.append(y.tolist())\n",
    "    evaluation = [item for sublist in evaluation for item in sublist]\n",
    "    pred_v = [item for sublist in pred_v for item in sublist]\n",
    "    true_v = [item for sublist in true_v for item in sublist]\n",
    "\n",
    "    running_acc = sum(evaluation)*100 / len(evaluation)\n",
    "    val_acc_list.append(running_acc)\n",
    "    loss_list.append(val_loss.cpu())\n",
    "    do_plot_acc_loss(val_acc_list, loss_list)\n",
    "    print(\"val_loss =\", val_loss, \"val_acc =\", running_acc)\n",
    "    print(\"Epoch:\", epoch,\"lr:\", current_lr,\" train_loss =\", loss_sum.data, \" train_acc =\", train_acc)\n",
    "\n",
    "    state = {\"state_dict\": net.state_dict(), \"epoch\": epoch}\n",
    "    save_ckpt(state, best_acc < running_acc, model_save_dir, 'best_cls.pth')\n",
    "    best_acc = max(best_acc, running_acc)\n",
    "\n",
    "print(\"Highest acc:\", max(val_acc_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3126f035-0257-4933-9893-21eb7550ca1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbe8263-2b0f-473e-b4e1-1c1f57502866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a06601-f3d9-406b-b31e-a3e80f6abaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(classification=True).to(device)\n",
    "checkpoint = torch.load(os.path.join(model_save_dir,'best_cls.pth'))\n",
    "model.load_state_dict(checkpoint['state_dict'], strict=True)\n",
    "epoch_b = checkpoint['epoch']\n",
    "# model.train()\n",
    "model.eval()\n",
    "val_loss = 0\n",
    "evaluation = []\n",
    "pred_v = []\n",
    "true_v = []\n",
    "with torch.no_grad():\n",
    "    for X, y in test_iter:\n",
    "        output = model(X)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        evaluation.append((predicted == y).tolist())\n",
    "        l = criterion(output, y)\n",
    "        val_loss += l\n",
    "        pred_v.append(predicted.tolist())\n",
    "        true_v.append(y.tolist())\n",
    "evaluation = [item for sublist in evaluation for item in sublist]\n",
    "pred_v = [item for sublist in pred_v for item in sublist]\n",
    "true_v = [item for sublist in true_v for item in sublist]\n",
    "\n",
    "highest_acc = sum(evaluation) / len(evaluation)\n",
    "print(\"epoch=\" , epoch_b, \"val_acc =\", highest_acc)\n",
    "def calculate_all_prediction(confMatrix):\n",
    "    '''\n",
    "    计算总精度：对角线上所有值除以总数\n",
    "    '''\n",
    "    total_sum = confMatrix.sum()\n",
    "    correct_sum = (np.diag(confMatrix)).sum()\n",
    "    prediction = round(100 * float(correct_sum) / float(total_sum), 2)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def calculate_label_prediction(confMatrix, labelidx):\n",
    "    '''\n",
    "    计算某一个类标预测精度：该类被预测正确的数除以该类的总数\n",
    "    '''\n",
    "    label_total_sum = confMatrix.sum(axis=0)[labelidx]\n",
    "    label_correct_sum = confMatrix[labelidx][labelidx]\n",
    "    prediction = 0\n",
    "    if label_total_sum != 0:\n",
    "        prediction = round(100 * float(label_correct_sum) / float(label_total_sum), 2)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def calculate_label_recall(confMatrix, labelidx):\n",
    "    '''\n",
    "    计算某一个类标的召回率：\n",
    "    '''\n",
    "    label_total_sum = confMatrix.sum(axis=1)[labelidx]\n",
    "    label_correct_sum = confMatrix[labelidx][labelidx]\n",
    "    recall = 0\n",
    "    if label_total_sum != 0:\n",
    "        recall = round(100 * float(label_correct_sum) / float(label_total_sum), 2)\n",
    "    return recall\n",
    "\n",
    "\n",
    "def calculate_f1(prediction, recall):\n",
    "    if (prediction + recall) == 0:\n",
    "        return 0\n",
    "    return round(2 * prediction * recall / (prediction + recall), 2)\n",
    "\n",
    "cm = confusion_matrix(true_v, pred_v)\n",
    "f1_macro = f1_score(true_v, pred_v, average='macro')\n",
    "\n",
    "i=0\n",
    "f1 = []\n",
    "for i in range(5):\n",
    "    r = calculate_label_recall(cm,i)\n",
    "    p = calculate_label_prediction(cm,i)\n",
    "    f = calculate_f1(p,r)\n",
    "    f1.append(f)\n",
    "\n",
    "\n",
    "log_templete[\"acc\"] = '{:.3%}'.format(highest_acc)\n",
    "log_templete[\"epoch\"] = epoch_b\n",
    "\n",
    "\n",
    "log_templete[\"cm\"] = str(cm)\n",
    "log_templete[\"f1\"] = str(f1_macro)\n",
    "log_templete[\"per F1\"] = str(f1)\n",
    "log = log_templete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49149ca0-806f-4288-ad69-b7859cf8744c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
